diff --git a/.cargo/config.toml b/.cargo/config.toml
index 46cd4526..ce383d8b 100644
--- a/.cargo/config.toml
+++ b/.cargo/config.toml
@@ -1,2 +1,5 @@
 [alias]
 xtask = "run --manifest-path ./tasks/Cargo.toml --"
+
+[target.x86_64-unknown-linux-gnu]
+linker = "/usr/bin/cc"
\ No newline at end of file
diff --git a/.github/workflows/pbs_gpu_benchmark.yml b/.github/workflows/pbs_gpu_benchmark.yml
new file mode 100644
index 00000000..b5812f19
--- /dev/null
+++ b/.github/workflows/pbs_gpu_benchmark.yml
@@ -0,0 +1,142 @@
+# Run PBS benchmarks on an AWS instance with CUDA and return parsed results to Slab CI bot.
+name: PBS GPU benchmarks
+
+on:
+  workflow_dispatch:
+    inputs:
+      instance_id:
+        description: "Instance ID"
+        type: string
+      instance_image_id:
+        description: "Instance AMI ID"
+        type: string
+      instance_type:
+        description: "Instance product type"
+        type: string
+      runner_name:
+        description: "Action runner name"
+        type: string
+      request_id:
+        description: "Slab request ID"
+        type: string
+      # This input is not used in this workflow but still mandatory since a calling workflow could
+      # use it. If a triggering command include a user_inputs field, then the triggered workflow
+      # must include this very input, otherwise the workflow won't be called.
+      # See start_full_benchmarks.yml as example.
+      user_inputs:
+        description: "Type of benchmarks to run"
+        type: string
+        default: "weekly_benchmarks"
+
+env:
+  CARGO_TERM_COLOR: always
+  RESULTS_FILENAME: parsed_benchmark_results_${{ github.sha }}.json
+  ACTION_RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
+
+jobs:
+  run-pbs-benchmarks:
+    name: Execute PBS benchmarks in EC2
+    runs-on: ${{ github.event.inputs.runner_name }}
+    if: ${{ !cancelled() }}
+    steps:
+      - name: Instance configuration used
+        run: |
+          echo "IDs: ${{ inputs.instance_id }}"
+          echo "AMI: ${{ inputs.instance_image_id }}"
+          echo "Type: ${{ inputs.instance_type }}"
+          echo "Request ID: ${{ inputs.request_id }}"
+
+      - name: Get benchmark date
+        run: |
+          echo "BENCH_DATE=$(date --iso-8601=seconds)" >> "${GITHUB_ENV}"
+
+      - name: Checkout tfhe-rs repo with tags
+        uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11
+        with:
+          fetch-depth: 0
+
+      - name: Set up home
+        # "Install rust" step require root user to have a HOME directory which is not set.
+        run: |
+          echo "HOME=/home/ubuntu" >> "${GITHUB_ENV}"
+
+      - name: Install rust
+        uses: dtolnay/rust-toolchain@be73d7920c329f220ce78e0234b8f96b7ae60248
+        with:
+          toolchain: nightly
+
+      - name: Export CUDA variables
+        if: ${{ !cancelled() }}
+        run: |
+          echo "CUDA_PATH=$CUDA_PATH" >> "${GITHUB_ENV}"
+          echo "$CUDA_PATH/bin" >> "${GITHUB_PATH}"
+          echo "LD_LIBRARY_PATH=$CUDA_PATH/lib:$LD_LIBRARY_PATH" >> "${GITHUB_ENV}"
+          echo "CUDACXX=/usr/local/cuda-${{ matrix.cuda }}/bin/nvcc" >> "${GITHUB_ENV}"
+
+      # Specify the correct host compilers
+      - name: Export gcc and g++ variables
+        if: ${{ !cancelled() }}
+        run: |
+          echo "CC=/usr/bin/gcc-${{ matrix.gcc }}" >> "${GITHUB_ENV}"
+          echo "CXX=/usr/bin/g++-${{ matrix.gcc }}" >> "${GITHUB_ENV}"
+          echo "CUDAHOSTCXX=/usr/bin/g++-${{ matrix.gcc }}" >> "${GITHUB_ENV}"
+          echo "HOME=/home/ubuntu" >> "${GITHUB_ENV}"
+
+      - name: Run benchmarks with AVX512
+        run: |
+          make AVX512_SUPPORT=ON bench_pbs_gpu
+
+      - name: Parse results
+        run: |
+          COMMIT_DATE="$(git --no-pager show -s --format=%cd --date=iso8601-strict ${{ github.sha }})"
+          COMMIT_HASH="$(git describe --tags --dirty)"
+          python3 ./ci/benchmark_parser.py target/criterion ${{ env.RESULTS_FILENAME }} \
+          --database tfhe_rs \
+          --hardware ${{ inputs.instance_type }} \
+          --backend gpu \
+          --project-version "${COMMIT_HASH}" \
+          --branch ${{ github.ref_name }} \
+          --commit-date "${COMMIT_DATE}" \
+          --bench-date "${{ env.BENCH_DATE }}" \
+          --name-suffix avx512 \
+          --walk-subdirs \
+          --throughput
+
+      - name: Upload parsed results artifact
+        uses: actions/upload-artifact@26f96dfa697d77e81fd5907df203aa23a56210a8
+        with:
+          name: ${{ github.sha }}_pbs
+          path: ${{ env.RESULTS_FILENAME }}
+
+      - name: Checkout Slab repo
+        uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11
+        with:
+          repository: zama-ai/slab
+          path: slab
+          token: ${{ secrets.CONCRETE_ACTIONS_TOKEN }}
+
+      - name: Send data to Slab
+        shell: bash
+        run: |
+          echo "Computing HMac on downloaded artifact"
+          SIGNATURE="$(slab/scripts/hmac_calculator.sh ${{ env.RESULTS_FILENAME }} '${{ secrets.JOB_SECRET }}')"
+          echo "Sending results to Slab..."
+          curl -v -k \
+          -H "Content-Type: application/json" \
+          -H "X-Slab-Repository: ${{ github.repository }}" \
+          -H "X-Slab-Command: store_data_v2" \
+          -H "X-Hub-Signature-256: sha256=${SIGNATURE}" \
+          -d @${{ env.RESULTS_FILENAME }} \
+          ${{ secrets.SLAB_URL }}
+
+      - name: Slack Notification
+        if: ${{ failure() }}
+        continue-on-error: true
+        uses: rtCamp/action-slack-notify@b24d75fe0e728a4bf9fc42ee217caa686d141ee8
+        env:
+          SLACK_COLOR: ${{ job.status }}
+          SLACK_CHANNEL: ${{ secrets.SLACK_CHANNEL }}
+          SLACK_ICON: https://pbs.twimg.com/profile_images/1274014582265298945/OjBKP9kn_400x400.png
+          SLACK_MESSAGE: "PBS GPU benchmarks failed. (${{ env.ACTION_RUN_URL }})"
+          SLACK_USERNAME: ${{ secrets.BOT_USERNAME }}
+          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
diff --git a/.gitignore b/.gitignore
index 2858698a..d5fe8a18 100644
--- a/.gitignore
+++ b/.gitignore
@@ -1,6 +1,7 @@
 target/
 .idea/
 .vscode/
+testvectors/
 
 # Path we use for internal-keycache during tests
 /keys/
diff --git a/Cargo.toml b/Cargo.toml
index 96f9a264..c5e9f36e 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -6,7 +6,6 @@ members = [
     "tasks",
     "apps/trivium",
     "concrete-csprng",
-    "backends/tfhe-cuda-backend",
     "utils/tfhe-versionable",
     "utils/tfhe-versionable-derive",
 ]
@@ -30,6 +29,6 @@ lto = "off"
 # Compiles much faster for tests and allows reasonable performance for iterating
 [profile.devo]
 inherits = "dev"
-opt-level = 3
+opt-level = 0
 lto = "off"
 debug-assertions = false
diff --git a/Makefile b/Makefile
index 11661bc3..82668498 100644
--- a/Makefile
+++ b/Makefile
@@ -517,6 +517,25 @@ test_core_crypto_cov: install_rs_build_toolchain install_rs_check_toolchain inst
 			-p $(TFHE_SPEC) -- -Z unstable-options --report-time core_crypto::; \
 	fi
 
+# Run the internal tests of the FPGA
+# --lib            : Avoid doctests for now
+# --test-threads=1 : Sequential tests, as multiple threads cannot share FPGA
+# --show-output    : For seeing println's while executing tests
+.PHONY: test_integer_fpga
+test_integer_fpga:
+	RUSTFLAGS="$(RUSTFLAGS)" cargo $(CARGO_RS_BUILD_TOOLCHAIN) test --profile $(CARGO_PROFILE) \
+		--lib \
+		--features=$(TARGET_ARCH_FEATURE),fpga -p $(TFHE_SPEC) -- integer::fpga:: \
+		--test-threads=1 \
+		--show-output
+		
+.PHONY: test_integer_fpga_emulate
+test_integer_fpga_emulate:
+	RUSTFLAGS="$(RUSTFLAGS)" cargo $(CARGO_RS_BUILD_TOOLCHAIN) test --profile $(CARGO_PROFILE) \
+		--lib \
+		--features=$(TARGET_ARCH_FEATURE),fpga,emulate_fpga -p $(TFHE_SPEC) -- integer::fpga:: \
+		--show-output
+
 .PHONY: test_cuda_backend # Run the internal tests of the CUDA backend
 test_cuda_backend:
 	mkdir -p "$(TFHECUDA_BUILD)" && \
@@ -953,18 +972,39 @@ dieharder_csprng: install_dieharder build_concrete_csprng
 #
 # Benchmarks
 #
-
 .PHONY: print_doc_bench_parameters # Print parameters used in doc benchmarks
 print_doc_bench_parameters:
 	RUSTFLAGS="" cargo run --example print_doc_bench_parameters \
 	--features=$(TARGET_ARCH_FEATURE),shortint,internal-keycache -p tfhe
+.PHONY: bench_fpga # Run benchmarks for integer operations supported on fpga
+
+bench_integer_fpga:
+	RUSTFLAGS="$(RUSTFLAGS)" __TFHE_RS_BENCH_OP_FLAVOR=$(BENCH_OP_FLAVOR) __TFHE_RS_FAST_BENCH=$(FAST_BENCH) \
+	cargo $(CARGO_RS_CHECK_TOOLCHAIN) bench \
+	--bench fpga-integer \
+	--features=$(TARGET_ARCH_FEATURE),integer,internal-keycache,boolean,shortint,fpga -p $(TFHE_SPEC) --
+
+.PHONY: bench_fpga_throughput # Run benchmarks for fpga pbs throughput
+bench_fpga_throughput:
+	RUSTFLAGS="$(RUSTFLAGS)" __TFHE_RS_BENCH_OP_FLAVOR=$(BENCH_OP_FLAVOR) __TFHE_RS_FAST_BENCH=$(FAST_BENCH) \
+	cargo $(CARGO_RS_CHECK_TOOLCHAIN) bench \
+	--bench fpga-throughput \
+	--features=$(TARGET_ARCH_FEATURE),internal-keycache,boolean,shortint,fpga -p $(TFHE_SPEC) --
+	python3 tfhe/benches/fpga/throughput.py
+
+.PHONY: bench_fpga_kspbs # Run benchmarks for sub-routines of fpga integration
+bench_fpga_kspbs:
+	RUSTFLAGS="$(RUSTFLAGS)" __TFHE_RS_BENCH_OP_FLAVOR=$(BENCH_OP_FLAVOR) __TFHE_RS_FAST_BENCH=$(FAST_BENCH) \
+	cargo $(CARGO_RS_CHECK_TOOLCHAIN) bench \
+	--bench fpga-kspbs \
+	--features=$(TARGET_ARCH_FEATURE),internal-keycache,boolean,shortint,fpga -p $(TFHE_SPEC) --
 
 .PHONY: bench_integer # Run benchmarks for unsigned integer
 bench_integer: install_rs_check_toolchain
 	RUSTFLAGS="$(RUSTFLAGS)" __TFHE_RS_BENCH_OP_FLAVOR=$(BENCH_OP_FLAVOR) __TFHE_RS_FAST_BENCH=$(FAST_BENCH) \
 	cargo $(CARGO_RS_CHECK_TOOLCHAIN) bench \
 	--bench integer-bench \
-	--features=$(TARGET_ARCH_FEATURE),integer,internal-keycache,nightly-avx512 -p $(TFHE_SPEC) --
+	--features=$(TARGET_ARCH_FEATURE),boolean,integer,internal-keycache,nightly-avx512 -p $(TFHE_SPEC) --
 
 .PHONY: bench_signed_integer # Run benchmarks for signed integer
 bench_signed_integer: install_rs_check_toolchain
diff --git a/README.md b/README.md
index 6aa7db07..b7ef2ccc 100644
--- a/README.md
+++ b/README.md
@@ -1,280 +1,20 @@
-<p align="center">
-<!-- product name logo -->
-<picture>
-  <source media="(prefers-color-scheme: dark)" srcset="https://github.com/zama-ai/tfhe-rs/assets/157474013/5283e0ba-da1e-43af-9f2a-c5221367a12b">
-  <source media="(prefers-color-scheme: light)" srcset="https://github.com/zama-ai/tfhe-rs/assets/157474013/b94a8c96-7595-400b-9311-70765c706955">
-  <img width=600 alt="Zama TFHE-rs">
-</picture>
-</p>
+# TFHE-rs
 
-<hr/>
+This repository is a fork of [tfhe-rs]() with integration of FPT. Refer to `tfhe-rs`' [README.md](./ZAMA_README.md) for more information.
 
-<p align="center">
-  <a href="https://docs.zama.ai/tfhe-rs"> 📒 Documentation</a> | <a href="https://zama.ai/community"> 💛 Community support</a> | <a href="https://github.com/zama-ai/awesome-zama"> 📚 FHE resources by Zama</a>
-</p>
+## Apps
 
+A number of apps have been added to profile, test, and demo FPT. Refer to [apps/README.md](./apps/README.md) for more information.
 
-<p align="center">
-  <a href="https://github.com/zama-ai/tfhe-rs/releases"><img src="https://img.shields.io/github/v/release/zama-ai/tfhe-rs?style=flat-square"></a>
-  <a href="LICENSE"><img src="https://img.shields.io/badge/License-BSD--3--Clause--Clear-%23ffb243?style=flat-square"></a>
-  <a href="https://github.com/zama-ai/bounty-program"><img src="https://img.shields.io/badge/Contribute-Zama%20Bounty%20Program-%23ffd208?style=flat-square"></a>
-</p>
 
-## About
+## Syncing with upstream
 
-### What is TFHE-rs
+To sync with an upstream version of `tfhe-rs`, run the following:
 
-**TFHE-rs** is a pure Rust implementation of TFHE for boolean and integer arithmetics over encrypted data.
-
-It includes:
-- a **Rust** API
-- a **C** API
-- and a **client-side WASM** API
-
-TFHE-rs is designed for developers and researchers who want full control over
-what they can do with TFHE, while not having to worry about the low-level
-implementation. The goal is to have a stable, simple, high-performance, and
-production-ready library for all the advanced features of TFHE.
-<br></br>
-
-### Main features
-
-- **Low-level cryptographic library** that implements Zama’s variant of TFHE, including programmable bootstrapping
-- **Implementation of the original TFHE boolean API** that can be used as a drop-in replacement for other TFHE libraries
-- **Short integer API** that enables exact, unbounded FHE integer arithmetics with up to 8 bits of message space
-- **Size-efficient public key encryption**
-- **Ciphertext and server key compression** for efficient data transfer
-- **Full Rust API, C bindings to the Rust High-Level API, and client-side Javascript API using WASM**.
-
-*Learn more about TFHE-rs features in the [documentation](https://docs.zama.ai/tfhe-rs/readme).*
-<br></br>
-
-## Table of Contents
-- **[Getting started](#getting-started)**
-   - [Cargo.toml configuration](#cargotoml-configuration)
-   - [A simple example](#a-simple-example)
-- **[Resources](#resources)**
-   - [TFHE deep dive](#tfhe-deep-dive)
-   - [Tutorials](#tutorials)
-   - [Documentation](#documentation)
-- **[Working with TFHE-rs](#working-with-tfhe-rs)**
-   - [Disclaimers](#disclaimers)
-   - [Citations](#citations)
-   - [Contributing](#contributing)
-   - [License](#license)
-- **[Support](#support)**
-<br></br>
-
-## Getting started
-
-### Cargo.toml configuration
-To use the latest version of `TFHE-rs` in your project, you first need to add it as a dependency in your `Cargo.toml`:
-
-+ For x86_64-based machines running Unix-like OSes:
-
-```toml
-tfhe = { version = "*", features = ["boolean", "shortint", "integer", "x86_64-unix"] }
-```
-
-+ For Apple Silicon or aarch64-based machines running Unix-like OSes:
-
-```toml
-tfhe = { version = "*", features = ["boolean", "shortint", "integer", "aarch64-unix"] }
-```
-
-+ For x86_64-based machines with the [`rdseed instruction`](https://en.wikipedia.org/wiki/RDRAND) running Windows:
-
-```toml
-tfhe = { version = "*", features = ["boolean", "shortint", "integer", "x86_64"] }
-```
-
-> [!Note]
-> Note: You need to use a Rust version >= 1.73 to compile TFHE-rs.
-
-> [!Note]
-> Note: aarch64-based machines are not yet supported for Windows as it's currently missing an entropy source to be able to seed the [CSPRNGs](https://en.wikipedia.org/wiki/Cryptographically_secure_pseudorandom_number_generator) used in TFHE-rs.
-
-<p align="right">
-  <a href="#about" > ↑ Back to top </a> 
-</p>
-
-### A simple example
-
-Here is a full example:
-
-``` rust
-use tfhe::prelude::*;
-use tfhe::{generate_keys, set_server_key, ConfigBuilder, FheUint32, FheUint8};
-
-fn main() -> Result<(), Box<dyn std::error::Error>> {
-    // Basic configuration to use homomorphic integers
-    let config = ConfigBuilder::default().build();
-
-    // Key generation
-    let (client_key, server_keys) = generate_keys(config);
-
-    let clear_a = 1344u32;
-    let clear_b = 5u32;
-    let clear_c = 7u8;
-
-    // Encrypting the input data using the (private) client_key
-    // FheUint32: Encrypted equivalent to u32
-    let mut encrypted_a = FheUint32::try_encrypt(clear_a, &client_key)?;
-    let encrypted_b = FheUint32::try_encrypt(clear_b, &client_key)?;
-
-    // FheUint8: Encrypted equivalent to u8
-    let encrypted_c = FheUint8::try_encrypt(clear_c, &client_key)?;
-
-    // On the server side:
-    set_server_key(server_keys);
-
-    // Clear equivalent computations: 1344 * 5 = 6720
-    let encrypted_res_mul = &encrypted_a * &encrypted_b;
-
-    // Clear equivalent computations: 6720 >> 5 = 210
-    encrypted_a = &encrypted_res_mul >> &encrypted_b;
-
-    // Clear equivalent computations: let casted_a = a as u8;
-    let casted_a: FheUint8 = encrypted_a.cast_into();
-
-    // Clear equivalent computations: min(210, 7) = 7
-    let encrypted_res_min = &casted_a.min(&encrypted_c);
-
-    // Operation between clear and encrypted data:
-    // Clear equivalent computations: 7 & 1 = 1
-    let encrypted_res = encrypted_res_min & 1_u8;
-
-    // Decrypting on the client side:
-    let clear_res: u8 = encrypted_res.decrypt(&client_key);
-    assert_eq!(clear_res, 1_u8);
-
-    Ok(())
-}
+```bash
+git remote add upstream https://github.com/zama-ai/tfhe-rs.git
+git fetch upstream
+git merge <tag> --no-ff
 ```
 
-To run this code, use the following command: 
-<p align="center"> <code> cargo run --release </code> </p>
-
-> [!Note]
-> Note that when running code that uses `TFHE-rs`, it is highly recommended
-to run in release mode with cargo's `--release` flag to have the best performances possible.
-
-*Find an example with more explanations in [this part of the documentation](https://docs.zama.ai/tfhe-rs/get-started/quick_start)*
-
-<p align="right">
-  <a href="#about" > ↑ Back to top </a> 
-</p>
-
-
-
-## Resources 
-
-### TFHE deep dive
-- [TFHE Deep Dive - Part I - Ciphertext types](https://www.zama.ai/post/tfhe-deep-dive-part-1)
-- [TFHE Deep Dive - Part II - Encodings and linear leveled operations](https://www.zama.ai/post/tfhe-deep-dive-part-2)
-- [TFHE Deep Dive - Part III - Key switching and leveled multiplications](https://www.zama.ai/post/tfhe-deep-dive-part-3)
-- [TFHE Deep Dive - Part IV - Programmable Bootstrapping](https://www.zama.ai/post/tfhe-deep-dive-part-4)
-<br></br>
-
-### Tutorials
-- [[Video tutorial] Implement signed integers using TFHE-rs ](https://www.zama.ai/post/video-tutorial-implement-signed-integers-ssing-tfhe-rs)
-- [Homomorphic parity bit](https://docs.zama.ai/tfhe-rs/tutorials/parity_bit)
-- [Homomorphic case changing on Ascii string](https://docs.zama.ai/tfhe-rs/tutorials/ascii_fhe_string)
-- [Boolean SHA256 with TFHE-rs](https://www.zama.ai/post/boolean-sha256-tfhe-rs)
-- [Dark market with TFHE-rs](https://www.zama.ai/post/dark-market-tfhe-rs)
-- [Regular expression engine with TFHE-rs](https://www.zama.ai/post/regex-engine-tfhe-rs)
-
-*Explore more useful resources in [TFHE-rs tutorials](https://docs.zama.ai/tfhe-rs/tutorials) and [Awesome Zama repo](https://github.com/zama-ai/awesome-zama)*
-<br></br>
-### Documentation
-
-Full, comprehensive documentation is available here: [https://docs.zama.ai/tfhe-rs](https://docs.zama.ai/tfhe-rs).
-<p align="right">
-  <a href="#about" > ↑ Back to top </a> 
-</p>
-
-
-## Working with TFHE-rs
-
-### Disclaimers
-
-#### Security estimation
-
-Security estimations are done using the
-[Lattice Estimator](https://github.com/malb/lattice-estimator)
-with `red_cost_model = reduction.RC.BDGL16`.
-
-When a new update is published in the Lattice Estimator, we update parameters accordingly.
-
-### Security model
-
-The default parameters for the TFHE-rs library are chosen considering the IND-CPA security model, and are selected with a bootstrapping failure probability fixed at p_error = $2^{-64}$. In particular, it is assumed that the results of decrypted computations are not shared by the secret key owner with any third parties, as such an action can lead to leakage of the secret encryption key. If you are designing an application where decryptions must be shared, you will need to craft custom encryption parameters which are chosen in consideration of the IND-CPA^D security model [1]. 
-
-[1] Li, Baiyu, et al. "Securing approximate homomorphic encryption using differential privacy." Annual International Cryptology Conference. Cham: Springer Nature Switzerland, 2022. https://eprint.iacr.org/2022/816.pdf
-
-#### Side-channel attacks
-
-Mitigation for side-channel attacks has not yet been implemented in TFHE-rs,
-and will be released in upcoming versions.
-<br></br>
-
-### Citations
-To cite TFHE-rs in academic papers, please use the following entry:
-
-```text
-@Misc{TFHE-rs,
-  title={{TFHE-rs: A Pure Rust Implementation of the TFHE Scheme for Boolean and Integer Arithmetics Over Encrypted Data}},
-  author={Zama},
-  year={2022},
-  note={\url{https://github.com/zama-ai/tfhe-rs}},
-}
-```
-
-### Contributing
-
-There are two ways to contribute to TFHE-rs:
-
-- [Open issues](https://github.com/zama-ai/tfhe-rs/issues/new/choose) to report bugs and typos, or to suggest new ideas
-- Request to become an official contributor by emailing [hello@zama.ai](mailto:hello@zama.ai).
-
-Becoming an approved contributor involves signing our Contributor License Agreement (CLA). Only approved contributors can send pull requests, so please make sure to get in touch before you do!
-<br></br>
-
-### License
-This software is distributed under the **BSD-3-Clause-Clear** license. Read [this](LICENSE) for more details.
-
-#### FAQ
-**Is Zama’s technology free to use?**
->Zama’s libraries are free to use under the BSD 3-Clause Clear license only for development, research, prototyping, and experimentation purposes. However, for any commercial use of Zama's open source code, companies must purchase Zama’s commercial patent license.
->
->Everything we do is open source and we are very transparent on what it means for our users, you can read more about how we monetize our open source products at Zama in [this blogpost](https://www.zama.ai/post/open-source).
-
-**What do I need to do if I want to use Zama’s technology for commercial purposes?**
->To commercially use Zama’s technology you need to be granted Zama’s patent license. Please contact us hello@zama.ai for more information.
-
-**Do you file IP on your technology?**
->Yes, all Zama’s technologies are patented.
-
-**Can you customize a solution for my specific use case?**
->We are open to collaborating and advancing the FHE space with our partners. If you have specific needs, please email us at hello@zama.ai.
-
-<p align="right">
-  <a href="#about" > ↑ Back to top </a> 
-</p>
-
-
-## Support
-
-<a target="_blank" href="https://community.zama.ai">
-<picture>
-  <source media="(prefers-color-scheme: dark)" srcset="https://github.com/zama-ai/tfhe-rs/assets/157474013/08656d0a-3f44-4126-b8b6-8c601dff5380">
-  <source media="(prefers-color-scheme: light)" srcset="https://github.com/zama-ai/tfhe-rs/assets/157474013/1c9c9308-50ac-4aab-a4b9-469bb8c536a4">
-  <img alt="Support">
-</picture>
-</a>
-
-🌟 If you find this project helpful or interesting, please consider giving it a star on GitHub! Your support helps to grow the community and motivates further development. 
-
-<p align="right">
-  <a href="#about" > ↑ Back to top </a> 
-</p>
+Afterwards, resolve any merge conflicts. :warning: Please only sync with tagged versions.
diff --git a/ZAMA_README.md b/ZAMA_README.md
new file mode 100644
index 00000000..4614ca3f
--- /dev/null
+++ b/ZAMA_README.md
@@ -0,0 +1,256 @@
+### What is TFHE-rs
+
+**TFHE-rs** is a pure Rust implementation of TFHE for boolean and integer arithmetics over encrypted data.
+
+It includes:
+- a **Rust** API
+- a **C** API
+- and a **client-side WASM** API
+
+TFHE-rs is designed for developers and researchers who want full control over
+what they can do with TFHE, while not having to worry about the low-level
+implementation. The goal is to have a stable, simple, high-performance, and
+production-ready library for all the advanced features of TFHE.
+<br></br>
+
+### Main features
+
+- **Low-level cryptographic library** that implements Zama’s variant of TFHE, including programmable bootstrapping
+- **Implementation of the original TFHE boolean API** that can be used as a drop-in replacement for other TFHE libraries
+- **Short integer API** that enables exact, unbounded FHE integer arithmetics with up to 8 bits of message space
+- **Size-efficient public key encryption**
+- **Ciphertext and server key compression** for efficient data transfer
+- **Full Rust API, C bindings to the Rust High-Level API, and client-side Javascript API using WASM**.
+
+*Learn more about TFHE-rs features in the [documentation](https://docs.zama.ai/tfhe-rs/readme).*
+<br></br>
+
+## Table of Contents
+- **[Getting started](#getting-started)**
+   - [Cargo.toml configuration](#cargotoml-configuration)
+   - [A simple example](#a-simple-example)
+- **[Resources](#resources)**
+   - [TFHE deep dive](#tfhe-deep-dive)
+   - [Tutorials](#tutorials)
+   - [Documentation](#documentation)
+- **[Working with TFHE-rs](#working-with-tfhe-rs)**
+   - [Disclaimers](#disclaimers)
+   - [Citations](#citations)
+   - [Contributing](#contributing)
+   - [License](#license)
+- **[Support](#support)**
+<br></br>
+
+## Getting started
+
+### Cargo.toml configuration
+To use the latest version of `TFHE-rs` in your project, you first need to add it as a dependency in your `Cargo.toml`:
+
++ For x86_64-based machines running Unix-like OSes:
+
+```toml
+tfhe = { version = "*", features = ["boolean", "shortint", "integer", "x86_64-unix"] }
+```
+
++ For Apple Silicon or aarch64-based machines running Unix-like OSes:
+
+```toml
+tfhe = { version = "*", features = ["boolean", "shortint", "integer", "aarch64-unix"] }
+```
+
++ For x86_64-based machines with the [`rdseed instruction`](https://en.wikipedia.org/wiki/RDRAND) running Windows:
+
+```toml
+tfhe = { version = "*", features = ["boolean", "shortint", "integer", "x86_64"] }
+```
+
+> [!Note]
+> Note: You need to use a Rust version >= 1.73 to compile TFHE-rs.
+
+> [!Note]
+> Note: aarch64-based machines are not yet supported for Windows as it's currently missing an entropy source to be able to seed the [CSPRNGs](https://en.wikipedia.org/wiki/Cryptographically_secure_pseudorandom_number_generator) used in TFHE-rs.
+
+<p align="right">
+  <a href="#about" > ↑ Back to top </a> 
+</p>
+
+### A simple example
+
+Here is a full example:
+
+``` rust
+use tfhe::prelude::*;
+use tfhe::{generate_keys, set_server_key, ConfigBuilder, FheUint32, FheUint8};
+
+fn main() -> Result<(), Box<dyn std::error::Error>> {
+    // Basic configuration to use homomorphic integers
+    let config = ConfigBuilder::default().build();
+
+    // Key generation
+    let (client_key, server_keys) = generate_keys(config);
+
+    let clear_a = 1344u32;
+    let clear_b = 5u32;
+    let clear_c = 7u8;
+
+    // Encrypting the input data using the (private) client_key
+    // FheUint32: Encrypted equivalent to u32
+    let mut encrypted_a = FheUint32::try_encrypt(clear_a, &client_key)?;
+    let encrypted_b = FheUint32::try_encrypt(clear_b, &client_key)?;
+
+    // FheUint8: Encrypted equivalent to u8
+    let encrypted_c = FheUint8::try_encrypt(clear_c, &client_key)?;
+
+    // On the server side:
+    set_server_key(server_keys);
+
+    // Clear equivalent computations: 1344 * 5 = 6720
+    let encrypted_res_mul = &encrypted_a * &encrypted_b;
+
+    // Clear equivalent computations: 6720 >> 5 = 210
+    encrypted_a = &encrypted_res_mul >> &encrypted_b;
+
+    // Clear equivalent computations: let casted_a = a as u8;
+    let casted_a: FheUint8 = encrypted_a.cast_into();
+
+    // Clear equivalent computations: min(210, 7) = 7
+    let encrypted_res_min = &casted_a.min(&encrypted_c);
+
+    // Operation between clear and encrypted data:
+    // Clear equivalent computations: 7 & 1 = 1
+    let encrypted_res = encrypted_res_min & 1_u8;
+
+    // Decrypting on the client side:
+    let clear_res: u8 = encrypted_res.decrypt(&client_key);
+    assert_eq!(clear_res, 1_u8);
+
+    Ok(())
+}
+```
+
+To run this code, use the following command: 
+<p align="center"> <code> cargo run --release </code> </p>
+
+> [!Note]
+> Note that when running code that uses `TFHE-rs`, it is highly recommended
+to run in release mode with cargo's `--release` flag to have the best performances possible.
+
+*Find an example with more explanations in [this part of the documentation](https://docs.zama.ai/tfhe-rs/get-started/quick_start)*
+
+<p align="right">
+  <a href="#about" > ↑ Back to top </a> 
+</p>
+
+
+
+## Resources 
+
+### TFHE deep dive
+- [TFHE Deep Dive - Part I - Ciphertext types](https://www.zama.ai/post/tfhe-deep-dive-part-1)
+- [TFHE Deep Dive - Part II - Encodings and linear leveled operations](https://www.zama.ai/post/tfhe-deep-dive-part-2)
+- [TFHE Deep Dive - Part III - Key switching and leveled multiplications](https://www.zama.ai/post/tfhe-deep-dive-part-3)
+- [TFHE Deep Dive - Part IV - Programmable Bootstrapping](https://www.zama.ai/post/tfhe-deep-dive-part-4)
+<br></br>
+
+### Tutorials
+- [[Video tutorial] Implement signed integers using TFHE-rs ](https://www.zama.ai/post/video-tutorial-implement-signed-integers-ssing-tfhe-rs)
+- [Homomorphic parity bit](https://docs.zama.ai/tfhe-rs/tutorials/parity_bit)
+- [Homomorphic case changing on Ascii string](https://docs.zama.ai/tfhe-rs/tutorials/ascii_fhe_string)
+- [Boolean SHA256 with TFHE-rs](https://www.zama.ai/post/boolean-sha256-tfhe-rs)
+- [Dark market with TFHE-rs](https://www.zama.ai/post/dark-market-tfhe-rs)
+- [Regular expression engine with TFHE-rs](https://www.zama.ai/post/regex-engine-tfhe-rs)
+
+*Explore more useful resources in [TFHE-rs tutorials](https://docs.zama.ai/tfhe-rs/tutorials) and [Awesome Zama repo](https://github.com/zama-ai/awesome-zama)*
+<br></br>
+### Documentation
+
+Full, comprehensive documentation is available here: [https://docs.zama.ai/tfhe-rs](https://docs.zama.ai/tfhe-rs).
+<p align="right">
+  <a href="#about" > ↑ Back to top </a> 
+</p>
+
+
+## Working with TFHE-rs
+
+### Disclaimers
+
+#### Security estimation
+
+Security estimations are done using the
+[Lattice Estimator](https://github.com/malb/lattice-estimator)
+with `red_cost_model = reduction.RC.BDGL16`.
+
+When a new update is published in the Lattice Estimator, we update parameters accordingly.
+
+### Security model
+
+The default parameters for the TFHE-rs library are chosen considering the IND-CPA security model, and are selected with a bootstrapping failure probability fixed at p_error = $2^{-64}$. In particular, it is assumed that the results of decrypted computations are not shared by the secret key owner with any third parties, as such an action can lead to leakage of the secret encryption key. If you are designing an application where decryptions must be shared, you will need to craft custom encryption parameters which are chosen in consideration of the IND-CPA^D security model [1]. 
+
+[1] Li, Baiyu, et al. "Securing approximate homomorphic encryption using differential privacy." Annual International Cryptology Conference. Cham: Springer Nature Switzerland, 2022. https://eprint.iacr.org/2022/816.pdf
+
+#### Side-channel attacks
+
+Mitigation for side-channel attacks has not yet been implemented in TFHE-rs,
+and will be released in upcoming versions.
+<br></br>
+
+### Citations
+To cite TFHE-rs in academic papers, please use the following entry:
+
+```text
+@Misc{TFHE-rs,
+  title={{TFHE-rs: A Pure Rust Implementation of the TFHE Scheme for Boolean and Integer Arithmetics Over Encrypted Data}},
+  author={Zama},
+  year={2022},
+  note={\url{https://github.com/zama-ai/tfhe-rs}},
+}
+```
+
+### Contributing
+
+There are two ways to contribute to TFHE-rs:
+
+- [Open issues](https://github.com/zama-ai/tfhe-rs/issues/new/choose) to report bugs and typos, or to suggest new ideas
+- Request to become an official contributor by emailing [hello@zama.ai](mailto:hello@zama.ai).
+
+Becoming an approved contributor involves signing our Contributor License Agreement (CLA). Only approved contributors can send pull requests, so please make sure to get in touch before you do!
+<br></br>
+
+### License
+This software is distributed under the **BSD-3-Clause-Clear** license. Read [this](LICENSE) for more details.
+
+#### FAQ
+**Is Zama’s technology free to use?**
+>Zama’s libraries are free to use under the BSD 3-Clause Clear license only for development, research, prototyping, and experimentation purposes. However, for any commercial use of Zama's open source code, companies must purchase Zama’s commercial patent license.
+>
+>Everything we do is open source and we are very transparent on what it means for our users, you can read more about how we monetize our open source products at Zama in [this blogpost](https://www.zama.ai/post/open-source).
+
+**What do I need to do if I want to use Zama’s technology for commercial purposes?**
+>To commercially use Zama’s technology you need to be granted Zama’s patent license. Please contact us hello@zama.ai for more information.
+
+**Do you file IP on your technology?**
+>Yes, all Zama’s technologies are patented.
+
+**Can you customize a solution for my specific use case?**
+>We are open to collaborating and advancing the FHE space with our partners. If you have specific needs, please email us at hello@zama.ai.
+
+<p align="right">
+  <a href="#about" > ↑ Back to top </a> 
+</p>
+
+
+## Support
+
+<a target="_blank" href="https://community.zama.ai">
+<picture>
+  <source media="(prefers-color-scheme: dark)" srcset="https://github.com/zama-ai/tfhe-rs/assets/157474013/08656d0a-3f44-4126-b8b6-8c601dff5380">
+  <source media="(prefers-color-scheme: light)" srcset="https://github.com/zama-ai/tfhe-rs/assets/157474013/1c9c9308-50ac-4aab-a4b9-469bb8c536a4">
+  <img alt="Support">
+</picture>
+</a>
+
+🌟 If you find this project helpful or interesting, please consider giving it a star on GitHub! Your support helps to grow the community and motivates further development. 
+
+<p align="right">
+  <a href="#about" > ↑ Back to top </a> 
+</p>
\ No newline at end of file
diff --git a/format.sh b/format.sh
new file mode 100755
index 00000000..5de67e5d
--- /dev/null
+++ b/format.sh
@@ -0,0 +1,21 @@
+#!/bin/bash
+
+# Get the list of modified files (excluding deleted files)
+modified_files=$(git diff --name-only --diff-filter=ACM)
+
+# Filter out only the Rust files
+rust_files=$(echo "$modified_files" | grep '\.rs$')
+
+# Check if there are any Rust files to format
+if [ -z "$rust_files" ]; then
+  echo "No modified Rust files to format."
+  exit 0
+fi
+
+# Apply cargo fmt to each Rust file
+for file in $rust_files; do
+  echo "Formatting $file"
+  rustfmt $file
+done
+
+echo "Formatting complete."
\ No newline at end of file
diff --git a/params/boolean/.gitignore b/params/boolean/.gitignore
new file mode 100644
index 00000000..c96a04f0
--- /dev/null
+++ b/params/boolean/.gitignore
@@ -0,0 +1,2 @@
+*
+!.gitignore
\ No newline at end of file
diff --git a/params/shortint/.gitignore b/params/shortint/.gitignore
new file mode 100644
index 00000000..c96a04f0
--- /dev/null
+++ b/params/shortint/.gitignore
@@ -0,0 +1,2 @@
+*
+!.gitignore
\ No newline at end of file
diff --git a/tfhe/Cargo.toml b/tfhe/Cargo.toml
index eb210f10..196678bd 100644
--- a/tfhe/Cargo.toml
+++ b/tfhe/Cargo.toml
@@ -41,9 +41,9 @@ libm = "0.2.6"
 test-case = "3.1.0"
 combine = "4.6.6"
 env_logger = "0.10.0"
-log = "0.4.19"
 hex = "0.4.3"
 # End regex-engine deps
+proc-macro2 = "=1.0.79"
 # Used for backward compatibility test metadata
 ron = "0.8"
 tfhe-backward-compat-data = { git = "https://github.com/zama-ai/tfhe-backward-compat-data.git", branch = "v0.2", default-features = false, features = [
@@ -52,6 +52,7 @@ tfhe-backward-compat-data = { git = "https://github.com/zama-ai/tfhe-backward-co
 
 [build-dependencies]
 cbindgen = { version = "0.26.0", optional = true }
+bindgen = "*"
 
 [dependencies]
 concrete-csprng = { version = "0.4.1", path = "../concrete-csprng", features = [
@@ -65,9 +66,10 @@ bincode = "1.3.3"
 concrete-fft = { version = "0.5.1", features = ["serde", "fft128"] }
 concrete-ntt = { version = "0.2.0" }
 pulp = "0.18.22"
-tfhe-cuda-backend = { version = "0.4.1", path = "../backends/tfhe-cuda-backend", optional = true }
+#tfhe-cuda-backend = { version = "0.4.1", path = "../backends/tfhe-cuda-backend", optional = true }
 aligned-vec = { version = "0.5", features = ["serde"] }
-dyn-stack = { version = "0.10" }
+dyn-stack  = { version = "0.10" }
+log = "0.4.19"
 paste = "1.0.7"
 fs2 = { version = "0.4.3", optional = true }
 # Used for OPRF in shortint
@@ -78,6 +80,8 @@ rand_core = { version = "0.6.4", features = ["std"] }
 tfhe-zk-pok = { version = "0.3.0", path = "../tfhe-zk-pok", optional = true }
 tfhe-versionable = { version = "0.3.0", path = "../utils/tfhe-versionable" }
 
+num-integer = "0.1.45"
+toml = "0.7.5"
 # wasm deps
 wasm-bindgen = { version = ">=0.2.86,<0.2.94", features = [
     "serde-serialize",
@@ -90,11 +94,14 @@ getrandom = { version = "0.2.8", optional = true }
 bytemuck = "1.14.3"
 
 [features]
+default = ["boolean", "integer", "seeder_unix", "fpga"]
 boolean = []
 shortint = ["dep:sha3"]
 integer = ["shortint"]
 internal-keycache = ["dep:lazy_static", "dep:fs2"]
-gpu = ["dep:tfhe-cuda-backend"]
+gpu = []
+fpga = []
+emulate_fpga = []
 zk-pok = ["dep:tfhe-zk-pok"]
 
 pbs-stats = []
@@ -157,7 +164,7 @@ aarch64-unix = ["aarch64", "seeder_unix"]
 
 [package.metadata.docs.rs]
 # TODO: manage builds for docs.rs based on their documentation https://docs.rs/about
-features = ["x86_64-unix", "boolean", "shortint", "integer", "gpu", "zk-pok"]
+features = ["x86_64-unix", "boolean", "shortint", "integer"]
 rustdoc-args = ["--html-in-header", "katex-header.html"]
 
 ###########
@@ -258,6 +265,24 @@ path = "benches/utilities.rs"
 harness = false
 required-features = ["boolean", "shortint", "integer", "internal-keycache"]
 
+[[bench]]
+name = "fpga-integer"
+path = "benches/fpga/integer.rs"
+harness = false
+required-features = ["integer", "shortint", "boolean", "fpga", "internal-keycache"]
+
+[[bench]]
+name = "fpga-throughput"
+path = "benches/fpga/throughput.rs"
+harness = false
+required-features = ["shortint", "boolean", "fpga", "internal-keycache"]
+
+[[bench]]
+name = "fpga-kspbs"
+path = "benches/fpga/kspbs.rs"
+harness = false
+required-features =  ["shortint", "boolean", "fpga", "internal-keycache"]
+
 # Examples used as tools
 
 [[example]]
diff --git a/tfhe/benches/fpga/integer.rs b/tfhe/benches/fpga/integer.rs
new file mode 100644
index 00000000..08fb1850
--- /dev/null
+++ b/tfhe/benches/fpga/integer.rs
@@ -0,0 +1,622 @@
+#![allow(dead_code)]
+
+use criterion::{criterion_group, Criterion};
+use itertools::iproduct;
+use rand::prelude::*;
+use std::env;
+use std::vec::IntoIter;
+use tfhe::integer::bigint::StaticUnsignedBigInt;
+use tfhe::integer::fpga::BelfortServerKey;
+use tfhe::integer::keycache::KEY_CACHE;
+use tfhe::integer::{IntegerKeyKind, RadixCiphertext, U256};
+use tfhe::keycache::NamedParam;
+use tfhe::shortint::parameters::*;
+
+pub(crate) const NB_FPGA: usize = 1;
+
+type ScalarType = U256;
+
+fn gen_random_u256(rng: &mut ThreadRng) -> U256 {
+    let clearlow = rng.gen::<u128>();
+    let clearhigh = rng.gen::<u128>();
+
+    tfhe::integer::U256::from((clearlow, clearhigh))
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// An iterator that yields a succession of combinations of parameters and
+// a num_block to achieve a certain bit_size ciphertext in radix decomposition
+
+struct ParamsAndNumBlocksIter {
+    params_and_bit_sizes:
+        itertools::Product<IntoIter<tfhe::shortint::PBSParameters>, IntoIter<usize>>,
+}
+
+impl Default for ParamsAndNumBlocksIter {
+    fn default() -> Self {
+        const DEFAULT_BENCH_BIT_SIZES: [usize; 3] = [8, 32, 64];
+
+        let params = vec![PARAM_MESSAGE_2_CARRY_2_KS_PBS.into()];
+
+        let params_and_bit_sizes = iproduct!(params, DEFAULT_BENCH_BIT_SIZES.to_vec());
+        Self {
+            params_and_bit_sizes,
+        }
+    }
+}
+
+impl Iterator for ParamsAndNumBlocksIter {
+    type Item = (tfhe::shortint::PBSParameters, usize, usize);
+
+    fn next(&mut self) -> Option<Self::Item> {
+        let (param, bit_size) = self.params_and_bit_sizes.next()?;
+        let num_block =
+            (bit_size as f64 / (param.message_modulus().0 as f64).log(2.0)).ceil() as usize;
+
+        Some((param, num_block, bit_size))
+    }
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// Bench implementations
+
+fn bench_fpga_key_univariate_function_clean_inputs<F>(c: &mut Criterion, bench_name: &str, un_fn: F)
+where
+    F: Fn(&BelfortServerKey, &mut RadixCiphertext),
+{
+    let mut bench_group = c.benchmark_group(bench_name);
+    bench_group
+        .sample_size(15)
+        .measurement_time(std::time::Duration::from_secs(60));
+
+    let mut rng = rand::thread_rng();
+
+    for (param, num_block, bit_size) in ParamsAndNumBlocksIter::default() {
+        let param_name = param.name();
+
+        let (cks, sks) = KEY_CACHE.get_from_params(param, IntegerKeyKind::Radix);
+
+        let mut fpga_key = BelfortServerKey::from(&sks);
+        fpga_key.connect(NB_FPGA);
+
+        let bench_id = format!("{bench_name}::{param_name}::{bit_size}_bits");
+        bench_group.bench_function(&bench_id, |b| {
+            let encrypt_one_value = || {
+                let clear_0 = gen_random_u256(&mut rng);
+
+                cks.encrypt_radix(clear_0, num_block)
+            };
+
+            b.iter_batched(
+                encrypt_one_value,
+                |mut ct_0| {
+                    un_fn(&fpga_key, &mut ct_0);
+                },
+                criterion::BatchSize::SmallInput,
+            )
+        });
+
+        fpga_key.disconnect();
+    }
+
+    bench_group.finish()
+}
+
+fn bench_fpga_key_bivariate_function_clean_inputs<F>(
+    c: &mut Criterion,
+    bench_name: &str,
+    binary_op: F,
+) where
+    F: Fn(&BelfortServerKey, &mut RadixCiphertext, &mut RadixCiphertext),
+{
+    let mut bench_group = c.benchmark_group(bench_name);
+    bench_group
+        .sample_size(15)
+        .measurement_time(std::time::Duration::from_secs(60));
+    let mut rng = rand::thread_rng();
+
+    for (param, num_block, bit_size) in ParamsAndNumBlocksIter::default() {
+        let param_name = param.name();
+
+        let (cks, sks) = KEY_CACHE.get_from_params(param, IntegerKeyKind::Radix);
+        let mut fpga_key = BelfortServerKey::from(&sks);
+        fpga_key.connect(NB_FPGA);
+
+        let bench_id = format!("{bench_name}::{param_name}::{bit_size}_bits");
+        bench_group.bench_function(&bench_id, |b| {
+            let encrypt_two_values = || {
+                let clear_0 = gen_random_u256(&mut rng);
+                let clear_1 = gen_random_u256(&mut rng);
+
+                let ct_0 = cks.encrypt_radix(clear_0, num_block);
+                let ct_1 = cks.encrypt_radix(clear_1, num_block);
+
+                (ct_0, ct_1)
+            };
+
+            b.iter_batched(
+                encrypt_two_values,
+                |(mut ct_0, mut ct_1)| {
+                    binary_op(&fpga_key, &mut ct_0, &mut ct_1);
+                },
+                criterion::BatchSize::SmallInput,
+            )
+        });
+
+        fpga_key.disconnect();
+    }
+
+    bench_group.finish()
+}
+
+fn bench_fpga_key_bivariate_scalar_function_clean_inputs<F>(
+    c: &mut Criterion,
+    bench_name: &str,
+    binary_op: F,
+) where
+    F: Fn(&BelfortServerKey, &mut RadixCiphertext, ScalarType),
+{
+    let mut bench_group = c.benchmark_group(bench_name);
+    bench_group
+        .sample_size(15)
+        .measurement_time(std::time::Duration::from_secs(60));
+    let mut rng = rand::thread_rng();
+
+    for (param, num_block, bit_size) in ParamsAndNumBlocksIter::default() {
+        if bit_size > ScalarType::BITS as usize {
+            break;
+        }
+        let param_name = param.name();
+
+        let (cks, sks) = KEY_CACHE.get_from_params(param, IntegerKeyKind::Radix);
+
+        let mut fpga_key = BelfortServerKey::from(&sks);
+        fpga_key.connect(NB_FPGA);
+
+        let max_value_for_bit_size = ScalarType::MAX >> (ScalarType::BITS as usize - bit_size);
+
+        let bench_id = format!("{bench_name}::{param_name}::{bit_size}_bits_scalar_{bit_size}");
+        bench_group.bench_function(&bench_id, |b| {
+            let encrypt_one_value = || {
+                let clear_0 = gen_random_u256(&mut rng);
+                let clear_1 = gen_random_u256(&mut rng) & max_value_for_bit_size;
+
+                let ct_0 = cks.encrypt_radix(clear_0, num_block);
+
+                (ct_0, clear_1)
+            };
+
+            b.iter_batched(
+                encrypt_one_value,
+                |(mut ct_0, clear_1)| {
+                    binary_op(&fpga_key, &mut ct_0, clear_1);
+                },
+                criterion::BatchSize::SmallInput,
+            )
+        });
+
+        fpga_key.disconnect();
+    }
+
+    bench_group.finish()
+}
+
+fn bench_fpga_key_univariate_function_dirty_inputs<F>(c: &mut Criterion, bench_name: &str, un_fn: F)
+where
+    F: Fn(&BelfortServerKey, &mut RadixCiphertext),
+{
+    let mut bench_group = c.benchmark_group(bench_name);
+    bench_group
+        .sample_size(15)
+        .measurement_time(std::time::Duration::from_secs(60));
+
+    let mut rng = rand::thread_rng();
+
+    for (param, num_block, bit_size) in ParamsAndNumBlocksIter::default() {
+        let param_name = param.name();
+        let (cks, sks) = KEY_CACHE.get_from_params(param, IntegerKeyKind::Radix);
+
+        let mut fpga_key = BelfortServerKey::from(&sks);
+        fpga_key.connect(NB_FPGA);
+
+        let bench_id = format!("{bench_name}::{param_name}::{bit_size}_bits");
+        bench_group.bench_function(&bench_id, |b| {
+            let encrypt_one_value = || {
+                let clear_0 = gen_random_u256(&mut rng);
+                let mut ct_0 = cks.encrypt_radix(clear_0, num_block);
+
+                // Raise the degree, so as to ensure worst case path in operations
+                let mut carry_mod = param.carry_modulus().0;
+                while carry_mod > 0 {
+                    // Raise the degree, so as to ensure worst case path in operations
+                    let clear_2 = gen_random_u256(&mut rng);
+                    let ct_2 = cks.encrypt_radix(clear_2, num_block);
+                    fpga_key.unchecked_add_assign(&mut ct_0, &ct_2);
+
+                    carry_mod -= 1;
+                }
+
+                ct_0
+            };
+
+            b.iter_batched(
+                encrypt_one_value,
+                |mut ct_0| {
+                    un_fn(&fpga_key, &mut ct_0);
+                },
+                criterion::BatchSize::SmallInput,
+            )
+        });
+        fpga_key.disconnect();
+    }
+
+    bench_group.finish()
+}
+
+fn bench_fpga_key_bivariate_function_dirty_inputs<F>(
+    c: &mut Criterion,
+    bench_name: &str,
+    binary_op: F,
+) where
+    F: Fn(&BelfortServerKey, &mut RadixCiphertext, &mut RadixCiphertext),
+{
+    let mut bench_group = c.benchmark_group(bench_name);
+    bench_group
+        .sample_size(15)
+        .measurement_time(std::time::Duration::from_secs(60));
+    let mut rng = rand::thread_rng();
+
+    for (param, num_block, bit_size) in ParamsAndNumBlocksIter::default() {
+        let param_name = param.name();
+
+        let (cks, sks) = KEY_CACHE.get_from_params(param, IntegerKeyKind::Radix);
+        let mut fpga_key = BelfortServerKey::from(&sks);
+        fpga_key.connect(NB_FPGA);
+
+        let bench_id = format!("{bench_name}::{param_name}::{bit_size}_bits");
+        bench_group.bench_function(&bench_id, |b| {
+            let encrypt_two_values = || {
+                let clear_0 = gen_random_u256(&mut rng);
+                let clear_1 = gen_random_u256(&mut rng);
+
+                let mut ct_0 = cks.encrypt_radix(clear_0, num_block);
+                let mut ct_1 = cks.encrypt_radix(clear_1, num_block);
+
+                // Raise the degree, so as to ensure worst case path in operations
+                let mut carry_mod = param.carry_modulus().0;
+                while carry_mod > 0 {
+                    // Raise the degree, so as to ensure worst case path in operations
+                    let clear_2 = gen_random_u256(&mut rng);
+                    let ct_2 = cks.encrypt_radix(clear_2, num_block);
+                    fpga_key.unchecked_add_assign(&mut ct_0, &ct_2);
+                    fpga_key.unchecked_add_assign(&mut ct_1, &ct_2);
+
+                    carry_mod -= 1;
+                }
+
+                (ct_0, ct_1)
+            };
+
+            b.iter_batched(
+                encrypt_two_values,
+                |(mut ct_0, mut ct_1)| {
+                    binary_op(&fpga_key, &mut ct_0, &mut ct_1);
+                },
+                criterion::BatchSize::SmallInput,
+            )
+        });
+
+        fpga_key.disconnect();
+    }
+
+    bench_group.finish()
+}
+
+fn bench_fpga_key_bivariate_scalar_function_dirty_inputs<F>(
+    c: &mut Criterion,
+    bench_name: &str,
+    binary_op: F,
+) where
+    F: Fn(&BelfortServerKey, &mut RadixCiphertext, ScalarType),
+{
+    let mut bench_group = c.benchmark_group(bench_name);
+    bench_group
+        .sample_size(15)
+        .measurement_time(std::time::Duration::from_secs(60));
+    let mut rng = rand::thread_rng();
+
+    for (param, num_block, bit_size) in ParamsAndNumBlocksIter::default() {
+        let param_name = param.name();
+        let (cks, sks) = KEY_CACHE.get_from_params(param, IntegerKeyKind::Radix);
+
+        let mut fpga_key = BelfortServerKey::from(&sks);
+        fpga_key.connect(NB_FPGA);
+
+        let max_value_for_bit_size = ScalarType::MAX >> (ScalarType::BITS as usize - bit_size);
+
+        let bench_id = format!("{bench_name}::{param_name}::{bit_size}_bits");
+        bench_group.bench_function(&bench_id, |b| {
+            let encrypt_one_value = || {
+                let clear_0 = gen_random_u256(&mut rng);
+                let mut ct_0 = cks.encrypt_radix(clear_0, num_block);
+
+                // Raise the degree, so as to ensure worst case path in operations
+                let mut carry_mod = param.carry_modulus().0;
+                while carry_mod > 0 {
+                    // Raise the degree, so as to ensure worst case path in operations
+                    let clearlow = rng.gen::<u128>();
+                    let clearhigh = rng.gen::<u128>();
+                    let clear_2 = tfhe::integer::U256::from((clearlow, clearhigh));
+                    let ct_2 = cks.encrypt_radix(clear_2, num_block);
+                    fpga_key.unchecked_add_assign(&mut ct_0, &ct_2);
+
+                    carry_mod -= 1;
+                }
+
+                let clear_1 = gen_random_u256(&mut rng) & max_value_for_bit_size;
+
+                (ct_0, clear_1)
+            };
+
+            b.iter_batched(
+                encrypt_one_value,
+                |(mut ct_0, clear_1)| {
+                    binary_op(&fpga_key, &mut ct_0, clear_1);
+                },
+                criterion::BatchSize::SmallInput,
+            )
+        });
+
+        fpga_key.disconnect();
+    }
+
+    bench_group.finish()
+}
+
+fn bench_if_then_else(c: &mut Criterion) {
+    let bench_name = "integer::fpga::if_then_else";
+
+    let mut bench_group = c.benchmark_group(bench_name);
+    bench_group
+        .sample_size(15)
+        .measurement_time(std::time::Duration::from_secs(60));
+    let mut rng = rand::thread_rng();
+
+    for (param, num_block, bit_size) in ParamsAndNumBlocksIter::default() {
+        let param_name = param.name();
+
+        let (cks, sks) = KEY_CACHE.get_from_params(param, IntegerKeyKind::Radix);
+
+        let mut fpga_key = BelfortServerKey::from(&sks);
+        fpga_key.connect(NB_FPGA);
+
+        let bench_id = format!("{bench_name}::{param_name}::{bit_size}_bits");
+        bench_group.bench_function(&bench_id, |b| {
+            let encrypt_tree_values = || {
+                let clear_0 = gen_random_u256(&mut rng);
+                let ct_0 = cks.encrypt_radix(clear_0, num_block);
+
+                let clear_1 = gen_random_u256(&mut rng);
+                let ct_1 = cks.encrypt_radix(clear_1, num_block);
+
+                let cond = sks.create_trivial_boolean_block(rng.gen_bool(0.5));
+
+                (cond, ct_0, ct_1)
+            };
+
+            b.iter_batched(
+                encrypt_tree_values,
+                |(condition, true_ct, false_ct)| {
+                    fpga_key.if_then_else(&condition, &true_ct, &false_ct)
+                },
+                criterion::BatchSize::SmallInput,
+            )
+        });
+
+        fpga_key.disconnect();
+    }
+
+    bench_group.finish()
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// Bench definition macros
+
+macro_rules! bench_univariate_fn_with_clean_inputs (
+    ($method:ident) => {
+        fn $method(c: &mut Criterion) {
+            bench_fpga_key_univariate_function_clean_inputs(
+                c,
+                concat!("integer::fpga::", stringify!($method)),
+                |fpga_key, lhs| { fpga_key.$method(lhs); }
+            );
+        }
+    }
+);
+
+macro_rules! bench_bivariate_fn_with_clean_inputs (
+    ($method:ident) => {
+        fn $method(c: &mut Criterion) {
+            bench_fpga_key_bivariate_function_clean_inputs(
+                c,
+                concat!("integer::fpga::", stringify!($method)),
+                |fpga_key, lhs, rhs| {fpga_key.$method(lhs, rhs); }
+            );
+        }
+    }
+);
+
+macro_rules! bench_scalar_bivariate_fn_with_clean_inputs (
+    ($method:ident) => {
+        fn $method(c: &mut Criterion) {
+            bench_fpga_key_bivariate_scalar_function_clean_inputs(
+                c,
+                concat!("integer::fpga::", stringify!($method)),
+                |fpga_key, lhs, rhs| {fpga_key.$method(lhs, rhs); }
+            );
+        }
+    }
+);
+
+macro_rules! bench_univariate_fn_with_dirty_inputs (
+    ($method:ident) => {
+        fn $method(c: &mut Criterion) {
+            bench_fpga_key_univariate_function_dirty_inputs(
+                c,
+                concat!("integer::fpga::", stringify!($method)),
+                |fpga_key, lhs| { fpga_key.$method(lhs); }
+            );
+        }
+    }
+);
+
+macro_rules! bench_bivariate_fn_with_dirty_inputs (
+    ($method:ident) => {
+        fn $method(c: &mut Criterion) {
+            bench_fpga_key_bivariate_function_dirty_inputs(
+                c,
+                concat!("integer::fpga::", stringify!($method)),
+                |fpga_key, lhs, rhs| {fpga_key.$method(lhs, rhs); }
+            );
+        }
+    }
+);
+
+macro_rules! bench_scalar_bivariate_fn_with_dirty_inputs (
+    ($method:ident) => {
+        fn $method(c: &mut Criterion) {
+            bench_fpga_key_bivariate_scalar_function_dirty_inputs(
+                c,
+                concat!("integer::fpga::", stringify!($method)),
+                |fpga_key, lhs, rhs| {fpga_key.$method(lhs, rhs); }
+            );
+        }
+    }
+);
+
+////////////////////////////////////////////////////////////////////////////////
+// Benches for Default Ops
+
+bench_univariate_fn_with_dirty_inputs!(full_propagate);
+
+bench_bivariate_fn_with_clean_inputs!(add);
+bench_bivariate_fn_with_clean_inputs!(sub);
+bench_univariate_fn_with_clean_inputs!(neg);
+bench_bivariate_fn_with_clean_inputs!(mul);
+bench_bivariate_fn_with_clean_inputs!(div_rem);
+
+bench_bivariate_fn_with_clean_inputs!(eq);
+bench_bivariate_fn_with_clean_inputs!(ne);
+bench_bivariate_fn_with_clean_inputs!(gt);
+bench_bivariate_fn_with_clean_inputs!(ge);
+bench_bivariate_fn_with_clean_inputs!(lt);
+bench_bivariate_fn_with_clean_inputs!(le);
+bench_bivariate_fn_with_clean_inputs!(max);
+bench_bivariate_fn_with_clean_inputs!(min);
+
+bench_bivariate_fn_with_clean_inputs!(bitand);
+bench_bivariate_fn_with_clean_inputs!(bitor);
+bench_bivariate_fn_with_clean_inputs!(bitxor);
+bench_univariate_fn_with_clean_inputs!(bitnot);
+
+bench_bivariate_fn_with_clean_inputs!(right_shift);
+bench_bivariate_fn_with_clean_inputs!(left_shift);
+bench_bivariate_fn_with_clean_inputs!(rotate_right);
+bench_bivariate_fn_with_clean_inputs!(rotate_left);
+
+bench_univariate_fn_with_clean_inputs!(leading_zeros);
+bench_univariate_fn_with_clean_inputs!(leading_ones);
+bench_univariate_fn_with_clean_inputs!(trailing_zeros);
+bench_univariate_fn_with_clean_inputs!(trailing_ones);
+
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_add);
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_sub);
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_mul);
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_eq);
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_ne);
+
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_bitand);
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_bitor);
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_bitxor);
+
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_right_shift);
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_left_shift);
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_rotate_right);
+bench_scalar_bivariate_fn_with_clean_inputs!(scalar_rotate_left);
+
+////////////////////////////////////////////////////////////////////////////////
+// Benches for Smart Ops
+
+bench_bivariate_fn_with_dirty_inputs!(smart_add);
+bench_bivariate_fn_with_dirty_inputs!(smart_sub);
+bench_univariate_fn_with_dirty_inputs!(smart_neg);
+bench_bivariate_fn_with_dirty_inputs!(smart_div_rem);
+
+bench_bivariate_fn_with_dirty_inputs!(smart_eq);
+bench_bivariate_fn_with_dirty_inputs!(smart_ne);
+bench_bivariate_fn_with_dirty_inputs!(smart_gt);
+bench_bivariate_fn_with_dirty_inputs!(smart_ge);
+bench_bivariate_fn_with_dirty_inputs!(smart_lt);
+bench_bivariate_fn_with_dirty_inputs!(smart_le);
+bench_bivariate_fn_with_dirty_inputs!(smart_max);
+bench_bivariate_fn_with_dirty_inputs!(smart_min);
+
+bench_bivariate_fn_with_dirty_inputs!(smart_bitand);
+bench_bivariate_fn_with_dirty_inputs!(smart_bitor);
+bench_bivariate_fn_with_dirty_inputs!(smart_bitxor);
+
+bench_bivariate_fn_with_dirty_inputs!(smart_right_shift);
+bench_bivariate_fn_with_dirty_inputs!(smart_left_shift);
+bench_bivariate_fn_with_dirty_inputs!(smart_rotate_right);
+bench_bivariate_fn_with_dirty_inputs!(smart_rotate_left);
+
+bench_scalar_bivariate_fn_with_dirty_inputs!(smart_scalar_add);
+bench_scalar_bivariate_fn_with_dirty_inputs!(smart_scalar_sub);
+bench_scalar_bivariate_fn_with_dirty_inputs!(smart_scalar_mul);
+bench_scalar_bivariate_fn_with_dirty_inputs!(smart_scalar_eq);
+bench_scalar_bivariate_fn_with_dirty_inputs!(smart_scalar_ne);
+
+bench_scalar_bivariate_fn_with_dirty_inputs!(smart_scalar_bitand);
+bench_scalar_bivariate_fn_with_dirty_inputs!(smart_scalar_bitor);
+bench_scalar_bivariate_fn_with_dirty_inputs!(smart_scalar_bitxor);
+
+bench_scalar_bivariate_fn_with_dirty_inputs!(smart_scalar_rotate_right);
+bench_scalar_bivariate_fn_with_dirty_inputs!(smart_scalar_rotate_left);
+
+////////////////////////////////////////////////////////////////////////////////
+// Benchmark Groups
+
+criterion_group!(default_addsub_ops, add, sub);
+criterion_group!(smart_addsub_ops, smart_add, smart_sub);
+
+criterion_group!(misc_ops, full_propagate);
+
+////////////////////////////////////////////////////////////////////////////////
+
+fn go_through_fpga_bench_groups(val: &str) {
+    match val.to_lowercase().as_str() {
+        "default" => {
+            default_addsub_ops();
+        }
+        "smart" => {
+            smart_addsub_ops();
+        }
+        "misc" => {
+            misc_ops();
+        }
+        _ => {
+            panic!("unknown benchmark operations flavor");
+        }
+    };
+}
+
+fn main() {
+    match env::var("__TFHE_RS_BENCH_OP_FLAVOR") {
+        Ok(val) => {
+            go_through_fpga_bench_groups(&val);
+        }
+        Err(_) => {}
+    };
+
+    Criterion::default().configure_from_args().final_summary();
+}
diff --git a/tfhe/benches/fpga/kspbs.rs b/tfhe/benches/fpga/kspbs.rs
new file mode 100644
index 00000000..71e423ac
--- /dev/null
+++ b/tfhe/benches/fpga/kspbs.rs
@@ -0,0 +1,115 @@
+use criterion::{black_box, criterion_group, Criterion};
+
+use tfhe::core_crypto::fpga::keyswitch_bootstrap::SkippedSlots;
+use tfhe::core_crypto::fpga::utils::Connect;
+use tfhe::core_crypto::fpga::BelfortFpgaUtils;
+use tfhe::keycache::NamedParam;
+
+use tfhe::boolean::ciphertext::Ciphertext as BooleanCiphertext;
+use tfhe::boolean::client_key::ClientKey as BooleanClientKey;
+use tfhe::boolean::parameters::{BooleanParameters, DEFAULT_PARAMETERS_KS_PBS};
+use tfhe::boolean::server_key::ServerKey as BooleanServerKey;
+
+use tfhe::shortint::ciphertext::Ciphertext as ShortintCiphertext;
+use tfhe::shortint::client_key::ClientKey as ShortintClientKey;
+use tfhe::shortint::parameters::{ClassicPBSParameters, PARAM_MESSAGE_2_CARRY_2_KS_PBS};
+use tfhe::shortint::server_key::ServerKey as ShortintServerKey;
+
+fn bench_boolean_kspbs(
+    c: &mut Criterion,
+    params: BooleanParameters,
+    pack_size: usize,
+    fpga_count: usize,
+) {
+    let mut bench_group = c.benchmark_group("fpga::kspbs");
+
+    let params_name = params.name();
+
+    let cks = BooleanClientKey::new(&params);
+    let sks = BooleanServerKey::new(&cks);
+
+    let mut fpga_utils = BelfortFpgaUtils::from(params);
+
+    fpga_utils.connect(&sks, fpga_count);
+
+    let mut ciphertexts: Vec<BooleanCiphertext> =
+        (0..pack_size).map(|_| cks.encrypt(true)).collect();
+    let luts: Vec<usize> = (0..pack_size).map(|_| 0).collect();
+
+    let sizes = fpga_utils.bench_calculate_sizes(ciphertexts.len());
+    let mut skip_indexes = Vec::<SkippedSlots>::new();
+
+    let id = format!("{params_name}::FpgaCount{fpga_count}::PackSize{pack_size}::pre-process");
+    bench_group.bench_function(&id, |b| {
+        b.iter(|| {
+            black_box(fpga_utils.bench_pre_boolean(&mut ciphertexts, &luts, &mut skip_indexes))
+        })
+    });
+
+    let id = format!("{params_name}::FpgaCount{fpga_count}::PackSize{pack_size}::interface");
+    bench_group.bench_function(&id, |b| {
+        b.iter(|| black_box(fpga_utils.bench_interface_fpga(&sizes)))
+    });
+
+    let id = format!("{params_name}::FpgaCount{fpga_count}::PackSize{pack_size}::post-process");
+    bench_group.bench_function(&id, |b| {
+        b.iter(|| {
+            black_box(fpga_utils.bench_post_boolean(&mut ciphertexts, &sizes, &mut skip_indexes))
+        })
+    });
+
+    fpga_utils.disconnect();
+}
+
+fn bench_shortint_kspbs(
+    c: &mut Criterion,
+    params: ClassicPBSParameters,
+    pack_size: usize,
+    fpga_count: usize,
+) {
+    let mut bench_group = c.benchmark_group("fpga::kspbs");
+
+    let params_name = params.name();
+
+    let cks = ShortintClientKey::new(params);
+    let sks = ShortintServerKey::new(&cks);
+
+    let mut fpga_utils = BelfortFpgaUtils::from(params);
+
+    fpga_utils.connect(&sks, fpga_count);
+
+    let mut ciphertexts: Vec<ShortintCiphertext> = (0..pack_size).map(|_| cks.encrypt(1)).collect();
+    let luts: Vec<usize> = (0..pack_size).map(|_| 1).collect();
+
+    let sizes = fpga_utils.bench_calculate_sizes(ciphertexts.len());
+
+    let id = format!("{params_name}::FpgaCount{fpga_count}::PackSize{pack_size}::pre-process");
+    bench_group.bench_function(&id, |b| {
+        b.iter(|| black_box(fpga_utils.bench_pre_shortint(&mut ciphertexts, &luts, &sizes)))
+    });
+
+    let id = format!("{params_name}::FpgaCount{fpga_count}::PackSize{pack_size}::interface");
+    bench_group.bench_function(&id, |b| {
+        b.iter(|| black_box(fpga_utils.bench_interface_fpga(&sizes)))
+    });
+
+    let id = format!(":{params_name}::FpgaCount{fpga_count}::PackSize{pack_size}::post-process");
+    bench_group.bench_function(&id, |b| {
+        b.iter(|| black_box(fpga_utils.bench_post_shortint(&mut ciphertexts, &sizes)))
+    });
+
+    fpga_utils.disconnect();
+}
+
+fn bench_kspbs(c: &mut Criterion) {
+    bench_boolean_kspbs(c, DEFAULT_PARAMETERS_KS_PBS, 12, 1);
+    bench_shortint_kspbs(c, PARAM_MESSAGE_2_CARRY_2_KS_PBS, 12, 1);
+}
+
+criterion_group!(fpga_kspbs, bench_kspbs);
+
+fn main() {
+    fpga_kspbs();
+
+    Criterion::default().configure_from_args().final_summary();
+}
diff --git a/tfhe/benches/fpga/throughput.py b/tfhe/benches/fpga/throughput.py
new file mode 100644
index 00000000..c3a57b3c
--- /dev/null
+++ b/tfhe/benches/fpga/throughput.py
@@ -0,0 +1,157 @@
+import os
+import json
+import matplotlib.pyplot as plt
+import numpy as np
+
+# Define global constants
+BENCH_OUTPUT_RELATIVE_PATH = '../../../target/criterion/fpga__throughput/'
+BASE_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), BENCH_OUTPUT_RELATIVE_PATH))
+
+# Extract parameter name, FPGA count, and pack size from folder names.
+def extract_info():
+  bench_results = []
+  
+  for folder_name in os.listdir(BASE_PATH):
+    sub_folder_path = os.path.join(BASE_PATH, folder_name)
+    if os.path.isdir(sub_folder_path) and '__FpgaCount' in folder_name and '__PackSize' in folder_name:
+      parts = folder_name.split('__')
+      parameter_name = '__'.join(parts[:-2])
+      fpga_count = parts[-2].replace('FpgaCount', '')
+      pack_size = parts[-1].replace('PackSize', '')
+      bench_results.append({
+        'parameter_name': parameter_name,
+        'fpga_count': fpga_count,
+        'pack_size': pack_size
+      })
+  
+  return bench_results
+
+# Group pack sizes by parameter name and FPGA count.
+def filter_and_list_pack_sizes(bench_results):
+  filtered_info = {}
+  for info in bench_results:
+    key = (info['parameter_name'], info['fpga_count'])
+    if key not in filtered_info:
+      filtered_info[key] = []
+    filtered_info[key].append(info['pack_size'])
+  return filtered_info
+
+# Extract median point estimate from a JSON file.
+def get_median_results(file_path):
+  try:
+    with open(file_path, 'r') as f:
+      data = json.load(f)
+    median_results = data.get('median', {})
+    return median_results.get('point_estimate', None) / 1000
+  except (FileNotFoundError, KeyError) as e:
+    print(f"Error reading {file_path}: {e}")
+    return None
+
+# Plot pack sizes vs. median results on both linear and log scales for X-axis, with a table of data on the right, for each parameter set.
+def plot_data(filtered_info):
+  
+  # Define a colormap for different FPGA counts
+  cmap = plt.colormaps.get_cmap('tab20')
+  
+  # Group by parameter name
+  parameter_groups = {}
+  for key, pack_sizes in filtered_info.items():
+    parameter_name, fpga_count = key
+    if parameter_name not in parameter_groups:
+      parameter_groups[parameter_name] = {}
+    parameter_groups[parameter_name][fpga_count] = pack_sizes
+
+  # Plot each parameter name
+  for parameter_name, fpga_data in parameter_groups.items():
+    plt.figure(figsize=(21, 7))  # Wider figure to accommodate the table
+
+    # Initialize subplots: Linear scale, Log scale, and Table
+    ax1 = plt.subplot(1, 3, 1)
+    ax2 = plt.subplot(1, 3, 2)
+    ax3 = plt.subplot(1, 3, 3)
+
+    # Collect data for the table
+    table_data = []
+    column_labels = ['Pack Size'] + [f'FPGA Count {fc}' for fc in sorted(fpga_data.keys())]
+    
+    # Collect unique pack sizes
+    all_pack_sizes = set()
+    for pack_sizes in fpga_data.values():
+      all_pack_sizes.update(pack_sizes)
+    all_pack_sizes = sorted(map(int, all_pack_sizes))
+    
+    # Create the table data structure
+    for pack_size in all_pack_sizes:
+      row = [pack_size]
+      for fpga_count in sorted(fpga_data.keys()):
+        json_file_path = os.path.join(BASE_PATH, f'{parameter_name}__FpgaCount{fpga_count}__PackSize{pack_size}/new/estimates.json')
+        median_point_estimate = get_median_results(json_file_path)
+        row.append(f'{median_point_estimate:.2f}' if median_point_estimate is not None else 'N/A')
+      table_data.append(row)
+
+    # Get list of colors from the colormap
+    fpga_count_len = len(fpga_data.keys())
+    colors = [cmap(i) for i in np.linspace(0, 1, fpga_count_len)]
+
+    # Plot each FPGA count
+    for idx, (fpga_count, pack_sizes) in enumerate(fpga_data.items()):
+      x = []
+      y = []
+      
+      for pack_size in pack_sizes:
+        json_file_path = os.path.join(BASE_PATH, f'{parameter_name}__FpgaCount{fpga_count}__PackSize{pack_size}/new/estimates.json')
+        
+        median_point_estimate = get_median_results(json_file_path)
+        if median_point_estimate is not None:
+          x.append(int(pack_size))
+          y.append(median_point_estimate)
+      
+      if x and y:
+        # Sort x and corresponding y
+        sorted_indices = sorted(range(len(x)), key=lambda i: x[i])
+        x_sorted = [x[i] for i in sorted_indices]
+        y_sorted = [y[i] for i in sorted_indices]
+
+        # Plot with linear X scale
+        ax1.plot(x_sorted, y_sorted, marker='o', linestyle='-', color=colors[idx], label=f'FPGA Count {fpga_count}')
+        ax1.set_xlabel('Pack Size')
+        ax1.set_ylabel('Median Result (us)')
+        ax1.set_title(f'{parameter_name} - Linear Scale')
+        ax1.grid(True)
+        ax1.legend()
+
+        # Plot with log X scale
+        ax2.plot(x_sorted, y_sorted, marker='o', linestyle='-', color=colors[idx], label=f'FPGA Count {fpga_count}')
+        ax2.set_xlabel('Pack Size')
+        ax2.set_ylabel('Median Result (us)')
+        ax2.set_title(f'{parameter_name} - Log Scale')
+        ax2.set_xscale('log')
+        ax2.grid(True)
+        ax2.legend()
+
+    # Add a table of data
+    ax3.axis('off')  # Hide the axis for the table subplot
+    table = ax3.table(cellText=table_data,
+                      colLabels=column_labels,
+                      cellLoc='center',
+                      loc='center',
+                      bbox=[0.05, 0.1, 0.9, 0.8])  # Adjust bbox for position and size
+    table.auto_set_font_size(False)
+    table.set_fontsize(8)
+
+    # Add table title
+    ax3.text(0.5, 1.05, 'KSPBS Execution Times (in us)',
+             ha='center', va='center', fontsize=10, weight='bold', transform=ax3.transAxes)
+
+    # Save the figure with plots for the parameter name
+    png_file_path = os.path.join(BASE_PATH, f'{parameter_name}.png')
+    plt.tight_layout()
+    plt.savefig(png_file_path)
+    plt.close()
+    print(f'Saved plot to {png_file_path}')
+
+# Main execution
+if __name__ == '__main__':
+  bench_results = extract_info()
+  filtered_info = filter_and_list_pack_sizes(bench_results)
+  plot_data(filtered_info)
diff --git a/tfhe/benches/fpga/throughput.rs b/tfhe/benches/fpga/throughput.rs
new file mode 100644
index 00000000..ad576629
--- /dev/null
+++ b/tfhe/benches/fpga/throughput.rs
@@ -0,0 +1,111 @@
+use criterion::{black_box, criterion_group, Criterion};
+
+use tfhe::core_crypto::fpga::keyswitch_bootstrap::KeyswitchBootstrapPacked;
+use tfhe::core_crypto::fpga::utils::Connect;
+use tfhe::core_crypto::fpga::BelfortFpgaUtils;
+
+use tfhe::boolean::ciphertext::Ciphertext as BooleanCiphertext;
+use tfhe::boolean::client_key::ClientKey as BooleanClientKey;
+use tfhe::boolean::parameters::{BooleanParameters, DEFAULT_PARAMETERS_KS_PBS};
+use tfhe::boolean::server_key::ServerKey as BooleanServerKey;
+
+use tfhe::keycache::NamedParam;
+use tfhe::shortint::ciphertext::Ciphertext as ShortintCiphertext;
+use tfhe::shortint::client_key::ClientKey as ShortintClientKey;
+use tfhe::shortint::parameters::{ClassicPBSParameters, PARAM_MESSAGE_2_CARRY_2_KS_PBS};
+use tfhe::shortint::server_key::ServerKey as ShortintServerKey;
+
+fn bench_boolean_throughput(
+    c: &mut Criterion,
+    params: BooleanParameters,
+    pack_sizes: Vec<usize>,
+    fpga_counts: Vec<usize>,
+) {
+    let mut bench_group = c.benchmark_group("fpga::throughput");
+
+    let params_name = params.name();
+
+    let cks = BooleanClientKey::new(&params);
+    let sks = BooleanServerKey::new(&cks);
+
+    let mut fpga_utils = BelfortFpgaUtils::from(params);
+
+    for fpga_count in fpga_counts {
+        fpga_utils.connect(&sks, fpga_count);
+
+        for pack_size in pack_sizes.clone() {
+            let mut ciphertexts: Vec<BooleanCiphertext> =
+                (0..pack_size).map(|_| cks.encrypt(true)).collect();
+            let luts: Vec<usize> = (0..pack_size).map(|_| 0).collect();
+
+            let id = format!("{params_name}::FpgaCount{fpga_count}::PackSize{pack_size}");
+            bench_group.bench_function(&id, |b| {
+                b.iter(|| black_box(fpga_utils.keyswitch_bootstrap_packed(&mut ciphertexts, &luts)))
+            });
+        }
+
+        fpga_utils.disconnect();
+    }
+}
+
+fn bench_shortint_throughput(
+    c: &mut Criterion,
+    params: ClassicPBSParameters,
+    pack_sizes: Vec<usize>,
+    fpga_counts: Vec<usize>,
+) {
+    let mut bench_group = c.benchmark_group("fpga::throughput");
+
+    let params_name = params.name();
+
+    let cks = ShortintClientKey::new(params);
+    let sks = ShortintServerKey::new(&cks);
+
+    let mut fpga_utils = BelfortFpgaUtils::from(params);
+
+    for fpga_count in fpga_counts {
+        fpga_utils.connect(&sks, fpga_count);
+
+        for pack_size in pack_sizes.clone() {
+            let mut ciphertexts: Vec<ShortintCiphertext> =
+                (0..pack_size).map(|_| cks.encrypt(1)).collect();
+            let luts: Vec<usize> = (0..pack_size).map(|_| 1).collect();
+
+            let id = format!("{params_name}::FpgaCount{fpga_count}::PackSize{pack_size}");
+            bench_group.bench_function(&id, |b| {
+                b.iter(|| black_box(fpga_utils.keyswitch_bootstrap_packed(&mut ciphertexts, &luts)))
+            });
+        }
+
+        fpga_utils.disconnect();
+    }
+}
+
+fn bench_thoughput(c: &mut Criterion) {
+    bench_boolean_throughput(
+        c,
+        DEFAULT_PARAMETERS_KS_PBS,
+        [
+            1, 2, 3, 4, 6, 8, 10, 12, 16, 24, 32, 48, 64, 96, 128, 256, 512, 1024,
+        ]
+        .to_vec(),
+        [1, 2, 4].to_vec(),
+    );
+    bench_shortint_throughput(
+        c,
+        PARAM_MESSAGE_2_CARRY_2_KS_PBS,
+        [
+            1, 2, 3, 4, 6, 8, 10, 12, 16, 24, 32, 48, 64, 96, 128, 256, 512, 1024,
+        ]
+        .to_vec(),
+        [1, 2, 4].to_vec(),
+    );
+}
+
+criterion_group!(fpga_throughput, bench_thoughput);
+
+fn main() {
+    fpga_throughput();
+
+    Criterion::default().configure_from_args().final_summary();
+}
diff --git a/tfhe/benches/integer/bench.rs b/tfhe/benches/integer/bench.rs
index 0c93bf99..4fa9ae89 100644
--- a/tfhe/benches/integer/bench.rs
+++ b/tfhe/benches/integer/bench.rs
@@ -8,6 +8,8 @@ use crate::utilities::{write_to_json, EnvConfig, OperatorType, ParamsAndNumBlock
 use criterion::{criterion_group, Criterion};
 use rand::prelude::*;
 use std::env;
+use std::vec::IntoIter;
+use tfhe::core_crypto::algorithms::misc::divide_ceil;
 use tfhe::integer::keycache::KEY_CACHE;
 use tfhe::integer::prelude::*;
 use tfhe::integer::{IntegerKeyKind, RadixCiphertext, RadixClientKey, ServerKey, U256};
@@ -877,26 +879,7 @@ define_server_key_bench_scalar_default_fn!(
     display_name: not_equal,
     rng_func: default_scalar
 );
-define_server_key_bench_scalar_default_fn!(
-    method_name: scalar_le_parallelized,
-    display_name: less_or_equal,
-    rng_func: default_scalar
-);
-define_server_key_bench_scalar_default_fn!(
-    method_name: scalar_lt_parallelized,
-    display_name: less_than,
-    rng_func: default_scalar
-);
-define_server_key_bench_scalar_default_fn!(
-    method_name: scalar_ge_parallelized,
-    display_name: greater_or_equal,
-    rng_func: default_scalar
-);
-define_server_key_bench_scalar_default_fn!(
-    method_name: scalar_gt_parallelized,
-    display_name: greater_than,
-    rng_func: default_scalar
-);
+
 define_server_key_bench_scalar_default_fn!(
     method_name: scalar_max_parallelized,
     display_name: max,
@@ -2244,9 +2227,7 @@ criterion_group!(
 criterion_group!(
     default_parallelized_ops,
     neg_parallelized,
-    abs_parallelized,
     add_parallelized,
-    unsigned_overflowing_add_parallelized,
     sub_parallelized,
     unsigned_overflowing_sub_parallelized,
     mul_parallelized,
@@ -2273,18 +2254,7 @@ criterion_group!(
     count_ones_parallelized,
 );
 
-criterion_group!(
-    default_parallelized_ops_comp,
-    max_parallelized,
-    min_parallelized,
-    eq_parallelized,
-    ne_parallelized,
-    lt_parallelized,
-    le_parallelized,
-    gt_parallelized,
-    ge_parallelized,
-    if_then_else_parallelized,
-);
+criterion_group!(default_parallelized_ops_comp, if_then_else_parallelized,);
 
 criterion_group!(
     default_dedup_ops,
@@ -2338,26 +2308,11 @@ criterion_group!(
 criterion_group!(
     default_scalar_parallelized_ops,
     scalar_add_parallelized,
-    unsigned_overflowing_scalar_add_parallelized,
     scalar_sub_parallelized,
-    unsigned_overflowing_scalar_sub_parallelized,
-    scalar_mul_parallelized,
-    scalar_div_parallelized,
-    scalar_rem_parallelized,
-    // scalar_div_rem_parallelized,
-    scalar_left_shift_parallelized,
-    scalar_right_shift_parallelized,
-    scalar_rotate_left_parallelized,
-    scalar_rotate_right_parallelized,
-    scalar_bitand_parallelized,
-    scalar_bitor_parallelized,
-    scalar_bitxor_parallelized,
 );
 
 criterion_group!(
     default_scalar_parallelized_ops_comp,
-    scalar_eq_parallelized,
-    scalar_ne_parallelized,
     scalar_lt_parallelized,
     scalar_le_parallelized,
     scalar_gt_parallelized,
@@ -2557,7 +2512,7 @@ fn go_through_gpu_bench_groups(val: &str) {
 fn go_through_cpu_bench_groups(val: &str) {
     match val.to_lowercase().as_str() {
         "default" => {
-            default_parallelized_ops();
+            //default_parallelized_ops();
             default_parallelized_ops_comp();
             default_scalar_parallelized_ops();
             default_scalar_parallelized_ops_comp();
diff --git a/tfhe/build.rs b/tfhe/build.rs
index ee078e57..ca7bb6b2 100644
--- a/tfhe/build.rs
+++ b/tfhe/build.rs
@@ -1,8 +1,10 @@
+extern crate bindgen;
+
+use std::env;
+use std::path::PathBuf;
+
 #[cfg(all(feature = "__c_api", not(feature = "__force_skip_cbindgen")))]
 fn gen_c_api() {
-    use std::env;
-    use std::path::PathBuf;
-
     if std::env::var("_CBINDGEN_IS_RUNNING").is_ok() {
         return;
     }
@@ -79,5 +81,28 @@ fn gen_c_api() {
 
 fn main() {
     #[cfg(all(feature = "__c_api", not(feature = "__force_skip_cbindgen")))]
-    gen_c_api()
+    gen_c_api();
+
+    // Tell cargo to look for shared libraries in the specified directory
+    println!("cargo:rustc-link-search=/opt/xilinx/xrt/lib");
+
+    // Tell cargo to tell rustc to link the system xrt libraries
+    // shared library.
+    println!("cargo:rustc-link-lib=xrt_coreutil");
+
+    // Tell cargo to invalidate the built crate whenever the wrapper changes
+    println!("cargo:rerun-if-changed=wrapper.h");
+
+    let bindings = bindgen::Builder::default()
+        .header("wrapper.h")
+        .clang_arg("-I/opt/xilinx/xrt/include")
+        .generate()
+        .expect("Unable to generate bindings");
+
+    let out_path = PathBuf::from(env::var("OUT_DIR").unwrap());
+    bindings
+        .write_to_file(out_path.join("bindings.rs"))
+        .expect("Couldn't write bindings!");
+
+
 }
diff --git a/tfhe/c_api_tests/test_boolean_keygen.c b/tfhe/c_api_tests/test_boolean_keygen.c
index 4fcb6f24..b5883444 100644
--- a/tfhe/c_api_tests/test_boolean_keygen.c
+++ b/tfhe/c_api_tests/test_boolean_keygen.c
@@ -1,4 +1,4 @@
-#include "tfhe.h"
+#include <tfhe.h>
 #include <assert.h>
 #include <inttypes.h>
 #include <stdio.h>
diff --git a/tfhe/c_api_tests/test_boolean_server_key.c b/tfhe/c_api_tests/test_boolean_server_key.c
index 3e2ec937..6d271ff5 100644
--- a/tfhe/c_api_tests/test_boolean_server_key.c
+++ b/tfhe/c_api_tests/test_boolean_server_key.c
@@ -1,4 +1,4 @@
-#include "tfhe.h"
+#include <tfhe.h>
 #include <assert.h>
 #include <inttypes.h>
 #include <stdio.h>
diff --git a/tfhe/c_api_tests/test_high_level_zk.c b/tfhe/c_api_tests/test_high_level_zk.c
index 77e6da56..017e8130 100644
--- a/tfhe/c_api_tests/test_high_level_zk.c
+++ b/tfhe/c_api_tests/test_high_level_zk.c
@@ -1,4 +1,4 @@
-#include "tfhe.h"
+#include <tfhe.h>
 #include <assert.h>
 #include <stdlib.h>
 
diff --git a/tfhe/c_api_tests/test_micro_bench_and.c b/tfhe/c_api_tests/test_micro_bench_and.c
index 936474b5..a0c5f31c 100644
--- a/tfhe/c_api_tests/test_micro_bench_and.c
+++ b/tfhe/c_api_tests/test_micro_bench_and.c
@@ -1,4 +1,4 @@
-#include "tfhe.h"
+#include <tfhe.h>
 #include <assert.h>
 #include <inttypes.h>
 #include <stdio.h>
diff --git a/tfhe/c_api_tests/test_shortint_keygen.c b/tfhe/c_api_tests/test_shortint_keygen.c
index cc1cbd95..ea9f1c06 100644
--- a/tfhe/c_api_tests/test_shortint_keygen.c
+++ b/tfhe/c_api_tests/test_shortint_keygen.c
@@ -1,4 +1,4 @@
-#include "tfhe.h"
+#include <tfhe.h>
 #include <assert.h>
 #include <inttypes.h>
 #include <stdio.h>
diff --git a/tfhe/c_api_tests/test_shortint_pbs.c b/tfhe/c_api_tests/test_shortint_pbs.c
index f5970ead..3fe6589e 100644
--- a/tfhe/c_api_tests/test_shortint_pbs.c
+++ b/tfhe/c_api_tests/test_shortint_pbs.c
@@ -1,4 +1,4 @@
-#include "tfhe.h"
+#include <tfhe.h>
 #include <assert.h>
 #include <inttypes.h>
 #include <stdio.h>
diff --git a/tfhe/c_api_tests/test_shortint_server_key.c b/tfhe/c_api_tests/test_shortint_server_key.c
index f0dfc928..72d246fe 100644
--- a/tfhe/c_api_tests/test_shortint_server_key.c
+++ b/tfhe/c_api_tests/test_shortint_server_key.c
@@ -1,4 +1,4 @@
-#include "tfhe.h"
+#include <tfhe.h>
 #include <assert.h>
 #include <inttypes.h>
 #include <stdio.h>
diff --git a/tfhe/docs/guides/debug.md b/tfhe/docs/guides/debug.md
new file mode 100644
index 00000000..c6b94205
--- /dev/null
+++ b/tfhe/docs/guides/debug.md
@@ -0,0 +1,72 @@
+# Debugging FHE Code
+
+Since tfhe-rs 0.5, [trivial ciphertexts](./trivial_ciphertext.md) have another application.
+They can be used to allow debugging via a debugger or print statements as well as speeding-up execution time
+so that you won't have to spend minutes waiting for execution to progress.
+
+This can greatly improve the pace at which one develops FHE applications.
+
+{% hint style="warning" %}
+Keep in mind that trivial ciphertexts are not secure at all, thus an application released/deployed in production
+must never receive trivial ciphertext from a client.
+{% endhint %}
+
+
+## Example
+
+To use this feature, simply call your circuits/functions with trivially encrypted values (made using `encrypt_trivial`)
+instead of real encryptions (made using `encrypt`)
+
+```rust
+use tfhe::prelude::*;
+use tfhe::{set_server_key, generate_keys, ConfigBuilder, FheUint128};
+
+
+fn mul_all(a: &FheUint128, b: &FheUint128, c: &FheUint128) -> FheUint128 {
+    // Use the debug format ('{:?}'), if you don't want to unwrap()
+    // and panic if the value is not a trivial.
+    println!(
+        "a: {:?}, b: {:?}, c: {:?}", 
+        a.try_decrypt_trivial::<u128>(),
+        b.try_decrypt_trivial::<u128>(),
+        c.try_decrypt_trivial::<u128>(),
+    );
+    let tmp = a * b;
+    
+    println!("a * b = {:?}", tmp.try_decrypt_trivial::<u128>());
+
+    tmp * c
+}
+
+
+fn main() {
+    let (cks, sks) = generate_keys(ConfigBuilder::default().build());
+    
+    set_server_key(sks);
+    
+    let a = FheUint128::encrypt_trivial(1234u128);
+    let b = FheUint128::encrypt_trivial(4567u128);
+    let c = FheUint128::encrypt_trivial(89101112u128);
+    
+    // since all inputs are trivially encrypted, this is going to be
+    // much faster
+    let result = mul_all(&a, &b, &c);
+}
+```
+
+This example is going to print.
+```text
+a: Ok(1234), b: Ok(4567), c: Ok(89101112)
+a * b = Ok(5635678)
+```
+
+If any input to `mul_all` is not a trivial ciphertexts, the computations would be done 100% in FHE, and the program
+would output:
+
+```text
+a: Err(NotTrivialCiphertextError), b: Err(NotTrivialCiphertextError), c: Err(NotTrivialCiphertextError)
+a * b = Err(NotTrivialCiphertextError)
+```
+
+Using trivial encryptions as input, the example runs in **980 ms** on a standard 12 cores laptop, using real encryptions
+it would run in **7.5 seconds** on a 128-core machine.
diff --git a/tfhe/examples/sha256.rs b/tfhe/examples/sha256.rs
index a38bb2d0..04e3dff1 100644
--- a/tfhe/examples/sha256.rs
+++ b/tfhe/examples/sha256.rs
@@ -226,6 +226,10 @@ fn main() -> Result<(), std::io::Error> {
             });
             set_server_key(server_key);
         }
+        #[cfg(feature = "fpga")]
+        (Device::Fpga, true) => todo!(),
+        #[cfg(feature = "fpga")]
+        (Device::Fpga, false) => todo!(),
     }
     println!("key gen end");
 
diff --git a/tfhe/js_on_wasm_tests/test-hlapi-unsigned.js b/tfhe/js_on_wasm_tests/test-hlapi-unsigned.js
index 0108b779..f0a99212 100644
--- a/tfhe/js_on_wasm_tests/test-hlapi-unsigned.js
+++ b/tfhe/js_on_wasm_tests/test-hlapi-unsigned.js
@@ -19,6 +19,7 @@ const {
 const {
     randomBytes,
 } = require('node:crypto');
+const {FheUint2048} = require("../pkg");
 
 const U256_MAX = BigInt("115792089237316195423570985008687907853269984665640564039457584007913129639935");
 const U128_MAX = BigInt("340282366920938463463374607431768211455");
diff --git a/tfhe/src/boolean/engine/bootstrapping.rs b/tfhe/src/boolean/engine/bootstrapping.rs
index b9a63388..c1fff552 100644
--- a/tfhe/src/boolean/engine/bootstrapping.rs
+++ b/tfhe/src/boolean/engine/bootstrapping.rs
@@ -323,7 +323,7 @@ impl CompressedServerKey {
 }
 
 /// Perform ciphertext bootstraps on the CPU
-pub(crate) struct Bootstrapper {
+pub struct Bootstrapper {
     memory: Memory,
     /// A structure containing two CSPRNGs to generate material for encryption like public masks
     /// and secret errors.
@@ -445,7 +445,7 @@ impl Bootstrapper {
         }
     }
 
-    pub(crate) fn bootstrap(
+    pub fn bootstrap(
         &mut self,
         input: &LweCiphertextOwned<u32>,
         server_key: &ServerKey,
@@ -487,6 +487,26 @@ impl Bootstrapper {
         )
     }
 
+    pub fn keyswitch(
+        &mut self,
+        input: &LweCiphertextOwned<u32>,
+        server_key: &ServerKey,
+    ) -> LweCiphertextOwned<u32> {
+        // Allocate the output of the KS
+        let mut output = LweCiphertext::new(
+            0u32,
+            server_key
+                .bootstrapping_key
+                .input_lwe_dimension()
+                .to_lwe_size(),
+            input.ciphertext_modulus(),
+        );
+
+        keyswitch_lwe_ciphertext(&server_key.key_switching_key, input, &mut output);
+
+        output
+    }
+
     pub(crate) fn bootstrap_keyswitch(
         &mut self,
         mut ciphertext: LweCiphertextOwned<u32>,
diff --git a/tfhe/src/boolean/engine/fpga.rs b/tfhe/src/boolean/engine/fpga.rs
new file mode 100644
index 00000000..b9f33719
--- /dev/null
+++ b/tfhe/src/boolean/engine/fpga.rs
@@ -0,0 +1,197 @@
+use itertools::izip;
+
+use crate::boolean::ciphertext::Ciphertext;
+use crate::boolean::engine::bootstrapping::ServerKey;
+use crate::boolean::engine::{
+    lwe_ciphertext_add, lwe_ciphertext_cleartext_mul_assign, lwe_ciphertext_opposite_assign,
+    lwe_ciphertext_plaintext_add_assign,
+};
+use crate::boolean::prelude::BinaryBooleanGates;
+use crate::boolean::{PLAINTEXT_FALSE, PLAINTEXT_TRUE};
+use crate::core_crypto::entities::*;
+use crate::core_crypto::fpga::keyswitch_bootstrap::KeyswitchBootstrapPacked;
+use crate::core_crypto::fpga::luts::BelfortLookupTable;
+use crate::core_crypto::fpga::utils::Connect;
+use crate::core_crypto::fpga::{BelfortFpgaLuts, BelfortFpgaUtils};
+
+#[derive(Clone)]
+pub enum Gate {
+    AND,
+    OR,
+    XOR,
+    NAND,
+    NOR,
+    XNOR,
+}
+
+#[derive(Clone)]
+pub struct BelfortBooleanServerKey {
+    pub key: ServerKey,
+    pub fpga_utils: BelfortFpgaUtils,
+}
+
+impl BelfortBooleanServerKey {
+    // Construct
+
+    pub fn default(cpu_key: ServerKey) -> Self {
+        Self {
+            key: cpu_key,
+            fpga_utils: BelfortFpgaUtils::default_boolean(),
+        }
+    }
+
+    pub fn connect(&mut self, fpga_count: usize) {
+        self.fpga_utils.connect(&self.key, fpga_count);
+    }
+
+    pub fn disconnect(&mut self) {
+        self.fpga_utils.disconnect();
+    }
+
+    pub fn packed_gates(
+        &self,
+        gates: &Vec<Gate>,
+        cts_left: &Vec<&Ciphertext>,
+        cts_right: &Vec<&Ciphertext>,
+    ) -> Vec<Ciphertext> {
+        assert!(gates.len() == cts_left.len());
+        assert!(gates.len() == cts_right.len());
+
+        let server_key = &self.key;
+
+        let lwe_size = server_key
+            .key_switching_key
+            .input_key_lwe_dimension()
+            .to_lwe_size();
+
+        let mut cts_pack = Vec::<Ciphertext>::new();
+
+        for (ct_left, ct_right, gate) in izip!(cts_left, cts_right, gates) {
+            match (*ct_left, *ct_right) {
+                (Ciphertext::Encrypted(ct_left_ct), Ciphertext::Encrypted(ct_right_ct)) => {
+                    let mut buffer_lwe_before_pbs =
+                        LweCiphertext::new(0u32, lwe_size, ct_left_ct.ciphertext_modulus());
+
+                    lwe_ciphertext_add(&mut buffer_lwe_before_pbs, &ct_left_ct, &ct_right_ct);
+
+                    match gate {
+                        Gate::AND => {
+                            // compute the linear combination for AND: ct_left + ct_right +
+                            // (0,...,0,-1/8) ct_left + ct_right
+                            lwe_ciphertext_plaintext_add_assign(
+                                &mut buffer_lwe_before_pbs,
+                                Plaintext(PLAINTEXT_FALSE),
+                            );
+                        }
+                        Gate::OR => {
+                            // Compute the linear combination for OR: ct_left + ct_right +
+                            // (0,...,0,+1/8) ct_left + ct_right
+                            lwe_ciphertext_plaintext_add_assign(
+                                &mut buffer_lwe_before_pbs,
+                                Plaintext(PLAINTEXT_TRUE),
+                            );
+                        }
+                        Gate::XOR => {
+                            // Compute the linear combination for XOR: 2*(ct_left + ct_right) +
+                            // (0,...,0,1/4) ct_left + ct_right
+                            lwe_ciphertext_plaintext_add_assign(
+                                &mut buffer_lwe_before_pbs,
+                                Plaintext(PLAINTEXT_TRUE),
+                            );
+                            //* 2
+                            lwe_ciphertext_cleartext_mul_assign(
+                                &mut buffer_lwe_before_pbs,
+                                Cleartext(2u32),
+                            );
+                        }
+                        Gate::NAND => {
+                            // Compute the linear combination for NAND: - ct_left - ct_right +
+                            // (0,...,0,1/8) ct_left + ct_right
+                            lwe_ciphertext_opposite_assign(&mut buffer_lwe_before_pbs);
+                            // + 1/8
+                            lwe_ciphertext_plaintext_add_assign(
+                                &mut buffer_lwe_before_pbs,
+                                Plaintext(PLAINTEXT_TRUE),
+                            );
+                        }
+                        Gate::NOR => {
+                            // Compute the linear combination for NOR: - ct_left - ct_right +
+                            // (0,...,0,-1/8) ct_left + ct_right
+
+                            lwe_ciphertext_opposite_assign(&mut buffer_lwe_before_pbs);
+                            // - 1/8
+                            lwe_ciphertext_plaintext_add_assign(
+                                &mut buffer_lwe_before_pbs,
+                                Plaintext(PLAINTEXT_FALSE),
+                            );
+                        }
+                        Gate::XNOR => {
+                            // Compute the linear combination for XNOR: 2*(-ct_left - ct_right +
+                            // (0,...,0,-1/8)) ct_left + ct_right
+
+                            lwe_ciphertext_plaintext_add_assign(
+                                &mut buffer_lwe_before_pbs,
+                                Plaintext(PLAINTEXT_TRUE),
+                            );
+                            // compute the negation
+                            lwe_ciphertext_opposite_assign(&mut buffer_lwe_before_pbs);
+
+                            //* 2
+                            lwe_ciphertext_cleartext_mul_assign(
+                                &mut buffer_lwe_before_pbs,
+                                Cleartext(2u32),
+                            );
+                        }
+                    }
+
+                    cts_pack.push(Ciphertext::Encrypted(buffer_lwe_before_pbs));
+                }
+                (Ciphertext::Trivial(message_left), Ciphertext::Trivial(message_right)) => {
+                    let ct: Ciphertext = match gate {
+                        Gate::AND => Ciphertext::Trivial(*message_left && *message_right),
+                        Gate::OR => Ciphertext::Trivial(*message_left | *message_right),
+                        Gate::XOR => Ciphertext::Trivial(*message_left ^ *message_right),
+                        Gate::NAND => Ciphertext::Trivial(!(*message_left && *message_right)),
+                        Gate::NOR => Ciphertext::Trivial(!(*message_left | *message_right)),
+                        Gate::XNOR => Ciphertext::Trivial(!(*message_left ^ *message_right)),
+                    };
+
+                    cts_pack.push(ct);
+                }
+                (Ciphertext::Encrypted(_), Ciphertext::Trivial(message_right)) => {
+                    let ct: Ciphertext = match gate {
+                        Gate::AND => server_key.and(*ct_left, *message_right),
+                        Gate::OR => server_key.or(*ct_left, *message_right),
+                        Gate::XOR => server_key.xor(*ct_left, *message_right),
+                        Gate::NAND => server_key.nand(*ct_left, *message_right),
+                        Gate::NOR => server_key.nor(*ct_left, *message_right),
+                        Gate::XNOR => server_key.xnor(*ct_left, *message_right),
+                    };
+
+                    cts_pack.push(ct);
+                }
+                (Ciphertext::Trivial(message_left), Ciphertext::Encrypted(_)) => {
+                    let ct: Ciphertext = match gate {
+                        Gate::AND => server_key.and(*message_left, *ct_right),
+                        Gate::OR => server_key.or(*message_left, *ct_right),
+                        Gate::XOR => server_key.xor(*message_left, *ct_right),
+                        Gate::NAND => server_key.nand(*message_left, *ct_right),
+                        Gate::NOR => server_key.nor(*message_left, *ct_right),
+                        Gate::XNOR => server_key.xnor(*message_left, *ct_right),
+                    };
+
+                    cts_pack.push(ct);
+                }
+            }
+        }
+
+        let luts: Vec<BelfortLookupTable> = (0..cts_pack.len())
+            .map(|_| BelfortFpgaLuts::boolean_lut())
+            .collect();
+
+        self.fpga_utils
+            .keyswitch_bootstrap_packed(&mut cts_pack, &luts);
+
+        return cts_pack;
+    }
+}
diff --git a/tfhe/src/boolean/engine/mod.rs b/tfhe/src/boolean/engine/mod.rs
index e1208921..b037f682 100644
--- a/tfhe/src/boolean/engine/mod.rs
+++ b/tfhe/src/boolean/engine/mod.rs
@@ -18,6 +18,7 @@ use crate::core_crypto::seeders::new_seeder;
 use std::cell::RefCell;
 
 pub mod bootstrapping;
+pub mod fpga;
 
 #[cfg(test)]
 mod tests;
@@ -42,7 +43,7 @@ pub(crate) trait BinaryGatesAssignEngine<L, R, K> {
 
 /// Trait to be able to access thread_local
 /// engines in a generic way
-pub(crate) trait WithThreadLocalEngine {
+pub trait WithThreadLocalEngine {
     fn with_thread_local_mut<R, F>(func: F) -> R
     where
         F: FnOnce(&mut Self) -> R;
@@ -60,11 +61,11 @@ pub struct BooleanEngine {
     /// A structure containing two CSPRNGs to generate material for encryption like public masks
     /// and secret errors.
     ///
-    /// The [`EncryptionRandomGenerator`] contains two CSPRNGs, one publicly seeded used to
+    /// The [`EncryptionRandomGenerator`] contains two CSPRNGs, one publicly seeded used rto
     /// generate mask coefficients and one privately seeded used to generate errors during
     /// encryption.
     encryption_generator: EncryptionRandomGenerator<ActivatedRandomGenerator>,
-    bootstrapper: Bootstrapper,
+    pub bootstrapper: Bootstrapper,
 }
 
 impl WithThreadLocalEngine for BooleanEngine {
diff --git a/tfhe/src/boolean/server_key/mod.rs b/tfhe/src/boolean/server_key/mod.rs
index 493125a2..d9905fbf 100644
--- a/tfhe/src/boolean/server_key/mod.rs
+++ b/tfhe/src/boolean/server_key/mod.rs
@@ -15,6 +15,8 @@ use crate::boolean::engine::{
     BinaryGatesAssignEngine, BinaryGatesEngine, BooleanEngine, WithThreadLocalEngine,
 };
 
+use crate::boolean::engine::fpga::BelfortBooleanServerKey;
+
 pub trait BinaryBooleanGates<L, R> {
     fn and(&self, ct_left: L, ct_right: R) -> Ciphertext;
     fn nand(&self, ct_left: L, ct_right: R) -> Ciphertext;
@@ -161,3 +163,9 @@ impl CompressedServerKey {
         BooleanEngine::with_thread_local_mut(|engine| engine.create_compressed_server_key(cks))
     }
 }
+
+impl From<ServerKey> for BelfortBooleanServerKey {
+    fn from(value: ServerKey) -> Self {
+        BelfortBooleanServerKey::default(value.clone())
+    }
+}
diff --git a/tfhe/src/core_crypto/entities/polynomial.rs b/tfhe/src/core_crypto/entities/polynomial.rs
index 05d64122..2d3cfaed 100644
--- a/tfhe/src/core_crypto/entities/polynomial.rs
+++ b/tfhe/src/core_crypto/entities/polynomial.rs
@@ -5,6 +5,7 @@ use tfhe_versionable::Versionize;
 use crate::core_crypto::backward_compatibility::entities::polynomial::PolynomialVersions;
 use crate::core_crypto::commons::parameters::*;
 use crate::core_crypto::commons::traits::*;
+use std::ops::{Deref, DerefMut};
 use std::ops::{Index, IndexMut};
 
 /// A [`polynomial`](`Polynomial`).
@@ -152,6 +153,20 @@ where
     }
 }
 
+impl<C: Container> Deref for Polynomial<C> {
+    type Target = [C::Element];
+
+    fn deref(&self) -> &Self::Target {
+        self.as_ref()
+    }
+}
+
+impl<C: ContainerMut> DerefMut for Polynomial<C> {
+    fn deref_mut(&mut self) -> &mut Self::Target {
+        self.as_mut()
+    }
+}
+
 /// Metadata used in the [`CreateFrom`] implementation to create [`Polynomial`] entities.
 #[derive(Clone, Copy)]
 pub struct PolynomialCreationMetadata {}
diff --git a/tfhe/src/core_crypto/fpga/accelerators/accelerators.rs b/tfhe/src/core_crypto/fpga/accelerators/accelerators.rs
new file mode 100644
index 00000000..83e8ce53
--- /dev/null
+++ b/tfhe/src/core_crypto/fpga/accelerators/accelerators.rs
@@ -0,0 +1,23 @@
+// This file is auto generated.
+
+pub const PARAM_MESSAGE_2_CARRY_2: ContainerParameters = ContainerParameters {
+  fpga_image: "/tools/xclbin/SHORTINT_MESSAGE_2_CARRY_2_S16_B12_2BK_v0_8.xclbin",
+  batch_size: 12,
+  streaming_size: 16,
+  bsk_num_kernels: 2,
+  ksk_num_kernels: 2,
+  bsk_bits: 54,
+  bsk_frac_bits: 46,
+  ksk_bits: 34,
+};
+
+pub const DEFAULT_PARAMETERS_KS_PBS: ContainerParameters = ContainerParameters {
+  fpga_image: "/tools/xclbin/BOOLEAN_KS_PBS_S8_B12_4B1K.xclbin",
+  batch_size: 12,
+  streaming_size: 8,
+  bsk_num_kernels: 4,
+  ksk_num_kernels: 1,
+  bsk_bits: 34,
+  bsk_frac_bits: 27,
+  ksk_bits: 21,
+};
diff --git a/tfhe/src/core_crypto/fpga/accelerators/mappings.rs b/tfhe/src/core_crypto/fpga/accelerators/mappings.rs
new file mode 100644
index 00000000..08497f83
--- /dev/null
+++ b/tfhe/src/core_crypto/fpga/accelerators/mappings.rs
@@ -0,0 +1,20 @@
+use crate::boolean::parameters::BooleanParameters;
+use crate::core_crypto::fpga::parameters::ContainerParameters;
+use crate::core_crypto::fpga::parameters::FpgaParameters;
+use crate::shortint::ClassicPBSParameters;
+
+include!("accelerators.rs");
+
+pub fn map_shortint_params(params: ClassicPBSParameters) -> FpgaParameters {
+  match params {
+    crate::shortint::parameters::PARAM_MESSAGE_2_CARRY_2 => FpgaParameters::from((PARAM_MESSAGE_2_CARRY_2, params)),
+    _ => panic!("Unknown variable"),
+  }
+}
+
+pub fn map_boolean_params(params: BooleanParameters) -> FpgaParameters {
+  match params {
+    crate::boolean::parameters::DEFAULT_PARAMETERS_KS_PBS => FpgaParameters::from((DEFAULT_PARAMETERS_KS_PBS, params)),
+    _ => panic!("Unknown variable"),
+  }
+}
diff --git a/tfhe/src/core_crypto/fpga/accelerators/mod.rs b/tfhe/src/core_crypto/fpga/accelerators/mod.rs
new file mode 100644
index 00000000..89e687c9
--- /dev/null
+++ b/tfhe/src/core_crypto/fpga/accelerators/mod.rs
@@ -0,0 +1 @@
+pub mod mappings;
diff --git a/tfhe/src/core_crypto/fpga/keyswitch_bootstrap.rs b/tfhe/src/core_crypto/fpga/keyswitch_bootstrap.rs
new file mode 100644
index 00000000..5bfd73f5
--- /dev/null
+++ b/tfhe/src/core_crypto/fpga/keyswitch_bootstrap.rs
@@ -0,0 +1,503 @@
+#![allow(non_upper_case_globals)]
+#![allow(non_camel_case_types)]
+#![allow(non_snake_case)]
+// Supress not FFI-safe warning
+#![allow(improper_ctypes)]
+#![allow(dead_code)]
+#![allow(unused_unsafe)]
+
+include!(concat!(env!("OUT_DIR"), "/bindings.rs"));
+
+use crate::boolean::ciphertext::Ciphertext as BooleanCiphertext;
+pub use crate::core_crypto::commons::parameters::CiphertextModulus;
+use crate::core_crypto::fpga::luts::BelfortLookupTable;
+use crate::core_crypto::fpga::BelfortFpgaUtils;
+use crate::core_crypto::prelude::*;
+use crate::shortint::ciphertext::Ciphertext as ShortintCiphertext;
+use crate::shortint::ciphertext::NoiseLevel;
+
+use std::alloc::{alloc, dealloc, Layout};
+use std::os::raw::c_void;
+use std::{mem, ptr, slice};
+
+pub struct Sizes {
+  lwe_in_size: usize,
+  lwe_in_padded_size: usize,
+  lwe_in_pad_size: usize,
+  lwe_out_size: usize,
+  lwe_out_padded_size: usize,
+  fpga_pack_sizes: Vec<usize>,
+}
+
+#[derive(Debug)]
+pub struct SkippedSlots {
+  fpga_index: usize,
+  slot_index: usize,
+}
+
+pub trait KeyswitchBootstrapPacked<Ciphertext> {
+  fn keyswitch_bootstrap_packed(&self, ciphertexts: &mut Vec<Ciphertext>, luts: &Vec<BelfortLookupTable>);
+}
+
+impl KeyswitchBootstrapPacked<BooleanCiphertext> for BelfortFpgaUtils {
+  fn keyswitch_bootstrap_packed(&self, ciphertexts: &mut Vec<BooleanCiphertext>, luts: &Vec<BelfortLookupTable>) {
+    // Keep track of the ciphertexts skipped from being bootstrap;
+    // i.e., the trivial-encrypted ciphertexts that does not need bootstrap
+    let mut skipped_slots = Vec::<SkippedSlots>::new();
+
+    // Convert Input Vec<Ciphertext> to Vec<u32> with modswitch and send to FPGA
+    let sizes = self.send_boolean_cts_to_fpga(ciphertexts, luts, &mut skipped_slots);
+
+    // Handle runs of Keyswitch-Bootstrap Kernels
+    self.execute_fpga_kernels(&sizes);
+
+    // Convert the Vec<u32> to Vec<Ciphertext>
+    self.recv_boolean_cts_from_fpga(ciphertexts, &sizes, &mut skipped_slots);
+  }
+}
+
+impl KeyswitchBootstrapPacked<ShortintCiphertext> for BelfortFpgaUtils {
+  fn keyswitch_bootstrap_packed(&self, ciphertexts: &mut Vec<ShortintCiphertext>, luts: &Vec<BelfortLookupTable>) {
+    // The trivial elements aren't counted as they do not need bootstrap
+    let pack_size = ciphertexts
+      .iter()
+      .filter(|&ciphertext| !ciphertext.is_trivial())
+      .count();
+
+    if pack_size == 0 {
+      return;
+    }
+
+    let sizes = self.calculate_sizes(pack_size);
+
+    // Convert Input Vec<Ciphertext> to Vec<u32> with modswitch and send to FPGA
+    let mut skipped_slots = self.send_shortint_cts_to_fpga(ciphertexts, luts, &sizes);
+
+    // Handle runs of Keyswitch-Bootstrap Kernels
+    self.execute_fpga_kernels(&sizes);
+
+    // Convert the Vec<u32> to Vec<Ciphertext>
+    self.recv_shortint_cts_from_fpga(ciphertexts, luts, &sizes, &mut skipped_slots);
+  }
+}
+
+impl BelfortFpgaUtils {
+  pub(crate) fn calculate_sizes(&self, pack_size: usize) -> Sizes {
+    let glwe_dimension = self.params.glwe_dimension.0;
+    let polynomial_size = self.params.polynomial_size.0;
+
+    let ks_num_streams = 2 * self.params.streaming_size * self.params.glwe_dimension.0;
+
+    let lwe_in_size = polynomial_size * glwe_dimension + 1;
+    let lwe_out_size = polynomial_size * glwe_dimension + 1;
+
+    let lwe_in_padded_size = polynomial_size * glwe_dimension + ks_num_streams;
+    let lwe_out_padded_size = polynomial_size * glwe_dimension + 16;
+
+    let fpga_pack_sizes = self.calculate_fpga_pack_sizes(pack_size);
+
+    Sizes {
+      lwe_in_size,
+      lwe_in_padded_size,
+      lwe_in_pad_size: ks_num_streams,
+      lwe_out_size,
+      lwe_out_padded_size,
+      fpga_pack_sizes,
+    }
+  }
+
+  fn calculate_fpga_pack_sizes(&self, pack_size: usize) -> Vec<usize> {
+    let fpga_count = self.enabled_fpga_count;
+    let batch_size = self.params.batch_size;
+
+    assert!(
+      pack_size / fpga_count <= batch_size * crate::core_crypto::fpga::utils::MAX_BATCH_COUNT,
+      "The pack size exceeds max."
+    );
+
+    let amount_of_batches = (pack_size + batch_size - 1) / batch_size;
+    let required_fpgas = amount_of_batches.min(fpga_count);
+
+    let mut fpga_pack_sizes: Vec<usize> = vec![0; required_fpgas];
+    let mut remaining_size = pack_size;
+
+    let mut fpga_index = 0;
+    while remaining_size > 0 {
+      fpga_pack_sizes[fpga_index] += remaining_size.min(batch_size);
+      fpga_index = (fpga_index + 1) % fpga_count;
+      remaining_size = remaining_size.saturating_sub(batch_size);
+    }
+
+    fpga_pack_sizes
+  }
+
+  pub(crate) fn send_boolean_cts_to_fpga(
+    &self,
+    ciphertexts: &Vec<BooleanCiphertext>,
+    luts: &Vec<BelfortLookupTable>,
+    skip_indexes: &mut Vec<SkippedSlots>,
+  ) -> Sizes {
+    // This is the pack-size, where the trivial elements are not counted
+    // as they do not need bootstrap
+    let pack_size = ciphertexts
+      .iter()
+      .filter(|&ciphertext| matches!(ciphertext, BooleanCiphertext::Encrypted(_)))
+      .count();
+
+    if pack_size == 0 {
+      panic!(
+        "How did we end up here? Is ciphertexts.len()={} is 0? Otherwise, are all items in the pack are trivial?",
+        ciphertexts.len()
+      );
+    }
+
+    let sizes = self.calculate_sizes(pack_size);
+
+    let lwe_in_padded_size = sizes.lwe_in_padded_size;
+    let lwe_in_pad_size = sizes.lwe_in_pad_size;
+    let fpga_pack_sizes = &sizes.fpga_pack_sizes;
+
+    let mut ciphertext_index = 0;
+
+    for (fpga_index, fpga_pack_size) in fpga_pack_sizes.iter().enumerate() {
+      let lwe_in_dma_size = fpga_pack_size * lwe_in_padded_size * mem::size_of::<u32>();
+      let lwe_in_layout = Layout::from_size_align(lwe_in_dma_size, 4096).expect("Invalid layout");
+      let lwe_in_ptr = unsafe { alloc(lwe_in_layout) as *mut u32 };
+      assert!(!lwe_in_ptr.is_null());
+
+      let mut lwe_in_ptr_index = 0;
+
+      let mut slot_index = 0;
+
+      // move ciphertext's into FPGA memory buffer after modswitch
+      while slot_index < *fpga_pack_size {
+        // TODO: remove clone (to_owned()) here
+        match ciphertexts[ciphertext_index].to_owned() {
+          // modswitched ciphertext coeffs
+          BooleanCiphertext::Encrypted(ct_tmp) => {
+            for element in ct_tmp.into_container() {
+              let modswitched =
+                self.modulus_switch_from_u32_to_u32(element, self.params.ks_base_log.0 * self.params.ks_level.0);
+              unsafe { ptr::write(lwe_in_ptr.add(lwe_in_ptr_index), modswitched as u32) };
+              lwe_in_ptr_index += 1;
+            }
+
+            // Pad accumulator index
+            unsafe { ptr::write(lwe_in_ptr.add(lwe_in_ptr_index), luts[ciphertext_index].index as u32) };
+
+            // Skip pad amount
+            lwe_in_ptr_index += lwe_in_pad_size - 1;
+
+            slot_index += 1;
+          }
+          BooleanCiphertext::Trivial(_) => {
+            skip_indexes.push(SkippedSlots { fpga_index, slot_index });
+          }
+        }
+
+        ciphertext_index += 1;
+      }
+
+      unsafe {
+        xrtRunSetArg(self.runhandle_lwe_in[fpga_index], 1, *fpga_pack_size as u32);
+        xrtRunSetArg(self.runhandle_lwe_out[fpga_index], 1, *fpga_pack_size as u32);
+
+        xrtBOWrite(
+          self.devmem_lwe_in[fpga_index],
+          lwe_in_ptr as *const c_void,
+          lwe_in_dma_size,
+          0,
+        );
+        xrtBOSync(
+          self.devmem_lwe_in[fpga_index],
+          xclBOSyncDirection_XCL_BO_SYNC_BO_TO_DEVICE,
+          lwe_in_dma_size,
+          0,
+        );
+
+        dealloc(lwe_in_ptr as *mut u8, lwe_in_layout);
+      }
+    }
+
+    sizes
+  }
+
+  pub(crate) fn send_shortint_cts_to_fpga(
+    &self,
+    ciphertexts: &Vec<ShortintCiphertext>,
+    luts: &Vec<BelfortLookupTable>,
+    sizes: &Sizes,
+  ) -> Vec<SkippedSlots> {
+    // Keep track of the ciphertexts skipped from being bootstrap;
+    // i.e., the trivial-encrypted ciphertexts that does not need bootstrap
+    let mut skipped_slots = Vec::<SkippedSlots>::new();
+
+    let lwe_in_padded_size = sizes.lwe_in_padded_size;
+    let lwe_in_pad_size = sizes.lwe_in_pad_size;
+    let fpga_pack_sizes = &sizes.fpga_pack_sizes;
+
+    let mut ciphertext_index = 0;
+
+    for (fpga_index, fpga_pack_size) in fpga_pack_sizes.iter().enumerate() {
+      let lwe_in_dma_size = fpga_pack_size * lwe_in_padded_size * mem::size_of::<u32>();
+      let lwe_in_layout = Layout::from_size_align(lwe_in_dma_size, 4096).expect("Invalid layout");
+      let lwe_in_ptr = unsafe { alloc(lwe_in_layout) as *mut u32 };
+      assert!(!lwe_in_ptr.is_null());
+
+      let mut lwe_in_ptr_index = 0;
+
+      let mut slot_index = 0;
+
+      // move ciphertext's into FPGA memory buffer after modswitch
+      while slot_index < *fpga_pack_size {
+        if ciphertexts[ciphertext_index].is_trivial() {
+          skipped_slots.push(SkippedSlots { fpga_index, slot_index });
+        } else {
+          // modswitched ciphertext coeffs
+          for element in ciphertexts[ciphertext_index].ct.as_ref() {
+            let modswitched =
+              self.modulus_switch_from_u64_to_u32(*element, self.params.ks_base_log.0 * self.params.ks_level.0);
+            unsafe { ptr::write(lwe_in_ptr.add(lwe_in_ptr_index), modswitched as u32) };
+            lwe_in_ptr_index += 1;
+          }
+
+          // Pad accumulator index
+          unsafe { ptr::write(lwe_in_ptr.add(lwe_in_ptr_index), luts[ciphertext_index].index as u32) };
+
+          // Skip pad amount
+          lwe_in_ptr_index += lwe_in_pad_size - 1;
+
+          slot_index += 1;
+        }
+
+        ciphertext_index += 1;
+      }
+
+      unsafe {
+        xrtRunSetArg(self.runhandle_lwe_in[fpga_index], 1, *fpga_pack_size as u32);
+        xrtRunSetArg(self.runhandle_lwe_out[fpga_index], 1, *fpga_pack_size as u32);
+
+        xrtBOWrite(
+          self.devmem_lwe_in[fpga_index],
+          lwe_in_ptr as *const c_void,
+          lwe_in_dma_size,
+          0,
+        );
+        xrtBOSync(
+          self.devmem_lwe_in[fpga_index],
+          xclBOSyncDirection_XCL_BO_SYNC_BO_TO_DEVICE,
+          lwe_in_dma_size,
+          0,
+        );
+
+        dealloc(lwe_in_ptr as *mut u8, lwe_in_layout);
+      }
+    }
+
+    skipped_slots
+  }
+
+  pub(crate) fn execute_fpga_kernels(&self, sizes: &Sizes) {
+    let fpga_pack_sizes: &Vec<usize> = &sizes.fpga_pack_sizes;
+
+    // depending on the input sizes, there may not be data input for each fpga
+    unsafe {
+      let batchcounts: Vec<usize> = {
+        let inuse_fpga_count = fpga_pack_sizes.len();
+        let batch_size = self.params.batch_size;
+        (0..inuse_fpga_count)
+          .map(|fpga_index| {
+            let fpga_pack_size = fpga_pack_sizes[fpga_index];
+            (fpga_pack_size / batch_size).max(1)
+          })
+          .collect()
+      };
+
+      for (fpga_index, _) in fpga_pack_sizes.iter().enumerate() {
+        xrtRunStart(self.runhandle_lwe_in[fpga_index]);
+
+        for batch_index in 0..batchcounts[fpga_index] {
+          for kernel in self.runhandle_ksk[fpga_index][batch_index].iter() {
+            xrtRunStart(*kernel);
+          }
+          for kernel in self.runhandle_bsk[fpga_index][batch_index].iter() {
+            xrtRunStart(*kernel);
+          }
+        }
+
+        xrtRunStart(self.runhandle_lwe_out[fpga_index]);
+      }
+
+      //////////////////////////////////////////////////////////////////////////
+      // wait for runs; waiting for only the output is enough
+
+      // Should be unneccessary, as they should already be done, if the above
+      // waited output is done. However, we have to call waits, to be able to
+      // re-use the runHandles in low-level api.
+
+      for (fpga_index, _) in fpga_pack_sizes.iter().enumerate() {
+        xrtRunWait(self.runhandle_lwe_out[fpga_index]);
+      }
+
+      for (fpga_index, _) in fpga_pack_sizes.iter().enumerate() {
+        xrtRunWait(self.runhandle_lwe_in[fpga_index]);
+
+        for batch_index in 0..batchcounts[fpga_index] {
+          for kernel in self.runhandle_ksk[fpga_index][batch_index].iter() {
+            xrtRunWait(*kernel);
+          }
+          for kernel in self.runhandle_bsk[fpga_index][batch_index].iter() {
+            xrtRunWait(*kernel);
+          }
+        }
+      }
+    }
+  }
+
+  pub(crate) fn recv_boolean_cts_from_fpga(
+    &self,
+    ciphertexts: &mut Vec<BooleanCiphertext>,
+    sizes: &Sizes,
+    skip_indexes: &mut Vec<SkippedSlots>,
+  ) {
+    let lwe_out_size = sizes.lwe_out_size;
+    let lwe_out_padded_size = sizes.lwe_out_padded_size;
+    let fpga_pack_sizes: &Vec<usize> = &sizes.fpga_pack_sizes;
+
+    let mut ciphertext_index = 0;
+
+    for (fpga_index, fpga_pack_size) in fpga_pack_sizes.iter().enumerate() {
+      let lwe_out_dma_size = fpga_pack_size * lwe_out_padded_size * mem::size_of::<u32>();
+      let lwe_out_layout = Layout::from_size_align(lwe_out_dma_size, 4096).expect("Invalid layout");
+      let lwe_out_ptr = unsafe { alloc(lwe_out_layout) as *mut u32 };
+      assert!(!lwe_out_ptr.is_null());
+
+      let mut lwe_out_ptr_index = 0;
+
+      unsafe {
+        xrtBOSync(
+          self.devmem_lwe_out[fpga_index],
+          xclBOSyncDirection_XCL_BO_SYNC_BO_FROM_DEVICE,
+          lwe_out_dma_size,
+          0,
+        );
+        xrtBORead(
+          self.devmem_lwe_out[fpga_index],
+          lwe_out_ptr as *mut c_void,
+          lwe_out_dma_size,
+          0,
+        );
+      }
+
+      let mut slot_index = 0;
+      while slot_index < *fpga_pack_size {
+        let is_skipped_slot = skip_indexes.first().map_or(false, |skip| {
+          skip.fpga_index == fpga_index && skip.slot_index == slot_index
+        });
+
+        if is_skipped_slot {
+          skip_indexes.remove(0);
+          ciphertext_index += 1;
+
+          continue;
+        }
+
+        let lwe_out_slot_u32: &[u32] =
+          unsafe { slice::from_raw_parts(lwe_out_ptr.add(lwe_out_ptr_index), lwe_out_size) };
+
+        lwe_out_ptr_index += lwe_out_padded_size;
+
+        // Convert Vec<u32> to Ciphertext
+        // and assign to arg ciphertexts
+        ciphertexts[ciphertext_index] = BooleanCiphertext::Encrypted(LweCiphertext::from_container(
+          lwe_out_slot_u32.to_vec(),
+          CiphertextModulus::new_native(),
+        ));
+
+        ciphertext_index += 1;
+        slot_index += 1;
+      }
+
+      unsafe {
+        dealloc(lwe_out_ptr as *mut u8, lwe_out_layout);
+      }
+    }
+  }
+
+  pub(crate) fn recv_shortint_cts_from_fpga(
+    &self,
+    ciphertexts: &mut Vec<ShortintCiphertext>,
+    luts: &Vec<BelfortLookupTable>,
+    sizes: &Sizes,
+    skip_indexes: &mut Vec<SkippedSlots>,
+  ) {
+    let lwe_out_size = sizes.lwe_out_size;
+    let lwe_out_padded_size = sizes.lwe_out_padded_size;
+    let fpga_pack_sizes: &Vec<usize> = &sizes.fpga_pack_sizes;
+
+    let mut ciphertext_index = 0;
+
+    for (fpga_index, fpga_pack_size) in fpga_pack_sizes.iter().enumerate() {
+      let lwe_out_dma_size = fpga_pack_size * lwe_out_padded_size * mem::size_of::<u32>();
+      let lwe_out_layout = Layout::from_size_align(lwe_out_dma_size, 4096).expect("Invalid layout");
+      let lwe_out_ptr = unsafe { alloc(lwe_out_layout) as *mut u32 };
+      assert!(!lwe_out_ptr.is_null());
+
+      let mut lwe_out_ptr_index = 0;
+
+      unsafe {
+        xrtBOSync(
+          self.devmem_lwe_out[fpga_index],
+          xclBOSyncDirection_XCL_BO_SYNC_BO_FROM_DEVICE,
+          lwe_out_dma_size,
+          0,
+        );
+        xrtBORead(
+          self.devmem_lwe_out[fpga_index],
+          lwe_out_ptr as *mut c_void,
+          lwe_out_dma_size,
+          0,
+        );
+      }
+
+      let mut slot_index = 0;
+      while slot_index < *fpga_pack_size {
+        let is_skipped_slot = skip_indexes.first().map_or(false, |skip| {
+          skip.fpga_index == fpga_index && skip.slot_index == slot_index
+        });
+
+        if is_skipped_slot {
+          skip_indexes.remove(0);
+          ciphertext_index += 1;
+
+          continue;
+        }
+
+        let lwe_out_slot_u32: &[u32] =
+          unsafe { slice::from_raw_parts(lwe_out_ptr.add(lwe_out_ptr_index), lwe_out_size) };
+
+        lwe_out_ptr_index += lwe_out_padded_size;
+
+        let lwe_out_slot_u64: Vec<u64> = lwe_out_slot_u32.iter().map(|&x| (x as u64) << 32).collect();
+
+        // Convert Vec<u64> to Ciphertext
+        // and assign to arg ciphertexts
+        ciphertexts[ciphertext_index] = ShortintCiphertext::new(
+          LweCiphertext::from_container(lwe_out_slot_u64, self.params.ciphertext_modulus),
+          luts[ciphertext_index].degree,
+          NoiseLevel::NOMINAL,
+          self.params.message_modulus,
+          self.params.carry_modulus,
+          PBSOrder::KeyswitchBootstrap,
+        );
+
+        ciphertext_index += 1;
+        slot_index += 1;
+      }
+
+      unsafe {
+        dealloc(lwe_out_ptr as *mut u8, lwe_out_layout);
+      }
+    }
+  }
+}
diff --git a/tfhe/src/core_crypto/fpga/keyswitch_bootstrap_bench.rs b/tfhe/src/core_crypto/fpga/keyswitch_bootstrap_bench.rs
new file mode 100644
index 00000000..5e9a23e5
--- /dev/null
+++ b/tfhe/src/core_crypto/fpga/keyswitch_bootstrap_bench.rs
@@ -0,0 +1,65 @@
+#![allow(non_upper_case_globals)]
+#![allow(non_camel_case_types)]
+#![allow(non_snake_case)]
+// Supress not FFI-safe warning
+#![allow(improper_ctypes)]
+#![allow(dead_code)]
+#![allow(unused_unsafe)]
+
+include!(concat!(env!("OUT_DIR"), "/bindings.rs"));
+
+use crate::boolean::ciphertext::Ciphertext as BooleanCiphertext;
+use crate::shortint::ciphertext::Ciphertext as ShortintCiphertext;
+
+pub use crate::core_crypto::commons::parameters::CiphertextModulus;
+use crate::core_crypto::fpga::keyswitch_bootstrap::Sizes;
+use crate::core_crypto::fpga::keyswitch_bootstrap::SkippedSlots;
+use crate::core_crypto::fpga::luts::BelfortLookupTable;
+use crate::core_crypto::fpga::BelfortFpgaUtils;
+
+impl BelfortFpgaUtils {
+  pub fn bench_calculate_sizes(&self, pack_size: usize) -> Sizes {
+    self.calculate_sizes(pack_size)
+  }
+
+  pub fn bench_pre_boolean(
+    &self,
+    ciphertexts: &Vec<BooleanCiphertext>,
+    luts: &Vec<BelfortLookupTable>,
+    skip_indexes: &mut Vec<SkippedSlots>,
+  ) -> Sizes {
+    self.send_boolean_cts_to_fpga(ciphertexts, luts, skip_indexes)
+  }
+
+  pub fn bench_pre_shortint(
+    &self,
+    ciphertexts: &Vec<ShortintCiphertext>,
+    luts: &Vec<BelfortLookupTable>,
+    sizes: &Sizes,
+  ) {
+    self.send_shortint_cts_to_fpga(ciphertexts, luts, sizes);
+  }
+
+  pub fn bench_interface_fpga(&self, sizes: &Sizes) {
+    self.execute_fpga_kernels(sizes);
+  }
+
+  pub fn bench_post_boolean(
+    &self,
+    ciphertexts: &mut Vec<BooleanCiphertext>,
+    sizes: &Sizes,
+    skip_indexes: &mut Vec<SkippedSlots>,
+  ) {
+    self.recv_boolean_cts_from_fpga(ciphertexts, sizes, skip_indexes);
+  }
+
+  pub fn bench_post_shortint(
+    &self,
+    ciphertexts: &mut Vec<ShortintCiphertext>,
+    luts: &Vec<BelfortLookupTable>,
+    sizes: &Sizes,
+    skip_indexes: &mut Vec<SkippedSlots>,
+  ) {
+    self.recv_shortint_cts_from_fpga(ciphertexts, luts, sizes, skip_indexes);
+  }
+}
diff --git a/tfhe/src/core_crypto/fpga/luts.rs b/tfhe/src/core_crypto/fpga/luts.rs
new file mode 100644
index 00000000..5efb70a1
--- /dev/null
+++ b/tfhe/src/core_crypto/fpga/luts.rs
@@ -0,0 +1,1395 @@
+use crate::shortint::ciphertext::Degree;
+use crate::shortint::server_key::LookupTableOwned;
+use crate::shortint::MessageModulus;
+use crate::shortint::ServerKey;
+
+use std::cmp::Ordering;
+
+use super::BelfortFpgaLuts;
+
+#[derive(Copy, Clone, Debug)]
+pub struct BelfortLookupTable {
+  pub index: usize,
+  pub degree: Degree,
+}
+
+type LutGenFn = fn(&ServerKey) -> LookupTableOwned;
+
+#[derive(Clone, Debug)]
+struct LUT {
+  index: usize,
+  name: &'static str,
+  lut_generator: LutGenFn,
+}
+
+pub const IS_INFERIOR: u64 = 0;
+pub const IS_EQUAL: u64 = 1;
+pub const IS_SUPERIOR: u64 = 2;
+
+pub(crate) enum OutputCarry {
+  None = 0,
+  Generated = 1,
+  Propagated = 2,
+}
+
+pub(crate) enum BitValue {
+  Zero = 0,
+  One = 1,
+}
+
+const fn overflow_happened(overflow_sum: u64) -> bool {
+  overflow_sum != 0
+}
+
+const LUTS: [LUT; 133] = [
+  LUT {
+    index: 0,
+    name: "gates",
+    lut_generator: |s| s.generate_lookup_table(|_: u64| 1 << 61),
+  },
+  LUT {
+    index: 1,
+    name: "identity",
+    lut_generator: |s| s.generate_lookup_table(|x: u64| x),
+  },
+  LUT {
+    index: 2,
+    name: "msg2_extract",
+    lut_generator: |s| s.generate_lookup_table(|x| x % (s.message_modulus.0 as u64)),
+  },
+  LUT {
+    index: 3,
+    name: "carry2_extract",
+    lut_generator: |s| s.generate_lookup_table(|x| x / (s.message_modulus.0 as u64)),
+  },
+  LUT {
+    index: 4,
+    name: "mult_2lsb",
+    lut_generator: |s| {
+      s.generate_lookup_table_bivariate(|x, y| (x * y) % (s.message_modulus.0 as u64))
+        .acc
+    },
+  },
+  LUT {
+    index: 5,
+    name: "mult_2msb",
+    lut_generator: |s| {
+      s.generate_lookup_table_bivariate(|x, y| (x * y) / (s.message_modulus.0 as u64))
+        .acc
+    },
+  },
+  LUT {
+    index: 6,
+    name: "equal_vector",
+    lut_generator: |s| {
+      let equal_vector = [9u64, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0].to_vec();
+      s.generate_lookup_table_vector(&equal_vector)
+    },
+  },
+  LUT {
+    index: 7,
+    name: "equal_10_vector",
+    lut_generator: |s| {
+      let equal_10_vector = [1u64, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0].to_vec();
+      s.generate_lookup_table_vector(&equal_10_vector)
+    },
+  },
+  LUT {
+    index: 8,
+    name: "min_vector",
+    lut_generator: |s| {
+      let min_vector = [0u64, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0].to_vec();
+      s.generate_lookup_table_vector(&min_vector)
+    },
+  },
+  LUT {
+    index: 9,
+    name: "add_2lsb",
+    lut_generator: |s| s.generate_lookup_table_bivariate(|x, y| (x + y) % 4).acc,
+  },
+  LUT {
+    index: 10,
+    name: "add_2msb",
+    lut_generator: |s| s.generate_lookup_table_bivariate(|x, y| (x + y) / 4).acc,
+  },
+  LUT {
+    index: 11,
+    name: "add",
+    lut_generator: |s| s.generate_lookup_table_bivariate(|x, y| (x + y)).acc,
+  },
+  LUT {
+    index: 12,
+    name: "equal_to",
+    lut_generator: |s| s.generate_lookup_table_bivariate(|x, y| u64::from(x == y)).acc,
+  },
+  LUT {
+    index: 13,
+    name: "not_equal_to",
+    lut_generator: |s| s.generate_lookup_table_bivariate(|x, y| u64::from(x != y)).acc,
+  },
+  LUT {
+    index: 14,
+    name: "is_non_zero",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from(x != 0)),
+  },
+  LUT {
+    index: 15,
+    name: "reduce_two_orderings",
+
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let msb = (x >> 2) & 3;
+        let lsb = x & 3;
+
+        if msb == 1 {
+          lsb
+        } else {
+          msb
+        }
+      })
+    },
+  },
+  LUT {
+    index: 16,
+    name: "lhs_min_max",
+    lut_generator: |s| s.generate_lookup_table(|x| if x < 4 { x } else { 0 }),
+  },
+  LUT {
+    index: 17,
+    name: "rhs_min_max",
+    lut_generator: |s| s.generate_lookup_table(|x: u64| if x >= 4 { x - 4 } else { 0 }),
+  },
+  LUT {
+    index: 18,
+    name: "comparison_result",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from(x != 0) + 1),
+  },
+  LUT {
+    index: 19,
+    name: "is_equal_to_one",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) == 1 as u64)),
+  },
+  LUT {
+    index: 20,
+    name: "is_equal_to_two",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) == 2 as u64)),
+  },
+  LUT {
+    index: 21,
+    name: "is_equal_to_three",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) == 3 as u64)),
+  },
+  LUT {
+    index: 22,
+    name: "is_equal_to_four",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) == 4 as u64)),
+  },
+  LUT {
+    index: 23,
+    name: "is_equal_to_five",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) == 5 as u64)),
+  },
+  LUT {
+    index: 24,
+    name: "is_equal_to_eight",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) == 8 as u64)),
+  },
+  LUT {
+    index: 25,
+    name: "is_equal_to_nine",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) == 9 as u64)),
+  },
+  LUT {
+    index: 26,
+    name: "is_equal_to_max",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) == 15 as u64)),
+  },
+  LUT {
+    index: 27,
+    name: "gt_two_blocks",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let result = reduce_sign_block(x);
+
+        u64::from(result == IS_SUPERIOR)
+      })
+    },
+  },
+  LUT {
+    index: 28,
+    name: "ge_two_blocks",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let result = reduce_sign_block(x);
+
+        u64::from(result == IS_SUPERIOR || result == IS_EQUAL)
+      })
+    },
+  },
+  LUT {
+    index: 29,
+    name: "lt_two_blocks",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let result = reduce_sign_block(x);
+
+        u64::from(result == IS_INFERIOR)
+      })
+    },
+  },
+  LUT {
+    index: 30,
+    name: "le_two_blocks",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let result = reduce_sign_block(x);
+
+        u64::from(result == IS_INFERIOR || result == IS_EQUAL)
+      })
+    },
+  },
+  LUT {
+    index: 31,
+    name: "two_blocks_min_max",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let result = reduce_sign_block(x);
+
+        if result == 0 {
+          s.message_modulus.0 as u64
+        } else {
+          0
+        }
+      })
+    },
+  },
+  LUT {
+    index: 32,
+    name: "gt_one_block",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let result = x % 3;
+
+        u64::from(result == IS_SUPERIOR)
+      })
+    },
+  },
+  LUT {
+    index: 33,
+    name: "ge_one_block",
+
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let result = x % 3;
+
+        u64::from(result == IS_SUPERIOR || result == IS_EQUAL)
+      })
+    },
+  },
+  LUT {
+    index: 34,
+    name: "lt_one_block",
+
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let result = x % 3;
+
+        u64::from(result == IS_INFERIOR)
+      })
+    },
+  },
+  LUT {
+    index: 35,
+    name: "le_one_block",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let result = x % 3;
+
+        u64::from(result == IS_INFERIOR || result == IS_EQUAL)
+      })
+    },
+  },
+  LUT {
+    index: 36,
+    name: "one_block_min_max",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let result = x % 3;
+
+        if result == 0 {
+          s.message_modulus.0 as u64
+        } else {
+          0
+        }
+      })
+    },
+  },
+  LUT {
+    index: 37,
+    name: "compare_with_sign_bits",
+    lut_generator: |s| {
+      s.generate_lookup_table_bivariate(|x: u64, y: u64| {
+        let sign_bit_pos = s.message_modulus.0.ilog2() - 1;
+
+        let x_sign_bit = x >> sign_bit_pos;
+        let y_sign_bit = y >> sign_bit_pos;
+
+        if x_sign_bit == y_sign_bit {
+          match x.cmp(&y) {
+            std::cmp::Ordering::Less => IS_INFERIOR,
+            std::cmp::Ordering::Equal => IS_EQUAL,
+            std::cmp::Ordering::Greater => IS_SUPERIOR,
+          }
+        } else {
+          match x.cmp(&y) {
+            std::cmp::Ordering::Less => IS_SUPERIOR,
+            std::cmp::Ordering::Equal => IS_EQUAL,
+            std::cmp::Ordering::Greater => IS_INFERIOR,
+          }
+        }
+      })
+      .acc
+    },
+  },
+  LUT {
+    index: 38,
+    name: "neg",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        if (x % 4) == 0 {
+          3
+        } else if (x % 4) == 1 {
+          2
+        } else if (x % 4) == 2 {
+          1
+        } else {
+          0
+        }
+      })
+    },
+  },
+  LUT {
+    index: 39,
+    name: "msg_bit1_extract",
+    lut_generator: |s| s.generate_lookup_table(|x| (x >> 1) & 1),
+  },
+  LUT {
+    index: 40,
+    name: "msg_bit0_extract",
+    lut_generator: |s| s.generate_lookup_table(|x| x & 1),
+  },
+  LUT {
+    index: 41,
+    name: "msg_bit1_extract_offset2",
+    lut_generator: |s| s.generate_lookup_table(|x| ((x >> 1) & 1) << 2),
+  },
+  LUT {
+    index: 42,
+    name: "msg_bit0_extract_offset2",
+    lut_generator: |s| s.generate_lookup_table(|x| (x & 1) << 2),
+  },
+  LUT {
+    index: 43,
+    name: "mux",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let x = x & 7;
+        let control_bit = x >> 2;
+        let previous_bit = (x & 2) >> 1;
+        let current_bit = x & 1;
+
+        if control_bit == 1 {
+          previous_bit
+        } else {
+          current_bit
+        }
+      })
+    },
+  },
+  LUT {
+    index: 44,
+    name: "bitand",
+    lut_generator: |s| s.generate_lookup_table_bivariate(|x, y| x & y).acc,
+  },
+  LUT {
+    index: 45,
+    name: "bitor",
+    lut_generator: |s| s.generate_lookup_table_bivariate(|x, y| x | y).acc,
+  },
+  LUT {
+    index: 46,
+    name: "bitxor",
+    lut_generator: |s| s.generate_lookup_table_bivariate(|x, y| x ^ y).acc,
+  },
+  LUT {
+    index: 47,
+    name: "does_block_generate_carry",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        if x >= s.message_modulus.0 as u64 {
+          OutputCarry::Generated as u64
+        } else {
+          OutputCarry::None as u64
+        }
+      })
+    },
+  },
+  LUT {
+    index: 48,
+    name: "does_block_generate_or_propagate",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        if x >= s.message_modulus.0 as u64 {
+          OutputCarry::Generated as u64
+        } else if x == (s.message_modulus.0 as u64 - 1) {
+          OutputCarry::Propagated as u64
+        } else {
+          OutputCarry::None as u64
+        }
+      })
+    },
+  },
+  LUT {
+    index: 49,
+    name: "carry_propagation_sum",
+    lut_generator: |s| {
+      s.generate_lookup_table_bivariate(|msb, lsb| {
+        if msb == OutputCarry::Propagated as u64 {
+          lsb
+        } else {
+          msb
+        }
+      })
+      .acc
+    },
+  },
+  LUT {
+    index: 50,
+    name: "predicate",
+    lut_generator: |s| s.generate_lookup_table_bivariate(|x, y| if y == 1 { 0 } else { x }).acc,
+  },
+  LUT {
+    index: 51,
+    name: "inverted_predicate",
+    lut_generator: |s| s.generate_lookup_table_bivariate(|x, y| if y != 1 { 0 } else { x }).acc,
+  },
+  LUT {
+    index: 52,
+    name: "does_block_generate_borrow",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        if x < (s.message_modulus.0 as u64) {
+          OutputCarry::Generated as u64
+        } else {
+          OutputCarry::None as u64
+        }
+      })
+    },
+  },
+  LUT {
+    index: 53,
+    name: "does_block_generate_or_propagate_borrow",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| match x.cmp(&(s.message_modulus.0 as u64)) {
+        Ordering::Less => OutputCarry::Generated as u64,
+        Ordering::Equal => OutputCarry::Propagated as u64,
+        Ordering::Greater => OutputCarry::None as u64,
+      })
+    },
+  },
+  LUT {
+    index: 54,
+    name: "msg_bit0_overflow_flag",
+    lut_generator: |s| {
+      s.generate_lookup_table_bivariate(|x: u64, y: u64| u64::from(x == 0 && y == 0))
+        .acc
+    },
+  },
+  LUT {
+    index: 55,
+    name: "msg_bit1_overflow_flag",
+    lut_generator: |s| {
+      s.generate_lookup_table_bivariate(|x: u64, y: u64| u64::from(x == 0 && y == 0) << 1)
+        .acc
+    },
+  },
+  LUT {
+    index: 56,
+    name: "is_mod_equal_to_zero",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| u64::from(x % (s.message_modulus.0 * s.carry_modulus.0) as u64 == 0))
+    },
+  },
+  LUT {
+    index: 57,
+    name: "is_mod_not_equal_to_zero",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| u64::from(x % (s.message_modulus.0 * s.carry_modulus.0) as u64 != 0))
+    },
+  },
+  LUT {
+    index: 58,
+    name: "zero_out_if_overflow_did_not_happen_with_f1",
+    lut_generator: |s| {
+      s.generate_lookup_table_bivariate_with_factor(
+        |block: u64, overflow_sum| {
+          if overflow_happened(overflow_sum) {
+            block
+          } else {
+            0
+          }
+        },
+        MessageModulus(1),
+      )
+      .acc
+    },
+  },
+  LUT {
+    index: 59,
+    name: "zero_out_if_overflow_did_not_happen_with_f2",
+    lut_generator: |s| {
+      s.generate_lookup_table_bivariate_with_factor(
+        |block: u64, overflow_sum| {
+          if overflow_happened(overflow_sum) {
+            block
+          } else {
+            0
+          }
+        },
+        MessageModulus(2),
+      )
+      .acc
+    },
+  },
+  LUT {
+    index: 60,
+    name: "zero_out_if_overflow_did_not_happen_with_f3",
+    lut_generator: |s| {
+      s.generate_lookup_table_bivariate_with_factor(
+        |block: u64, overflow_sum| {
+          if overflow_happened(overflow_sum) {
+            block
+          } else {
+            0
+          }
+        },
+        MessageModulus(3),
+      )
+      .acc
+    },
+  },
+  LUT {
+    index: 61,
+    name: "zero_out_if_overflow_happened_with_f1",
+    lut_generator: |s| {
+      s.generate_lookup_table_bivariate_with_factor(
+        |block: u64, overflow_sum| {
+          if overflow_happened(overflow_sum) {
+            0
+          } else {
+            block
+          }
+        },
+        MessageModulus(1),
+      )
+      .acc
+    },
+  },
+  LUT {
+    index: 62,
+    name: "zero_out_if_overflow_happened_with_f2",
+    lut_generator: |s| {
+      s.generate_lookup_table_bivariate_with_factor(
+        |block: u64, overflow_sum| {
+          if overflow_happened(overflow_sum) {
+            0
+          } else {
+            block
+          }
+        },
+        MessageModulus(2),
+      )
+      .acc
+    },
+  },
+  LUT {
+    index: 63,
+    name: "zero_out_if_overflow_happened_with_f3",
+    lut_generator: |s| {
+      s.generate_lookup_table_bivariate_with_factor(
+        |block: u64, overflow_sum| {
+          if overflow_happened(overflow_sum) {
+            0
+          } else {
+            block
+          }
+        },
+        MessageModulus(3),
+      )
+      .acc
+    },
+  },
+  LUT {
+    index: 64,
+    name: "last_block_swb0",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let message_modulus = s.message_modulus.0 as u64;
+        let num_bits_in_block = message_modulus.ilog2() as u64;
+        let shift_within_block = 0;
+
+        let x = x % message_modulus;
+        let x_sign_bit = x >> (num_bits_in_block - 1) & 1;
+        let shifted = x >> shift_within_block;
+
+        let mut padding = (message_modulus - 1) * x_sign_bit;
+
+        padding <<= num_bits_in_block - shift_within_block;
+        padding %= message_modulus;
+
+        shifted | padding
+      })
+    },
+  },
+  LUT {
+    index: 65,
+    name: "last_block_swb1",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let message_modulus = s.message_modulus.0 as u64;
+        let num_bits_in_block = message_modulus.ilog2() as u64;
+        let shift_within_block = 1;
+
+        let x = x % message_modulus;
+        let x_sign_bit = x >> (num_bits_in_block - 1) & 1;
+        let shifted = x >> shift_within_block;
+
+        let mut padding = (message_modulus - 1) * x_sign_bit;
+
+        padding <<= num_bits_in_block - shift_within_block;
+        padding %= message_modulus;
+
+        shifted | padding
+      })
+    },
+  },
+  LUT {
+    index: 66,
+    name: "pad_block_creator",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let message_modulus = s.message_modulus.0 as u64;
+        let num_bits_in_block = s.message_modulus.0.ilog2() as u64;
+
+        let x = x % message_modulus;
+        let x_sign_bit = x >> (num_bits_in_block - 1) & 1;
+
+        (message_modulus - 1) * x_sign_bit
+      })
+    },
+  },
+  LUT {
+    index: 67,
+    name: "shift_and_propagate_swb0",
+    lut_generator: |s| {
+      s.generate_lookup_table_bivariate(|current_block, mut next_block| {
+        let message_modulus = s.message_modulus.0 as u64;
+        let num_bits_in_block = message_modulus.ilog2() as u64;
+        let shift_within_block = 0;
+
+        next_block <<= num_bits_in_block;
+        next_block >>= shift_within_block;
+
+        let message_of_current_block = current_block >> shift_within_block;
+        let carry_of_previous_block = next_block % message_modulus;
+
+        message_of_current_block + carry_of_previous_block
+      })
+      .acc
+    },
+  },
+  LUT {
+    index: 68,
+    name: "shift_and_propagate_swb1",
+    lut_generator: |s| {
+      s.generate_lookup_table_bivariate(|current_block, mut next_block| {
+        // left shift so as not to lose
+        // bits when shifting right afterwards
+        let message_modulus = s.message_modulus.0 as u64;
+        let num_bits_in_block = message_modulus.ilog2() as u64;
+        let shift_within_block = 1;
+
+        next_block <<= num_bits_in_block;
+        next_block >>= shift_within_block;
+
+        // The way of getting carry / message is reversed compared
+        // to the usual way but its normal:
+        // The message is in the upper bits, the carry in lower bits
+        let message_of_current_block = current_block >> shift_within_block;
+        let carry_of_previous_block = next_block % message_modulus;
+
+        message_of_current_block + carry_of_previous_block
+      })
+      .acc
+    },
+  },
+  LUT {
+    index: 69,
+    name: "create_blocks_swb1",
+    lut_generator: |s| {
+      s.generate_lookup_table_bivariate(|previous_block, current_block| {
+        let message_modulus = s.message_modulus.0 as u64;
+        let shift_within_block = 1;
+
+        let current_block = current_block << shift_within_block;
+        let previous_block = previous_block << shift_within_block;
+
+        let message_of_current_block = current_block % message_modulus;
+        let carry_of_previous_block = previous_block / message_modulus;
+        message_of_current_block + carry_of_previous_block
+      })
+      .acc
+    },
+  },
+  LUT {
+    index: 70,
+    name: "shift1_mod",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let modulus = s.message_modulus.0 as u64;
+        (x << 1) % modulus
+      })
+    },
+  },
+  // TODO: Remove this, since duplicated in scalar_bitand_two
+  LUT {
+    index: 71,
+    name: "masking_lut_bit1",
+    lut_generator: |s| s.generate_lookup_table(|x| x & 2),
+  },
+  LUT {
+    index: 72,
+    name: "right_shift_1",
+    lut_generator: |s| s.generate_lookup_table(|x| x >> 1),
+  },
+  LUT {
+    index: 73,
+    name: "is_equal_to_zero",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) == 0 as u64)),
+  },
+  LUT {
+    index: 74,
+    name: "is_equal_to_six",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) == 6 as u64)),
+  },
+  LUT {
+    index: 75,
+    name: "is_equal_to_seven",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) == 7 as u64)),
+  },
+  LUT {
+    index: 76,
+    name: "is_equal_to_ten",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) == 10 as u64)),
+  },
+  LUT {
+    index: 77,
+    name: "is_equal_to_eleven",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) == 11 as u64)),
+  },
+  LUT {
+    index: 78,
+    name: "is_equal_to_twelve",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) == 12 as u64)),
+  },
+  LUT {
+    index: 79,
+    name: "is_equal_to_thirteen",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) == 13 as u64)),
+  },
+  LUT {
+    index: 80,
+    name: "is_equal_to_fourteen",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) == 14 as u64)),
+  },
+  LUT {
+    index: 81,
+    name: "is_not_equal_to_zero",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) != 0 as u64)),
+  },
+  LUT {
+    index: 82,
+    name: "is_not_equal_to_one",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) != 1 as u64)),
+  },
+  LUT {
+    index: 83,
+    name: "is_not_equal_to_two",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) != 2 as u64)),
+  },
+  LUT {
+    index: 84,
+    name: "is_not_equal_to_three",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) != 3 as u64)),
+  },
+  LUT {
+    index: 85,
+    name: "is_not_equal_to_four",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) != 4 as u64)),
+  },
+  LUT {
+    index: 86,
+    name: "is_not_equal_to_five",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) != 5 as u64)),
+  },
+  LUT {
+    index: 87,
+    name: "is_not_equal_to_six",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) != 6 as u64)),
+  },
+  LUT {
+    index: 88,
+    name: "is_not_equal_to_seven",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) != 7 as u64)),
+  },
+  LUT {
+    index: 89,
+    name: "is_not_equal_to_eight",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) != 8 as u64)),
+  },
+  LUT {
+    index: 90,
+    name: "is_not_equal_to_nine",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) != 9 as u64)),
+  },
+  LUT {
+    index: 91,
+    name: "is_not_equal_to_ten",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) != 10 as u64)),
+  },
+  LUT {
+    index: 92,
+    name: "is_not_equal_to_eleven",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) != 11 as u64)),
+  },
+  LUT {
+    index: 93,
+    name: "is_not_equal_to_twelve",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) != 12 as u64)),
+  },
+  LUT {
+    index: 94,
+    name: "is_not_equal_to_thirteen",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) != 13 as u64)),
+  },
+  LUT {
+    index: 95,
+    name: "is_not_equal_to_fourteen",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) != 14 as u64)),
+  },
+  LUT {
+    index: 96,
+    name: "is_not_equal_to_max",
+    lut_generator: |s| s.generate_lookup_table(|x| u64::from((x & 15 as u64) != 15 as u64)),
+  },
+  LUT {
+    index: 97,
+    name: "scalar_bitand_zero",
+    lut_generator: |s| s.generate_lookup_table(|x| x & 0),
+  },
+  LUT {
+    index: 98,
+    name: "scalar_bitand_one",
+    lut_generator: |s| s.generate_lookup_table(|x| x & 1),
+  },
+  LUT {
+    index: 99,
+    name: "scalar_bitand_two",
+    lut_generator: |s| s.generate_lookup_table(|x| x & 2),
+  },
+  LUT {
+    index: 100,
+    name: "scalar_bitand_three",
+    lut_generator: |s| s.generate_lookup_table(|x| x & 3),
+  },
+  LUT {
+    index: 101,
+    name: "scalar_bitor_zero",
+    lut_generator: |s| s.generate_lookup_table(|x| x | 0),
+  },
+  LUT {
+    index: 102,
+    name: "scalar_bitor_one",
+    lut_generator: |s| s.generate_lookup_table(|x| x | 1),
+  },
+  LUT {
+    index: 103,
+    name: "scalar_bitor_two",
+    lut_generator: |s| s.generate_lookup_table(|x| x | 2),
+  },
+  LUT {
+    index: 104,
+    name: "scalar_bitor_three",
+    lut_generator: |s| s.generate_lookup_table(|x| x | 3),
+  },
+  LUT {
+    index: 105,
+    name: "scalar_bitxor_zero",
+    lut_generator: |s| s.generate_lookup_table(|x| x ^ 0),
+  },
+  LUT {
+    index: 106,
+    name: "scalar_bitxor_one",
+    lut_generator: |s| s.generate_lookup_table(|x| x ^ 1),
+  },
+  LUT {
+    index: 107,
+    name: "scalar_bitxor_two",
+    lut_generator: |s| s.generate_lookup_table(|x| x ^ 2),
+  },
+  LUT {
+    index: 108,
+    name: "scalar_bitxor_three",
+    lut_generator: |s| s.generate_lookup_table(|x| x ^ 3),
+  },
+  LUT {
+    index: 109,
+    name: "sign_bit_is_set",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let sign_bit_pos = s.message_modulus.0.ilog2() - 1;
+        let sign_bit_is_set = 1;
+        let x = x % s.message_modulus.0 as u64;
+        let numerator_sign_bit_is_set = (x >> sign_bit_pos) & 1;
+        let numerator_and_divisor_sign_differs = numerator_sign_bit_is_set != sign_bit_is_set;
+
+        if numerator_and_divisor_sign_differs {
+          s.message_modulus.0 as u64 - 1
+        } else {
+          0
+        }
+      })
+    },
+  },
+  LUT {
+    index: 110,
+    name: "sign_bit_is_not_set",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let sign_bit_pos = s.message_modulus.0.ilog2() - 1;
+        let sign_bit_is_set = 0;
+        let x = x % s.message_modulus.0 as u64;
+        let numerator_sign_bit_is_set = (x >> sign_bit_pos) & 1;
+        let numerator_and_divisor_sign_differs = numerator_sign_bit_is_set != sign_bit_is_set;
+
+        if numerator_and_divisor_sign_differs {
+          s.message_modulus.0 as u64 - 1
+        } else {
+          0
+        }
+      })
+    },
+  },
+  LUT {
+    index: 111,
+    name: "two_blocks_gt_scalar",
+    lut_generator: |s| {
+      s.generate_lookup_table_bivariate(|lsb, msb| {
+        let msb = if msb == 1 { IS_EQUAL } else { IS_SUPERIOR };
+
+        let x = (msb << 2) + lsb;
+
+        let m = (x >> 2) & 3;
+        let l = x & 3;
+
+        let final_sign = if m == IS_EQUAL { l } else { m };
+
+        u64::from(final_sign == IS_SUPERIOR)
+      })
+      .acc
+    },
+  },
+  LUT {
+    index: 112,
+    name: "two_blocks_ge_scalar",
+    lut_generator: |s| {
+      s.generate_lookup_table_bivariate(|lsb, msb| {
+        let msb = if msb == 1 { IS_EQUAL } else { IS_SUPERIOR };
+
+        let x = (msb << 2) + lsb;
+
+        let m = (x >> 2) & 3;
+        let l = x & 3;
+
+        let final_sign = if m == IS_EQUAL { l } else { m };
+
+        u64::from(final_sign == IS_SUPERIOR || final_sign == IS_EQUAL)
+      })
+      .acc
+    },
+  },
+  LUT {
+    index: 113,
+    name: "two_blocks_lt_scalar",
+    lut_generator: |s| {
+      s.generate_lookup_table_bivariate(|lsb, msb| {
+        let msb = if msb == 1 { IS_EQUAL } else { IS_SUPERIOR };
+
+        let x = (msb << 2) + lsb;
+
+        let m = (x >> 2) & 3;
+        let l = x & 3;
+
+        let final_sign = if m == IS_EQUAL { l } else { m };
+
+        u64::from(final_sign == IS_INFERIOR)
+      })
+      .acc
+    },
+  },
+  LUT {
+    index: 114,
+    name: "two_blocks_le_scalar",
+    lut_generator: |s| {
+      s.generate_lookup_table_bivariate(|lsb, msb| {
+        let msb = if msb == 1 { IS_EQUAL } else { IS_SUPERIOR };
+
+        let x = (msb << 2) + lsb;
+
+        let m = (x >> 2) & 3;
+        let l = x & 3;
+
+        let final_sign = if m == IS_EQUAL { l } else { m };
+
+        u64::from(final_sign == IS_INFERIOR || final_sign == IS_EQUAL)
+      })
+      .acc
+    },
+  },
+  LUT {
+    index: 115,
+    name: "two_blocks_scalar_general",
+    lut_generator: |s| {
+      s.generate_lookup_table_bivariate(|lsb, msb| {
+        let msb = if msb == 1 { IS_EQUAL } else { IS_SUPERIOR };
+
+        let x = (msb << 2) + lsb;
+        let m = (x >> 2) & 3;
+        let l = x & 3;
+
+        if m == IS_EQUAL {
+          l
+        } else {
+          m
+        }
+      })
+      .acc
+    },
+  },
+  LUT {
+    index: 116,
+    name: "one_block_scalar_gt",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let x = if x == 1 { IS_EQUAL } else { IS_SUPERIOR };
+        u64::from(x == IS_SUPERIOR)
+      })
+    },
+  },
+  LUT {
+    index: 117,
+    name: "one_block_scalar_ge",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let x = if x == 1 { IS_EQUAL } else { IS_SUPERIOR };
+        u64::from(x == IS_SUPERIOR || x == IS_EQUAL)
+      })
+    },
+  },
+  LUT {
+    index: 118,
+    name: "one_block_scalar_lt",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let x = if x == 1 { IS_EQUAL } else { IS_SUPERIOR };
+        u64::from(x == IS_INFERIOR)
+      })
+    },
+  },
+  LUT {
+    index: 119,
+    name: "one_block_scalar_le",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let x = if x == 1 { IS_EQUAL } else { IS_SUPERIOR };
+        u64::from(x == IS_INFERIOR || x == IS_EQUAL)
+      })
+    },
+  },
+  LUT {
+    index: 120,
+    name: "one_block_scalar_general",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let x = if x == 1 { IS_EQUAL } else { IS_SUPERIOR };
+        x
+      })
+    },
+  },
+  LUT {
+    index: 121,
+    name: "trailing_bits_one",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let x = x % s.message_modulus.0 as u64;
+
+        let mut count = 0;
+        for i in 0..s.message_modulus.0.ilog2() {
+          if (x >> i) & 1 == BitValue::Zero as u64 {
+            break;
+          }
+          count += 1;
+        }
+        count
+      })
+    },
+  },
+  LUT {
+    index: 122,
+    name: "trailing_bits_zero",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let x = x % s.message_modulus.0 as u64;
+
+        let mut count = 0;
+        for i in 0..s.message_modulus.0.ilog2() {
+          if (x >> i) & 1 == BitValue::One as u64 {
+            break;
+          }
+          count += 1;
+        }
+        count
+      })
+    },
+  },
+  LUT {
+    index: 123,
+    name: "leading_bits_one",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let x = x % s.message_modulus.0 as u64;
+
+        let mut count = 0;
+        for i in (0..s.message_modulus.0.ilog2()).rev() {
+          if (x >> i) & 1 == BitValue::Zero as u64 {
+            break;
+          }
+          count += 1;
+        }
+        count
+      })
+    },
+  },
+  LUT {
+    index: 124,
+    name: "leading_bits_zero",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let x = x % s.message_modulus.0 as u64;
+
+        let mut count = 0;
+        for i in (0..s.message_modulus.0.ilog2()).rev() {
+          if (x >> i) & 1 == BitValue::One as u64 {
+            break;
+          }
+          count += 1;
+        }
+        count
+      })
+    },
+  },
+  LUT {
+    index: 125,
+    name: "trailing_bits_sum",
+    lut_generator: |s| {
+      s.generate_lookup_table_bivariate(|block_num_bit_count, more_significant_block_bit_count| {
+        if more_significant_block_bit_count == (s.message_modulus.0.ilog2() as u64) {
+          block_num_bit_count
+        } else {
+          0
+        }
+      })
+      .acc
+    },
+  },
+  LUT {
+    index: 126,
+    name: "carry_generation",
+    lut_generator: |s| s.generate_lookup_table_bivariate(|x, y| ((x + y) >= 3) as u64).acc,
+  },
+  LUT {
+    index: 127,
+    name: "sum",
+    lut_generator: |s| {
+      s.generate_lookup_table_bivariate(|x, y| {
+        let s = (x + (u64::MAX - 3) * ((x == 3) as u64)) as i64;
+        let c = y as i64;
+        ((c + s) as u64) % 4
+      })
+      .acc
+    },
+  },
+  LUT {
+    index: 128,
+    name: "extract_bitnot_msg",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        // extract message
+        let x = x % s.message_modulus.0 as u64;
+        // bitnot the message
+        (!x) % s.message_modulus.0 as u64
+      })
+    },
+  },
+  LUT {
+    index: 129,
+    name: "extract_bitnot_carry",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        // extract carry
+        let x = x / s.message_modulus.0 as u64;
+        // bitnot the carry
+        (!x) % s.message_modulus.0 as u64
+      })
+    },
+  },
+  LUT {
+    index: 130,
+    name: "general_one_block",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let result = x % 3;
+
+        result
+      })
+    },
+  },
+  LUT {
+    index: 131,
+    name: "general_two_blocks",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let msb = (x >> 2) & 3;
+        let lsb = x & 3;
+
+        if msb == IS_EQUAL {
+          lsb
+        } else {
+          msb
+        }
+      })
+    },
+  },
+  LUT {
+    index: 132,
+    name: "padding_block_creator",
+    lut_generator: |s| {
+      s.generate_lookup_table(|x| {
+        let message_modulus = s.message_modulus.0 as u64;
+        let x = x % message_modulus as u64;
+        let num_bits_in_block = message_modulus.ilog2();
+        let x_sign_bit = x >> (num_bits_in_block - 1) & 1;
+        // padding is a message full of 1 if sign bit is one
+        // else padding is a zero message
+        (message_modulus - 1) * x_sign_bit
+      })
+    },
+  },
+];
+
+impl BelfortFpgaLuts {
+  pub fn lut_count() -> usize {
+    LUTS.len()
+  }
+
+  pub fn lut_by_name(name: &str, server_key: &ServerKey) -> BelfortLookupTable {
+    for l in &LUTS {
+      if l.name == name {
+        let belfort_lut = BelfortLookupTable {
+          index: l.index,
+          degree: (l.lut_generator)(server_key).degree,
+        };
+        return belfort_lut;
+      }
+    }
+    panic!("LUT [name {}] not found", name);
+  }
+
+  pub fn lut_by_index(index: usize, server_key: &ServerKey) -> BelfortLookupTable {
+    for l in &LUTS {
+      if l.index == index {
+        let belfort_lut = BelfortLookupTable {
+          index: l.index,
+          degree: (l.lut_generator)(server_key).degree,
+        };
+        return belfort_lut;
+      }
+    }
+    panic!("LUT [index {}] not found", index);
+  }
+
+  pub fn boolean_lut() -> BelfortLookupTable {
+    let name = "gates";
+    for l in &LUTS {
+      if l.name == name {
+        let belfort_lut = BelfortLookupTable {
+          index: l.index,
+          degree: Degree::new(0),
+        };
+        return belfort_lut;
+      }
+    }
+    panic!("LUT [name {}] not found", name);
+  }
+
+  pub fn name_by_index(lut_index: usize) -> String {
+    for l in &LUTS {
+      if l.index == lut_index {
+        return l.name.to_string();
+      }
+    }
+    panic!("LUT [index {}] not found", lut_index);
+  }
+
+  pub fn lut_generator_by_index(index: usize) -> LutGenFn {
+    for l in &LUTS {
+      if l.index == index {
+        return l.lut_generator;
+      }
+    }
+    panic!("LUT [index {}] not found", index);
+  }
+
+  pub fn get_lut_acc(lut: &BelfortLookupTable, server_key: &ServerKey) -> LookupTableOwned {
+    for l in &LUTS {
+      if l.index == lut.index {
+        return (l.lut_generator)(server_key);
+      }
+    }
+    panic!("LUT is not found");
+  }
+}
+
+pub fn reduce_sign_block(x: u64) -> u64 {
+  let relevant_bits: u64 = 3;
+
+  // Zero out irrelevant bits
+  let msb = (x >> 2) & relevant_bits;
+  let lsb = x & relevant_bits;
+
+  if msb == IS_EQUAL {
+    lsb
+  } else {
+    msb
+  }
+}
diff --git a/tfhe/src/core_crypto/fpga/mod.rs b/tfhe/src/core_crypto/fpga/mod.rs
new file mode 100644
index 00000000..c3552e47
--- /dev/null
+++ b/tfhe/src/core_crypto/fpga/mod.rs
@@ -0,0 +1,105 @@
+pub mod keyswitch_bootstrap;
+pub mod keyswitch_bootstrap_bench;
+pub mod luts;
+pub mod parameters;
+pub mod utils;
+
+use crate::core_crypto::fpga::parameters::*;
+use std::os::raw::c_void;
+
+use crate::boolean::prelude::BooleanParameters;
+use crate::shortint::ClassicPBSParameters as ShortintParametes;
+
+////////////////////////////////////////////////////////////////////////////////
+
+pub const MAX_FPGA_COUNT: usize = crate::core_crypto::fpga::parameters::MAX_FPGA_COUNT;
+
+////////////////////////////////////////////////////////////////////////////////
+
+pub struct BelfortFpgaLuts;
+
+////////////////////////////////////////////////////////////////////////////////
+
+#[derive(Clone, Debug)]
+pub struct BelfortFpgaUtils {
+  pub params: FpgaParameters,
+  pub xclbin_uuid: Vec<u8>,
+  pub fpga_device: Vec<*mut c_void>,
+  pub kernelhandle_lwe_in: Vec<*mut c_void>,
+  pub kernelhandle_lwe_out: Vec<*mut c_void>,
+  pub kernelhandle_ksk: Vec<Vec<*mut c_void>>,
+  pub kernelhandle_bsk: Vec<Vec<*mut c_void>>,
+  pub devmem_lwe_in: Vec<*mut c_void>,
+  pub devmem_lwe_out: Vec<*mut c_void>,
+  pub devmem_ksk: Vec<Vec<*mut c_void>>,
+  pub devmem_bsk: Vec<Vec<*mut c_void>>,
+  pub runhandle_lwe_in: Vec<*mut c_void>,
+  pub runhandle_lwe_out: Vec<*mut c_void>,
+  pub runhandle_ksk: Vec<Vec<Vec<*mut c_void>>>,
+  pub runhandle_bsk: Vec<Vec<Vec<*mut c_void>>>,
+  pub enabled_fpga_count: usize,
+  pub is_connected: bool,
+}
+
+pub enum BaseParameters {
+  Shortint(ShortintParametes),
+  Boolean(BooleanParameters),
+}
+
+impl BelfortFpgaUtils {
+  pub fn default(base_params: BaseParameters) -> Self {
+    let params = match base_params {
+      BaseParameters::Boolean(p) => FpgaParameters::from(p),
+      BaseParameters::Shortint(p) => FpgaParameters::from(p),
+    };
+
+    Self {
+      params: params,
+      xclbin_uuid: Vec::new(),
+      fpga_device: Vec::with_capacity(MAX_FPGA_COUNT),
+      kernelhandle_lwe_in: Vec::with_capacity(MAX_FPGA_COUNT),
+      kernelhandle_lwe_out: Vec::with_capacity(MAX_FPGA_COUNT),
+      kernelhandle_ksk: Vec::with_capacity(MAX_FPGA_COUNT),
+      kernelhandle_bsk: Vec::with_capacity(MAX_FPGA_COUNT),
+      devmem_lwe_in: Vec::with_capacity(MAX_FPGA_COUNT),
+      devmem_lwe_out: Vec::with_capacity(MAX_FPGA_COUNT),
+      devmem_ksk: Vec::with_capacity(MAX_FPGA_COUNT),
+      devmem_bsk: Vec::with_capacity(MAX_FPGA_COUNT),
+      runhandle_lwe_in: Vec::with_capacity(MAX_FPGA_COUNT),
+      runhandle_lwe_out: Vec::with_capacity(MAX_FPGA_COUNT),
+      runhandle_ksk: Vec::with_capacity(MAX_FPGA_COUNT),
+      runhandle_bsk: Vec::with_capacity(MAX_FPGA_COUNT),
+      enabled_fpga_count: 0,
+      is_connected: false,
+    }
+  }
+
+  pub fn default_integer() -> Self {
+    Self::default(BaseParameters::Shortint(
+      crate::shortint::parameters::PARAM_MESSAGE_2_CARRY_2,
+    ))
+  }
+
+  pub fn default_boolean() -> Self {
+    Self::default(BaseParameters::Boolean(
+      crate::boolean::parameters::DEFAULT_PARAMETERS_KS_PBS,
+    ))
+  }
+}
+
+////////////////////////////////////////////////////////////////////////////////
+// from() function differs for ShortintServerKey / BooleanServerKey
+
+impl From<ShortintParametes> for BelfortFpgaUtils {
+  fn from(params: ShortintParametes) -> Self {
+    Self::default(BaseParameters::Shortint(params))
+  }
+}
+
+impl From<BooleanParameters> for BelfortFpgaUtils {
+  fn from(params: BooleanParameters) -> Self {
+    Self::default(BaseParameters::Boolean(params))
+  }
+}
+
+pub mod accelerators;
diff --git a/tfhe/src/core_crypto/fpga/parameters.rs b/tfhe/src/core_crypto/fpga/parameters.rs
new file mode 100644
index 00000000..5082075c
--- /dev/null
+++ b/tfhe/src/core_crypto/fpga/parameters.rs
@@ -0,0 +1,113 @@
+use crate::boolean::parameters::BooleanParameters;
+use crate::shortint::parameters::ClassicPBSParameters;
+
+use crate::core_crypto::commons::parameters::{
+  DecompositionBaseLog, DecompositionLevelCount, GlweDimension, LweDimension, PolynomialSize,
+};
+use crate::shortint::{CarryModulus, CiphertextModulus, MessageModulus};
+
+pub const MAX_FPGA_COUNT: usize = 4;
+
+#[derive(Copy, Clone, Debug)]
+pub struct ContainerParameters {
+  pub fpga_image: &'static str,
+  pub batch_size: usize,
+  pub streaming_size: usize,
+  pub bsk_num_kernels: usize,
+  pub ksk_num_kernels: usize,
+  pub bsk_bits: usize,
+  pub bsk_frac_bits: usize,
+  pub ksk_bits: usize,
+}
+
+#[derive(Copy, Clone, Debug)]
+pub struct FpgaParameters {
+  // TFHE Parameters
+  pub lwe_dimension: LweDimension,
+  pub glwe_dimension: GlweDimension,
+  pub polynomial_size: PolynomialSize,
+  pub pbs_base_log: DecompositionBaseLog,
+  pub pbs_level: DecompositionLevelCount,
+  pub ks_base_log: DecompositionBaseLog,
+  pub ks_level: DecompositionLevelCount,
+  pub message_modulus: MessageModulus,
+  pub carry_modulus: CarryModulus,
+  pub ciphertext_modulus: CiphertextModulus,
+  // Container Parameters
+  pub fpga_image: &'static str,
+  pub batch_size: usize,
+  pub streaming_size: usize,
+  pub bsk_num_kernels: usize,
+  pub ksk_num_kernels: usize,
+  pub bsk_bits: usize,
+  pub bsk_frac_bits: usize,
+  pub ksk_bits: usize,
+}
+
+impl From<(ContainerParameters, ClassicPBSParameters)> for FpgaParameters {
+  fn from(tuple: (ContainerParameters, ClassicPBSParameters)) -> Self {
+    let (container_params, shortint_params) = tuple;
+    Self {
+      // TFHE Parameters
+      lwe_dimension: shortint_params.lwe_dimension,
+      glwe_dimension: shortint_params.glwe_dimension,
+      polynomial_size: shortint_params.polynomial_size,
+      pbs_base_log: shortint_params.pbs_base_log,
+      pbs_level: shortint_params.pbs_level,
+      ks_base_log: shortint_params.ks_base_log,
+      ks_level: shortint_params.ks_level,
+      message_modulus: shortint_params.message_modulus,
+      carry_modulus: shortint_params.carry_modulus,
+      ciphertext_modulus: shortint_params.ciphertext_modulus,
+      // Container Parameters
+      fpga_image: container_params.fpga_image,
+      batch_size: container_params.batch_size,
+      streaming_size: container_params.streaming_size,
+      bsk_num_kernels: container_params.bsk_num_kernels,
+      ksk_num_kernels: container_params.ksk_num_kernels,
+      bsk_bits: container_params.bsk_bits,
+      bsk_frac_bits: container_params.bsk_frac_bits,
+      ksk_bits: container_params.ksk_bits,
+    }
+  }
+}
+
+impl From<(ContainerParameters, BooleanParameters)> for FpgaParameters {
+  fn from(tuple: (ContainerParameters, BooleanParameters)) -> Self {
+    let (container_params, boolean_params) = tuple;
+    Self {
+      // TFHE Parameters
+      lwe_dimension: boolean_params.lwe_dimension,
+      glwe_dimension: boolean_params.glwe_dimension,
+      polynomial_size: boolean_params.polynomial_size,
+      pbs_base_log: boolean_params.pbs_base_log,
+      pbs_level: boolean_params.pbs_level,
+      ks_base_log: boolean_params.ks_base_log,
+      ks_level: boolean_params.ks_level,
+      message_modulus: MessageModulus(0),
+      carry_modulus: CarryModulus(0),
+      ciphertext_modulus: CiphertextModulus::new_native(),
+      // Container Parameters
+      fpga_image: container_params.fpga_image,
+      batch_size: container_params.batch_size,
+      streaming_size: container_params.streaming_size,
+      bsk_num_kernels: container_params.bsk_num_kernels,
+      ksk_num_kernels: container_params.ksk_num_kernels,
+      bsk_bits: container_params.bsk_bits,
+      bsk_frac_bits: container_params.bsk_frac_bits,
+      ksk_bits: container_params.ksk_bits,
+    }
+  }
+}
+
+impl From<ClassicPBSParameters> for FpgaParameters {
+  fn from(params: ClassicPBSParameters) -> Self {
+    crate::core_crypto::fpga::accelerators::mappings::map_shortint_params(params)
+  }
+}
+
+impl From<BooleanParameters> for FpgaParameters {
+  fn from(params: BooleanParameters) -> Self {
+    crate::core_crypto::fpga::accelerators::mappings::map_boolean_params(params)
+  }
+}
diff --git a/tfhe/src/core_crypto/fpga/rustfmt.toml b/tfhe/src/core_crypto/fpga/rustfmt.toml
new file mode 100644
index 00000000..2ae9699b
--- /dev/null
+++ b/tfhe/src/core_crypto/fpga/rustfmt.toml
@@ -0,0 +1,2 @@
+tab_spaces = 2
+max_width = 120
\ No newline at end of file
diff --git a/tfhe/src/core_crypto/fpga/utils.rs b/tfhe/src/core_crypto/fpga/utils.rs
new file mode 100644
index 00000000..61d22993
--- /dev/null
+++ b/tfhe/src/core_crypto/fpga/utils.rs
@@ -0,0 +1,869 @@
+#![allow(non_upper_case_globals)]
+#![allow(non_camel_case_types)]
+#![allow(non_snake_case)]
+// Supress not FFI-safe warning
+#![allow(improper_ctypes)]
+#![allow(dead_code)]
+
+include!(concat!(env!("OUT_DIR"), "/bindings.rs"));
+
+use crate::core_crypto::fpga::parameters::*;
+use crate::core_crypto::fpga::BelfortFpgaUtils;
+use crate::core_crypto::prelude::*;
+
+use std::ffi::CString;
+use std::mem;
+use std::os::raw::c_void;
+
+use crate::boolean::server_key::ServerKey as BooleanServerKey;
+use crate::shortint::server_key::ServerKey as ShortintServerKey;
+use crate::shortint::server_key::ShortintBootstrappingKey;
+
+////////////////////////////////////////////////////////////////////////////////
+
+pub const MAX_FPGA_COUNT: usize = crate::core_crypto::fpga::parameters::MAX_FPGA_COUNT;
+
+pub const MAX_BATCH_COUNT: usize = 1024;
+//
+// This is used for preallocating MAX_BATCH_COUNT times memories and runhandles
+// for ksk and bsk. These are kind of reservations, that will be re-used
+// later at run time, executing bootstraps. We do the reservation in
+// enable_fpga() function, rather than at re-initialising them each time
+// the bootstrap needs it, for cutting the interfacing overheads.
+
+////////////////////////////////////////////////////////////////////////////////
+
+pub trait Connect<Serverkey> {
+  fn connect(&mut self, cpu_key: &Serverkey, fpga_count: usize);
+}
+
+impl Connect<ShortintServerKey> for BelfortFpgaUtils {
+  fn connect(&mut self, cpu_key: &ShortintServerKey, fpga_count: usize) {
+    if cpu_key.pbs_order == PBSOrder::BootstrapKeyswitch {
+      panic!("Packed BootstrapKeyswitch is not supported")
+    }
+
+    let bootstrapping_key = cpu_key.bootstrapping_key.clone();
+    let key_switching_key = cpu_key.key_switching_key.clone();
+
+    let bsk = match bootstrapping_key {
+      ShortintBootstrappingKey::Classic(flbko) => flbko,
+      ShortintBootstrappingKey::MultiBit { .. } => {
+        panic!("Multibit BSK is not supported in FPGA!")
+      }
+    };
+
+    let ksk = key_switching_key;
+
+    self.connect_fpga(bsk, ksk, fpga_count);
+  }
+}
+
+impl Connect<BooleanServerKey> for BelfortFpgaUtils {
+  fn connect(&mut self, cpu_key: &BooleanServerKey, fpga_count: usize) {
+    if cpu_key.pbs_order == PBSOrder::BootstrapKeyswitch {
+      panic!("Packed BootstrapKeyswitch is not supported")
+    }
+
+    let bsk = cpu_key.bootstrapping_key.clone();
+    let ksk = cpu_key.key_switching_key.clone();
+
+    self.connect_fpga(bsk, ksk, fpga_count);
+  }
+}
+
+impl BelfortFpgaUtils {
+  fn connect_fpga<Scalar: UnsignedInteger>(
+    &mut self,
+    bsk: FourierLweBootstrapKeyOwned,
+    ksk: LweKeyswitchKey<Vec<Scalar>>,
+    fpga_count: usize,
+  ) {
+    if !self.is_connected {
+      let lwe_dimension = self.params.lwe_dimension.0;
+      let glwe_dimension = self.params.glwe_dimension.0;
+      let polynomial_size = self.params.polynomial_size.0;
+      let ks_level = self.params.ks_level.0;
+      let batch_size = self.params.batch_size;
+      let bsk_num_kernels = self.params.bsk_num_kernels;
+      let ksk_num_kernels = self.params.ksk_num_kernels;
+      let ksk_num_streams = 2 * self.params.streaming_size * self.params.glwe_dimension.0;
+
+      unsafe {
+        //////////////////////////////////////////////////////////////////////////
+        // program FPGA
+
+        for fpga_index in 0..fpga_count {
+          // get FPGA handle
+          self.fpga_device.push(xrtDeviceOpen(fpga_index as u32));
+
+          // program FPGA with xclbin container
+          let xclbin_file = CString::new(self.params.fpga_image).unwrap();
+          xrtDeviceLoadXclbinFile(self.fpga_device[fpga_index], xclbin_file.as_ptr());
+
+          // get the laoded xclbin UUID (Universally Unique IDentifier)
+          let mut xclbin_uuid = vec![0u8; 16];
+          xrtDeviceGetXclbinUUID(self.fpga_device[fpga_index], xclbin_uuid.as_mut_ptr());
+
+          self.xclbin_uuid = xclbin_uuid.clone();
+        }
+
+        //////////////////////////////////////////////////////////////////////////
+        // create kernel handles
+
+        for fpga_index in 0..fpga_count {
+          self.kernelhandle_lwe_in.push({
+            let kernel_name = CString::new("ks_lwe_in").unwrap();
+            xrtPLKernelOpenExclusive(
+              self.fpga_device[fpga_index],
+              self.xclbin_uuid.as_mut_ptr(),
+              kernel_name.as_ptr(),
+            )
+          });
+
+          self.kernelhandle_lwe_out.push({
+            let kernel_name = CString::new("pbs_lwe_out").unwrap();
+            xrtPLKernelOpenExclusive(
+              self.fpga_device[fpga_index],
+              self.xclbin_uuid.as_mut_ptr(),
+              kernel_name.as_ptr(),
+            )
+          });
+
+          self.kernelhandle_ksk.push({
+            let mut kernelhandle_ksk: Vec<*mut c_void> = Vec::new();
+
+            for ksk_kernel_index in 0..ksk_num_kernels {
+              let kernel_name = CString::new(format!("ksk:{{ksk_{}}}", ksk_kernel_index + 1)).unwrap();
+              kernelhandle_ksk.push(xrtPLKernelOpenExclusive(
+                self.fpga_device[fpga_index],
+                self.xclbin_uuid.as_mut_ptr(),
+                kernel_name.as_ptr(),
+              ));
+            }
+            kernelhandle_ksk
+          });
+
+          self.kernelhandle_bsk.push({
+            let mut kernelhandle_bsk: Vec<*mut c_void> = Vec::new();
+
+            for bsk_kernel_index in 0..bsk_num_kernels {
+              let kernel_name = CString::new(format!("bsk:{{bsk_{}}}", bsk_kernel_index + 1)).unwrap();
+              kernelhandle_bsk.push(xrtPLKernelOpenExclusive(
+                self.fpga_device[fpga_index],
+                self.xclbin_uuid.as_mut_ptr(),
+                kernel_name.as_ptr(),
+              ));
+            }
+            kernelhandle_bsk
+          });
+        }
+
+        //////////////////////////////////////////////////////////////////////////
+        // allocate memories in device memory (FPGA memory: DDR/HBM)
+
+        let lwe_in_size = polynomial_size * glwe_dimension + ksk_num_streams; // This is padded (aligned) size
+        let lwe_out_size = polynomial_size * glwe_dimension + 16; // This is padded (aligned) size
+        let ksk_part_size = {
+          let ksk_size = (lwe_dimension + 1) * glwe_dimension * polynomial_size * ks_level;
+          let ksk_width = self.params.ksk_bits;
+          let num_ksk_coeffs_per_dmatx: usize = 512 / ksk_width;
+          let num_ksk_dmatx: usize = {
+            let ceil_div = |a: usize, b: usize| (a + b - 1) / b;
+            ceil_div(ksk_size / ksk_num_kernels, num_ksk_coeffs_per_dmatx)
+          };
+          // number of transfers * the size of each 512-bits transfer
+          num_ksk_dmatx * 8
+        };
+        let bsk_part_size = {
+          let lwe_dimension = bsk.input_lwe_dimension().0;
+          let glwe_size = bsk.glwe_size().0;
+          let pbs_level = bsk.decomposition_level_count().0;
+          let polynomial_size = bsk.polynomial_size().0;
+          let bsk_size = lwe_dimension * pbs_level * glwe_size * glwe_size * polynomial_size / 2;
+          let bsk_size_per_kernel = bsk_size / bsk_num_kernels;
+          let bsk_width = self.params.bsk_bits;
+          let num_bsk_coeffs_per_dmatx = 512 / (2 * bsk_width);
+          let num_bsk_dmatx = {
+            let ceil_div = |a: usize, b: usize| (a + b - 1) / b;
+            ceil_div(bsk_size_per_kernel, num_bsk_coeffs_per_dmatx)
+          };
+          // number of transfers * the size of each 512-bits transfer
+          num_bsk_dmatx * 8
+        };
+
+        let devmem_lwe_in_size = lwe_in_size * batch_size * MAX_BATCH_COUNT * mem::size_of::<u32>();
+        let devmem_lwe_out_size = lwe_out_size * batch_size * MAX_BATCH_COUNT * mem::size_of::<u32>();
+        let devmem_ksk_part_size = ksk_part_size * mem::size_of::<u64>();
+        let devmem_bsk_part_size = bsk_part_size * mem::size_of::<u64>();
+
+        // Allocate the memories
+
+        for fpga_index in 0..fpga_count {
+          self.devmem_lwe_in.push({
+            let kernelArg_lwe_in_grp_0 = xrtKernelArgGroupId(self.kernelhandle_lwe_in[fpga_index], 0) as u32;
+
+            xrtBOAlloc(
+              self.fpga_device[fpga_index],
+              devmem_lwe_in_size,
+              0u64,
+              kernelArg_lwe_in_grp_0,
+            )
+          });
+
+          self.devmem_lwe_out.push({
+            let kernelArg_lwe_out_grp_0 = xrtKernelArgGroupId(self.kernelhandle_lwe_out[fpga_index], 0) as u32;
+
+            xrtBOAlloc(
+              self.fpga_device[fpga_index],
+              devmem_lwe_out_size,
+              0u64,
+              kernelArg_lwe_out_grp_0,
+            )
+          });
+
+          self.devmem_ksk.push({
+            let mut devmem_ksk: Vec<*mut c_void> = Vec::new();
+            for handle in self.kernelhandle_ksk[fpga_index].iter() {
+              let kernelArg_groupId = xrtKernelArgGroupId(*handle, 0) as u32;
+              devmem_ksk.push(xrtBOAlloc(
+                self.fpga_device[fpga_index],
+                devmem_ksk_part_size,
+                0u64,
+                kernelArg_groupId,
+              ));
+            }
+            devmem_ksk
+          });
+
+          self.devmem_bsk.push({
+            let mut devmem_bsk: Vec<*mut c_void> = Vec::new();
+            for handle in self.kernelhandle_bsk[fpga_index].iter() {
+              let kernelArg_groupId = xrtKernelArgGroupId(*handle, 0) as u32;
+              devmem_bsk.push(xrtBOAlloc(
+                self.fpga_device[fpga_index],
+                devmem_bsk_part_size,
+                0u64,
+                kernelArg_groupId,
+              ));
+            }
+            devmem_bsk
+          });
+        }
+
+        ////////////////////////////////////////////////////////////////////////
+        // create run handles: which are specific to one execution of a kernel;
+        // creates handles but not starts the kernels
+
+        for fpga_index in 0..fpga_count {
+          // Lwe In handles
+          self
+            .runhandle_lwe_in
+            .push(xrtRunOpen(self.kernelhandle_lwe_in[fpga_index]));
+          // Lwe Out handles
+          self
+            .runhandle_lwe_out
+            .push(xrtRunOpen(self.kernelhandle_lwe_out[fpga_index]));
+
+          let mut runhandle_ksk: Vec<Vec<*mut c_void>> = Vec::new();
+          let mut runhandle_bsk: Vec<Vec<*mut c_void>> = Vec::new();
+          for _ in 0..MAX_BATCH_COUNT {
+            // KSK handles
+            runhandle_ksk.push({
+              let ksk_handles: Vec<*mut c_void> = self.kernelhandle_ksk[fpga_index]
+                .iter()
+                .map(|handle| xrtRunOpen(*handle))
+                .collect();
+              ksk_handles
+            });
+
+            // BSK handles
+            runhandle_bsk.push({
+              let bsk_handles: Vec<*mut c_void> = self.kernelhandle_bsk[fpga_index]
+                .iter()
+                .map(|handle| xrtRunOpen(*handle))
+                .collect();
+              bsk_handles
+            });
+          }
+
+          self.runhandle_ksk.push(runhandle_ksk);
+          self.runhandle_bsk.push(runhandle_bsk);
+        }
+
+        //////////////////////////////////////////////////////////////////////////
+        // set devmem related run arguments already here
+
+        for fpga_index in 0..fpga_count {
+          xrtRunSetArg(self.runhandle_lwe_in[fpga_index], 0, self.devmem_lwe_in[fpga_index]);
+
+          xrtRunSetArg(self.runhandle_lwe_out[fpga_index], 0, self.devmem_lwe_out[fpga_index]);
+
+          for batch_index in 0..MAX_BATCH_COUNT {
+            for (handle_index, handle) in self.runhandle_ksk[fpga_index][batch_index].iter().enumerate() {
+              xrtRunSetArg(*handle, 0, self.devmem_ksk[fpga_index][handle_index]);
+            }
+            for (handle_index, handle) in self.runhandle_bsk[fpga_index][batch_index].iter().enumerate() {
+              xrtRunSetArg(*handle, 0, self.devmem_bsk[fpga_index][handle_index]);
+            }
+          }
+        }
+
+        //////////////////////////////////////////////////////////////////////////
+        // transfer the ksk to FPGA memory
+
+        let ksk_reordered: Vec<Vec<u64>> = self.ksk_reorder(ksk, &self.params);
+
+        assert!(ksk_part_size == ksk_reordered[0].len(), "KSK re-oredering was wrong");
+        assert!(ksk_num_kernels == ksk_reordered.len(), "KSK re-oredering was wrong");
+
+        for fpga_index in 0..fpga_count {
+          for kernel in 0..ksk_num_kernels {
+            // at the transfer of each part;
+            //   1. allocate 4K aligned host-memory
+            //   2. copy the part to that memory
+            //   3. transfer the data from aligned host-memory to device-memory
+
+            use std::alloc::{alloc, dealloc, Layout};
+
+            let ksk_layout = Layout::from_size_align(devmem_ksk_part_size, 4096).expect("Invalid layout");
+            let ksk_ptr = alloc(ksk_layout) as *mut u64;
+
+            if !ksk_ptr.is_null() {
+              ksk_ptr.copy_from_nonoverlapping(ksk_reordered[kernel].as_ptr(), ksk_reordered[kernel].len());
+              xrtBOWrite(
+                self.devmem_ksk[fpga_index][kernel],
+                ksk_ptr as *const c_void,
+                devmem_ksk_part_size,
+                0,
+              );
+              xrtBOSync(
+                self.devmem_ksk[fpga_index][kernel],
+                xclBOSyncDirection_XCL_BO_SYNC_BO_TO_DEVICE,
+                devmem_ksk_part_size,
+                0,
+              );
+              dealloc(ksk_ptr as *mut u8, ksk_layout);
+            } else {
+              println!("Memory allocation failed");
+            }
+          }
+        }
+
+        //////////////////////////////////////////////////////////////////////////
+        // transfer the bsk to FPGA memory
+
+        let bsk_reordered: Vec<Vec<u64>> = self.bsk_reorder(bsk, &self.params);
+
+        assert!(bsk_part_size == bsk_reordered[0].len(), "BSK re-oredering was wrong");
+        assert!(bsk_num_kernels == bsk_reordered.len(), "BSK re-oredering was wrong");
+
+        for fpga_index in 0..fpga_count {
+          for kernel in 0..bsk_num_kernels {
+            // at the transfer of each part;
+            //   1. allocate 4K aligned host-memory
+            //   2. copy the part to that memory
+            //   3. transfer the data from aligned host-memory to device-memory
+
+            use std::alloc::{alloc, dealloc, Layout};
+
+            let bsk_layout = Layout::from_size_align(devmem_bsk_part_size, 4096).expect("Invalid layout");
+            let bsk_ptr = alloc(bsk_layout) as *mut u64;
+
+            if !bsk_ptr.is_null() {
+              bsk_ptr.copy_from_nonoverlapping(bsk_reordered[kernel].as_ptr(), bsk_reordered[kernel].len());
+              xrtBOWrite(
+                self.devmem_bsk[fpga_index][kernel],
+                bsk_ptr as *const c_void,
+                devmem_bsk_part_size,
+                0,
+              );
+              xrtBOSync(
+                self.devmem_bsk[fpga_index][kernel],
+                xclBOSyncDirection_XCL_BO_SYNC_BO_TO_DEVICE,
+                devmem_bsk_part_size,
+                0,
+              );
+              dealloc(bsk_ptr as *mut u8, bsk_layout);
+            } else {
+              println!("Memory allocation failed");
+            }
+          }
+        }
+      }
+
+      self.enabled_fpga_count = fpga_count;
+      self.is_connected = true;
+    }
+  }
+
+  fn ksk_reorder<Scalar: UnsignedInteger>(
+    &self,
+    ksk: LweKeyswitchKey<Vec<Scalar>>,
+    params: &FpgaParameters,
+  ) -> Vec<Vec<u64>> {
+    let lwe_dim: usize = params.lwe_dimension.0.cast_into();
+    let glwe_dim: usize = params.glwe_dimension.0.cast_into();
+    let poly_size: usize = params.polynomial_size.0.cast_into();
+    let ksk_lev: usize = params.ks_level.0.cast_into();
+    let ksk_num_kernels = params.ksk_num_kernels;
+    let ksk_size = (lwe_dim + 1) * glwe_dim * poly_size * ksk_lev;
+    let ksk_num_streams = 2 * params.streaming_size * glwe_dim * ksk_lev;
+    let ksk_num_streams_per_kernel = ksk_num_streams / ksk_num_kernels;
+    let ksk_width = params.ksk_bits;
+
+    // The output is prepared for 512-bit wide DMA transfers
+    let num_ksk_coeffs_per_dmatx = 512 / ksk_width;
+    let num_ksk_dmatx = {
+      let ceil_div = |a: usize, b: usize| (a + b - 1) / b;
+      ceil_div(ksk_size / ksk_num_kernels, num_ksk_coeffs_per_dmatx)
+    };
+
+    // Flatten
+
+    let mut ksk_flat: Vec<u64> = Vec::new();
+    for keyswitch_key_block in ksk.iter() {
+      for level_key_ciphertext in keyswitch_key_block.iter() {
+        for mask in level_key_ciphertext.get_mask().as_ref().iter() {
+          let mask_modswitched = self.modulus_switch(*mask, ksk_width);
+          let mask128: u128 = mask_modswitched.cast_into();
+          let mask64: u64 = mask128 as u64;
+          ksk_flat.push(mask64);
+        }
+        let body = *level_key_ciphertext.get_body().data;
+        let body_modswitched = self.modulus_switch(body, ksk_width);
+        let body128: u128 = body_modswitched.cast_into();
+        let body64: u64 = body128 as u64;
+        ksk_flat.push(body64);
+      }
+    }
+
+    // Reorder data per kernel + Modswitch
+
+    let mut ksk_part_reordered: Vec<Vec<u64>> = {
+      // For the rearrangement part below, we create some extra space here.
+      // In the end, the last 512-bit AXI transfer will probably contain
+      // partially valid data, with the remainder needing to be ignored.
+      // That reaminder part will come from these extras.
+      let num_ksk_coeffs_per_dmatx: usize = 512 / ksk_width;
+      let pad_extra = num_ksk_coeffs_per_dmatx;
+      vec![vec![0; ksk_flat.len() / ksk_num_kernels + pad_extra]; ksk_num_kernels]
+    };
+
+    let mut ksk_kernel_index = 0;
+    let mut ksk_steam_index = 0;
+
+    for lwe_out_index in 0..(lwe_dim + 1) {
+      for lwe_in_index in 0..(glwe_dim * poly_size) {
+        for ksk_level_index in 0..ksk_lev {
+          let index = lwe_out_index + (lwe_dim + 1) * ksk_lev * lwe_in_index + (lwe_dim + 1) * ksk_level_index;
+
+          ksk_part_reordered[ksk_kernel_index][ksk_steam_index % ksk_num_streams_per_kernel
+            + ((ksk_steam_index / ksk_num_streams) * ksk_num_streams_per_kernel)] = ksk_flat[index];
+
+          ksk_steam_index += 1;
+
+          if ksk_steam_index % ksk_num_streams_per_kernel == 0 {
+            ksk_kernel_index += 1;
+
+            if ksk_kernel_index == ksk_num_kernels {
+              ksk_kernel_index = 0;
+            }
+          }
+        }
+      }
+    }
+
+    // Rearrange coefficients from 64-bit alignment to ksk-width alignment
+    // The output will be an array optimized for 512-bit DMA transfers
+
+    let mut ksk_part_rearranged: Vec<Vec<u64>> = {
+      // size = number of transfers * the size of each 512-bits transfer
+      let size_of_ksk_part = num_ksk_dmatx * 8;
+      vec![vec![0; size_of_ksk_part]; ksk_num_kernels]
+    };
+
+    // Do the realignment here.
+    // At each loop, take 512//ksk_width coefficients from ksk_part_reordered and
+    // write it to ksk_part_rearranged as 8x64-bit = 512-bit output
+    for k in 0..ksk_num_kernels {
+      for t in 0..num_ksk_dmatx {
+        let src_start = t * num_ksk_coeffs_per_dmatx;
+        let dst_start = t * 8;
+
+        let src: &[u64] = &ksk_part_reordered[k][src_start..src_start + num_ksk_coeffs_per_dmatx];
+        let dst: &mut [u64] = &mut ksk_part_rearranged[k][dst_start..dst_start + 8];
+
+        for i in 0..8 {
+          dst[i] = 0;
+        }
+
+        let mut result_bit_pos = 0;
+
+        let src_array_size: usize = 512 / ksk_width;
+
+        for i in 0..src_array_size {
+          let mask = (1u64 << ksk_width) - 1;
+          let value = src[i] & mask;
+
+          for j in 0..ksk_width {
+            let result_index = result_bit_pos / 64;
+            let bit_pos = result_bit_pos % 64;
+
+            dst[result_index] |= ((value >> j) & 1) << bit_pos;
+
+            result_bit_pos += 1;
+          }
+        }
+      }
+    }
+
+    ksk_part_rearranged
+  }
+
+  fn bsk_reorder(&self, bsk: FourierLweBootstrapKeyOwned, params: &FpgaParameters) -> Vec<Vec<u64>> {
+    use concrete_fft::c64;
+
+    //////////////////////////////////////////////////////////////////////////////
+    //
+    // Step 0 : Native     : c64 [lwe_dimension]reversed([pbs_level])[glwe_size][glwe_size][fourier_polynomial_size]
+    // Step 1 : Reorder to : c64 [lwe_dimension][glwe_size][pbs_level][glwe_size]bitreverse([fourier_polynomial_size])
+    // Step 2 : Map to     : u64 [lwe_dimension][num_streaming_chunks][glwe_size][pbs_level][glwe_size][streaming_size][2]
+    // Step 3 : Split over : NUM_BSK_KERNELS
+    //
+
+    //////////////////////////////////////////////////////////////////////////////
+    // Sizes and utility functions
+    //
+
+    let lwe_dimension: usize = bsk.input_lwe_dimension().0;
+    let glwe_size: usize = bsk.glwe_size().0;
+    let pbs_level: usize = bsk.decomposition_level_count().0;
+    let polynomial_size: usize = bsk.polynomial_size().0;
+    let streaming_size: usize = params.streaming_size;
+    let fourier_polynomial_size: usize = polynomial_size / 2;
+    let num_streaming_chunks: usize = fourier_polynomial_size / streaming_size;
+    let bsk_num_kernels = params.bsk_num_kernels;
+    let bsk_num_streams: usize = glwe_size * pbs_level * glwe_size * streaming_size;
+    let bsk_num_streams_per_kernel: usize = bsk_num_streams / params.bsk_num_kernels;
+    let bsk_width = params.bsk_bits;
+
+    let bsk_size = lwe_dimension * pbs_level * glwe_size * glwe_size * polynomial_size / 2;
+    let bsk_split_size = bsk_size / params.bsk_num_kernels;
+
+    // The output is prepared for 512-bit wide DMA transfers
+    let num_bsk_coeffs_per_dmatx = (512 / (2 * bsk_width)) * 2;
+    let num_bsk_dmatx = {
+      let ceil_div = |a: usize, b: usize| (a + b - 1) / b;
+      let bsk_size_per_kernel = bsk_size / bsk_num_kernels;
+      ceil_div(bsk_size_per_kernel, num_bsk_coeffs_per_dmatx / 2)
+    };
+
+    // Assuming Complex is a struct or enum in Rust representing complex numbers
+    // You need to replace Complex with the actual type you are using for complex numbers.
+    fn bit_reverse_perm(v: &[c64], fourier_polynomial_size: usize) -> Vec<c64> {
+      fn bit_reverse(input: usize, n_bits: usize) -> usize {
+        let binary_str = format!("{:0width$b}", input, width = n_bits as usize);
+        let reversed_str: String = binary_str.chars().rev().collect();
+        u32::from_str_radix(&reversed_str, 2).unwrap() as usize
+      }
+
+      let result: Vec<c64> = (0..fourier_polynomial_size)
+        .map(|i| v[bit_reverse(i, f64::log2(fourier_polynomial_size as f64) as usize)])
+        .collect();
+
+      result
+    }
+
+    //////////////////////////////////////////////////////////////////////////////
+    // Step 1:
+    //
+    // Input:  c64 [lwe_dimension]reversed([pbs_level])[glwe_size][glwe_size][fourier_polynomial_size]
+    // Output: c64 [lwe_dimension][glwe_size][pbs_level][glwe_size]bitreverse([fourier_polynomial_size])
+    //
+
+    let bsk_reordered: Vec<Vec<Vec<Vec<Vec<c64>>>>> = {
+      // Get All
+      // as [lwe_dimension * glwe_size * pbs_level * glwe_size][fourier_polynomial_size]
+      let bsk_64: Vec<Vec<c64>> = bsk
+        .clone()
+        .data()
+        .chunks(polynomial_size / 2)
+        // the first element should be put at the last position (likely because of different twist twiddles)
+        .map(|v| bit_reverse_perm(v, polynomial_size / 2))
+        .collect();
+
+      // Group by Columns
+      // as [lwe_dimension * glwe_size * pbs_level][glwe_size][fourier_polynomial_size]
+      let bsk_cols: Vec<Vec<Vec<c64>>> = bsk_64.chunks(glwe_size).map(|v| v.to_vec()).collect();
+
+      // Group by Rows
+      // as [lwe_dimension * pbs_level][glwe_size][glwe_size][fourier_polynomial_size]
+      let bsk_rows: Vec<Vec<Vec<Vec<c64>>>> = bsk_cols.chunks(glwe_size).map(|v| v.to_vec()).collect();
+
+      // Group by Levels
+      // as [lwe_dimension][pbs_level][glwe_size][glwe_size][fourier_polynomial_size]
+      let bsk_levels: Vec<Vec<Vec<Vec<Vec<c64>>>>> = bsk_rows.chunks(pbs_level).map(|v| v.to_vec()).collect();
+
+      // Reverts Rows
+      // as [lwe_dimension][pbs_level][glwe_size][glwe_size][fourier_polynomial_size]
+      // Tfhe-rs has the most-significant level first, but we want the least-significant level first
+      let bsk_rev: Vec<Vec<Vec<Vec<Vec<c64>>>>> =
+        bsk_levels.into_iter().map(|v| v.into_iter().rev().collect()).collect();
+
+      // Transpose
+      // as [lwe_dimension][glwe_size][pbs_level][glwe_size][fourier_polynomial_size]
+      let bsk_trps: Vec<Vec<Vec<Vec<Vec<c64>>>>> = bsk_rev
+        .into_iter()
+        .map(|v| {
+          let rows = v.len();
+          let cols = v[0].len();
+          (0..cols)
+            .map(|col| (0..rows).map(|row| v[row][col].clone()).collect())
+            .collect()
+        })
+        .collect();
+
+      bsk_trps
+    };
+
+    //////////////////////////////////////////////////////////////////////////////
+    // Step 2:
+    //
+    // Input:  c64 [lwe_dimension][glwe_size][pbs_level][glwe_size]bitreverse([fourier_polynomial_size])
+    // Output: u64 [lwe_dimension][num_streaming_chunks][glwe_size][pbs_level][glwe_size][streaming_size][2]
+    //
+
+    let mut bsk_streams: Vec<Vec<u64>> =
+      vec![
+        vec![u64::default(); glwe_size * pbs_level * glwe_size * streaming_size * 2];
+        lwe_dimension * num_streaming_chunks
+      ];
+
+    fn c64_to_memval(value: c64, bsk_frac_bits: u32) -> (u64, u64) {
+      let factor = 2_u64.pow(bsk_frac_bits as u32);
+      let rounded_re = ((value.re * factor as f64).round() as i64) as u64;
+      let rounded_im = ((value.im * factor as f64).round() as i64) as u64;
+      (rounded_re, rounded_im)
+    }
+
+    for i in 0..lwe_dimension {
+      for j in 0..glwe_size {
+        for k in 0..pbs_level {
+          for l in 0..glwe_size {
+            for n in 0..streaming_size {
+              for m in 0..num_streaming_chunks {
+                let serial = num_streaming_chunks * i + m;
+                let parallel =
+                  pbs_level * glwe_size * streaming_size * j + glwe_size * streaming_size * k + streaming_size * l + n;
+
+                (
+                  bsk_streams[serial][2 * parallel + 0],
+                  bsk_streams[serial][2 * parallel + 1],
+                ) = c64_to_memval(
+                  bsk_reordered[i][j][k][l][streaming_size * m + n],
+                  params.bsk_frac_bits as u32,
+                )
+              }
+            }
+          }
+        }
+      }
+    }
+
+    //////////////////////////////////////////////////////////////////////////////
+    // Step 3:
+    //
+    // Input:  u64 [lwe_dimension][num_streaming_chunks][glwe_size][pbs_level][glwe_size][streaming_size][2]
+    // Output: Split the "parallel" part of the bsk_streams between params.bsk_num_kernels kernels
+    //
+    //                                       Serial                                    Parallel
+    //                        <-----------------------------------><----------------------------------------------->
+    //   uint64_t bsk_streams[LWE_DIMENSION][NUM_STREAMING_CHUNKS][GLWE_SIZE][PBS_LEVEL][GLWE_SIZE][STREAMING_SIZE][2];
+    //
+
+    let bsk_final_size = lwe_dimension * num_streaming_chunks * glwe_size * pbs_level * glwe_size * streaming_size * 2;
+    let bsk_final_part_size = bsk_final_size / params.bsk_num_kernels;
+
+    assert!(bsk_final_size == bsk_size * 2, "BSK re-oredering is wrong");
+    assert!(bsk_final_part_size == bsk_split_size * 2, "BSK re-oredering is wrong");
+
+    let mut bsk_parts: Vec<Vec<u64>> = {
+      // For the rearrangement part below, we create some extra space here.
+      // In the end, the last 512-bit AXI transfer will probably contain
+      // partially valid data, with the remainder needing to be ignored.
+      // That reaminder part will come from these extras.
+      let pad_extra = num_bsk_coeffs_per_dmatx;
+      vec![vec![u64::default(); bsk_final_part_size + pad_extra]; params.bsk_num_kernels]
+    };
+
+    for kernel in 0..params.bsk_num_kernels {
+      let mut cnt = 0;
+
+      for serial in 0..(lwe_dimension * num_streaming_chunks) {
+        for parallel in 0..bsk_num_streams_per_kernel {
+          bsk_parts[kernel][cnt + 0] = bsk_streams[serial][kernel * bsk_num_streams_per_kernel * 2 + 2 * parallel + 0];
+          bsk_parts[kernel][cnt + 1] = bsk_streams[serial][kernel * bsk_num_streams_per_kernel * 2 + 2 * parallel + 1];
+          cnt += 2;
+        }
+      }
+    }
+
+    //////////////////////////////////////////////////////////////////////////////
+    // Step 4:
+    //
+    // Input:  u64
+    // Output: u64
+    //
+    // Rearrange coefficients from 64-bit alignment to bsk-width alignment
+    // The output will be an array optimized for 512-bit DMA transfers
+
+    let mut bsk_parts_rearranged: Vec<Vec<u64>> = {
+      // size = number of transfers * the size of each 512-bits transfer
+      let size_of_bsk_part = num_bsk_dmatx * 8;
+      vec![vec![0; size_of_bsk_part]; bsk_num_kernels]
+    };
+
+    // Do the realignment here.
+    // At each loop, take 512//bsk_width coefficients from bsk_part_reordered and
+    // write it to bsk_part_rearranged as 8x64-bit = 512-bit output
+    for b in 0..bsk_num_kernels {
+      for t in 0..num_bsk_dmatx {
+        let src_start = t * num_bsk_coeffs_per_dmatx;
+        let dst_start = t * 8;
+
+        let src: &[u64] = &bsk_parts[b][src_start..src_start + num_bsk_coeffs_per_dmatx];
+        let dst: &mut [u64] = &mut bsk_parts_rearranged[b][dst_start..dst_start + 8];
+
+        for i in 0..8 {
+          dst[i] = 0;
+        }
+
+        let mut result_bit_pos = 0;
+
+        let src_array_size: usize = num_bsk_coeffs_per_dmatx;
+
+        for i in 0..src_array_size {
+          let mask = (1u64 << bsk_width) - 1;
+          let value = src[i] & mask;
+
+          for j in 0..bsk_width {
+            let result_index = result_bit_pos / 64;
+            let bit_pos = result_bit_pos % 64;
+
+            dst[result_index] |= ((value >> j) & 1) << bit_pos;
+
+            result_bit_pos += 1;
+          }
+        }
+      }
+    }
+
+    bsk_parts_rearranged
+  }
+
+  pub fn disconnect(&mut self) {
+    self.disconnect_fpga();
+  }
+
+  fn disconnect_fpga(&mut self) {
+    if self.is_connected {
+      unsafe {
+        for fpga_index in 0..self.enabled_fpga_count {
+          // Free memories
+          xrtBOFree(self.devmem_lwe_in[fpga_index]);
+          xrtBOFree(self.devmem_lwe_out[fpga_index]);
+          for devmem in self.devmem_ksk[fpga_index].clone() {
+            xrtBOFree(devmem);
+          }
+          for devmem in self.devmem_bsk[fpga_index].clone() {
+            xrtBOFree(devmem);
+          }
+
+          // Close Runs
+          xrtRunClose(self.runhandle_lwe_in[fpga_index]);
+          xrtRunClose(self.runhandle_lwe_out[fpga_index]);
+          for runs in self.runhandle_ksk[fpga_index].clone() {
+            for run in runs {
+              xrtRunClose(run);
+            }
+          }
+          for runs in self.runhandle_bsk[fpga_index].clone() {
+            for run in runs {
+              xrtRunClose(run);
+            }
+          }
+
+          // Close Kernels
+          xrtKernelClose(self.kernelhandle_lwe_in[fpga_index]);
+          xrtKernelClose(self.kernelhandle_lwe_out[fpga_index]);
+          for kernel in self.kernelhandle_ksk[fpga_index].clone() {
+            xrtKernelClose(kernel);
+          }
+          for kernel in self.kernelhandle_bsk[fpga_index].clone() {
+            xrtKernelClose(kernel);
+          }
+        }
+      }
+
+      // clear the vectors
+      self.xclbin_uuid.clear();
+      self.fpga_device.clear();
+
+      self.devmem_lwe_in.clear();
+      self.devmem_lwe_out.clear();
+      self.devmem_ksk.clear();
+      self.devmem_bsk.clear();
+
+      self.runhandle_lwe_in.clear();
+      self.runhandle_lwe_out.clear();
+      self.runhandle_ksk.clear();
+      self.runhandle_bsk.clear();
+
+      self.kernelhandle_lwe_in.clear();
+      self.kernelhandle_lwe_out.clear();
+      self.kernelhandle_ksk.clear();
+      self.kernelhandle_bsk.clear();
+
+      self.is_connected = false;
+    }
+  }
+
+  pub fn modulus_switch_from_u32_to_u32(&self, num: u32, num_bits: usize) -> u32 {
+    let cut_off_bits = 32 - num_bits;
+    let rounded = u32::wrapping_add(num, 1 << (cut_off_bits - 1));
+    let modswitched = rounded >> cut_off_bits;
+    modswitched
+  }
+
+  pub fn modulus_switch_from_u64_to_u32(&self, num: u64, num_bits: usize) -> u32 {
+    let cut_off_bits = 64 - num_bits;
+    let rounded = u64::wrapping_add(num, 1 << (cut_off_bits - 1));
+    let modswitched = rounded >> cut_off_bits;
+    modswitched as u32
+  }
+
+  pub fn modulus_switch<T: UnsignedInteger>(&self, num: T, num_bits: usize) -> T {
+    let t_size = std::mem::size_of::<T>() * 8;
+    let num128: u128 = num.cast_into();
+    let cut_off_bits = t_size - num_bits;
+    let rounded = u128::wrapping_add(num128, 1 << (cut_off_bits - 1)) % (1 << t_size);
+    let modswitched = rounded >> cut_off_bits;
+    let modswitched_t: T = modswitched.cast_into();
+    modswitched_t
+  }
+}
+
+#[cfg(test)]
+mod tests {
+  use crate::core_crypto::fpga::BelfortFpgaUtils;
+
+  #[test]
+  fn test_max_value_modulus_switch() {
+    let num = u64::MAX;
+    let num_bits = 15; // Typical value
+    let utils = BelfortFpgaUtils::default_integer();
+    let result = utils.modulus_switch_from_u64_to_u32(num, num_bits);
+    assert_eq!(result, 0);
+  }
+}
diff --git a/tfhe/src/core_crypto/mod.rs b/tfhe/src/core_crypto/mod.rs
index a15ef7c0..e4d69e00 100644
--- a/tfhe/src/core_crypto/mod.rs
+++ b/tfhe/src/core_crypto/mod.rs
@@ -20,6 +20,8 @@ pub mod fft_impl;
 
 #[cfg(feature = "gpu")]
 pub mod gpu;
+// #[cfg(feature = "fpga")]
+pub mod fpga;
 #[cfg(test)]
 pub mod keycache;
 
diff --git a/tfhe/src/core_crypto/probe_time.rs b/tfhe/src/core_crypto/probe_time.rs
new file mode 100644
index 00000000..071be62f
--- /dev/null
+++ b/tfhe/src/core_crypto/probe_time.rs
@@ -0,0 +1,37 @@
+use std::time::{SystemTime, UNIX_EPOCH};
+
+const NUM_PROBES: usize = 16;
+pub const MAX_MEASUREMENTS_PER_PROBE: usize = 512;
+
+pub static mut EPOCH: SystemTime = UNIX_EPOCH;
+pub static mut TIME_STAMPS: [[SystemTime; NUM_PROBES]; MAX_MEASUREMENTS_PER_PROBE] =
+    [[UNIX_EPOCH; NUM_PROBES]; MAX_MEASUREMENTS_PER_PROBE];
+pub static mut PROBE_NAMES: [&str; NUM_PROBES] = ["NONAME"; NUM_PROBES];
+pub static mut PROBE_INDEX: usize = 0;
+pub static mut EXECUTION_INDEX: usize = 0;
+
+#[macro_export]
+macro_rules! probe_time {
+    ($probe_name:expr) => {
+        unsafe {
+            TIME_STAMPS[EXECUTION_INDEX][PROBE_INDEX] = SystemTime::now();
+            PROBE_NAMES[PROBE_INDEX] = $probe_name;
+            PROBE_INDEX += 1;
+            EPOCH = SystemTime::now();
+        }
+    };
+}
+
+#[macro_export]
+macro_rules! probe_time_init {
+    ($measurement_index:expr) => {
+        unsafe {
+            EXECUTION_INDEX = $measurement_index;
+            PROBE_INDEX = 0;
+            TIME_STAMPS[EXECUTION_INDEX][PROBE_INDEX] = SystemTime::now();
+            PROBE_NAMES[PROBE_INDEX] = "Init";
+            PROBE_INDEX += 1;
+            EPOCH = SystemTime::now();
+        }
+    };
+}
diff --git a/tfhe/src/high_level_api/array/dynamic/booleans.rs b/tfhe/src/high_level_api/array/dynamic/booleans.rs
index fded14b6..85ae3f2a 100644
--- a/tfhe/src/high_level_api/array/dynamic/booleans.rs
+++ b/tfhe/src/high_level_api/array/dynamic/booleans.rs
@@ -107,6 +107,10 @@ where
         Some(Device::CudaGpu) => {
             panic!("Not supported by Cuda devices")
         }
+        #[cfg(feature = "fpga")]
+        Some(Device::Fpga) => {
+            panic!("Not supported by FPGA devices")
+        }
         None => {
             panic!("{}", crate::high_level_api::errors::UninitializedServerKey);
         }
@@ -134,6 +138,10 @@ where
         Some(Device::CudaGpu) => {
             panic!("Not supported by Cuda devices")
         }
+        #[cfg(feature = "fpga")]
+        Some(Device::Fpga) => {
+            panic!("Not supported by FPGA devices")
+        }
         None => {
             panic!("{}", crate::high_level_api::errors::UninitializedServerKey);
         }
@@ -168,6 +176,10 @@ where
         Some(Device::CudaGpu) => {
             panic!("Not supported by Cuda devices")
         }
+        #[cfg(feature = "fpga")]
+        Some(Device::Fpga) => {
+            panic!("Not supported by FPGA devices")
+        }
         None => {
             panic!("{}", crate::high_level_api::errors::UninitializedServerKey);
         }
diff --git a/tfhe/src/high_level_api/array/dynamic/signed.rs b/tfhe/src/high_level_api/array/dynamic/signed.rs
index 9c302148..3de6eea8 100644
--- a/tfhe/src/high_level_api/array/dynamic/signed.rs
+++ b/tfhe/src/high_level_api/array/dynamic/signed.rs
@@ -190,6 +190,10 @@ where
         Some(Device::CudaGpu) => {
             panic!("Not supported by Cuda devices")
         }
+        #[cfg(feature = "fpga")]
+        Some(Device::Fpga) => {
+            panic!("Not supported by FPGA devices")
+        }
         None => {
             panic!("{}", crate::high_level_api::errors::UninitializedServerKey);
         }
@@ -217,6 +221,10 @@ where
         Some(Device::CudaGpu) => {
             panic!("Not supported by Cuda devices")
         }
+        #[cfg(feature = "fpga")]
+        Some(Device::Fpga) => {
+            panic!("Not supported by FPGA devices")
+        }
         None => {
             panic!("{}", crate::high_level_api::errors::UninitializedServerKey);
         }
@@ -341,6 +349,10 @@ where
         Some(Device::CudaGpu) => {
             panic!("Not supported by Cuda devices")
         }
+        #[cfg(feature = "fpga")]
+        Some(Device::Fpga) => {
+            panic!("Not supported by FPGA devices")
+        }
         None => {
             panic!("{}", crate::high_level_api::errors::UninitializedServerKey);
         }
diff --git a/tfhe/src/high_level_api/array/dynamic/unsigned.rs b/tfhe/src/high_level_api/array/dynamic/unsigned.rs
index ae9f5b7b..3aa5e8bd 100644
--- a/tfhe/src/high_level_api/array/dynamic/unsigned.rs
+++ b/tfhe/src/high_level_api/array/dynamic/unsigned.rs
@@ -202,6 +202,10 @@ where
         Some(Device::CudaGpu) => {
             panic!("Not supported by Cuda devices")
         }
+        #[cfg(feature = "fpga")]
+        Some(Device::Fpga) => {
+            panic!("Not supported by FPGA devices")
+        }
         None => {
             panic!("{}", crate::high_level_api::errors::UninitializedServerKey);
         }
@@ -229,6 +233,10 @@ where
         Some(Device::CudaGpu) => {
             panic!("Not supported by Cuda devices")
         }
+        #[cfg(feature = "fpga")]
+        Some(Device::Fpga) => {
+            panic!("Not supported by FPGA devices")
+        }
         None => {
             panic!("{}", crate::high_level_api::errors::UninitializedServerKey);
         }
@@ -353,6 +361,10 @@ where
         Some(Device::CudaGpu) => {
             panic!("Not supported by Cuda devices")
         }
+        #[cfg(feature = "fpga")]
+        Some(Device::Fpga) => {
+            panic!("Not supported by FPGA devices")
+        }
         None => {
             panic!("{}", crate::high_level_api::errors::UninitializedServerKey);
         }
diff --git a/tfhe/src/high_level_api/booleans/base.rs b/tfhe/src/high_level_api/booleans/base.rs
index 63f6e5cd..2e3957c8 100644
--- a/tfhe/src/high_level_api/booleans/base.rs
+++ b/tfhe/src/high_level_api/booleans/base.rs
@@ -201,6 +201,16 @@ where
                 );
                 FheUint::new(inner, cpu_sks.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner = fpga_key.if_then_else(
+                    &ct_condition.ciphertext.on_cpu(),
+                    &*ct_then.ciphertext.on_cpu(),
+                    &*ct_else.ciphertext.on_cpu(),
+                );
+                FheUint::new(inner, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner = cuda_key.key.key.if_then_else(
@@ -244,6 +254,16 @@ impl<Id: FheIntId> IfThenElse<FheInt<Id>> for FheBool {
                 );
                 FheInt::new(new_ct, key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let new_ct = fpga_key.if_then_else(
+                    &ct_condition.ciphertext.on_cpu(),
+                    &*ct_then.ciphertext.on_cpu(),
+                    &*ct_else.ciphertext.on_cpu(),
+                );
+                FheInt::new(new_ct, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support signed integers")
@@ -264,6 +284,15 @@ impl IfThenElse<Self> for FheBool {
                 );
                 Self::new(new_ct, key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let new_ct = fpga_key.pbs_key().if_then_else_parallelized(
+                    &ct_condition.ciphertext.on_cpu(),
+                    &*ct_then.ciphertext.on_cpu(),
+                    &*ct_else.ciphertext.on_cpu(),
+                );
+                Self::new(new_ct, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support signed integers")
@@ -305,6 +334,15 @@ where
                 let ciphertext = InnerBoolean::Cpu(BooleanBlock::new_unchecked(inner));
                 Self::new(ciphertext, key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner = fpga_key.pbs_key().key.equal(
+                    self.ciphertext.on_cpu().as_ref(),
+                    other.borrow().ciphertext.on_cpu().as_ref(),
+                );
+                let ciphertext = InnerBoolean::Cpu(BooleanBlock::new_unchecked(inner));
+                Self::new(ciphertext, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner = cuda_key.key.key.eq(
@@ -347,6 +385,16 @@ where
                 let ciphertext = InnerBoolean::Cpu(BooleanBlock::new_unchecked(inner));
                 Self::new(ciphertext, key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner = fpga_key.pbs_key().key.not_equal(
+                    self.ciphertext.on_cpu().as_ref(),
+                    other.borrow().ciphertext.on_cpu().as_ref(),
+                );
+                let ciphertext = InnerBoolean::Cpu(BooleanBlock::new_unchecked(inner));
+                Self::new(ciphertext, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner = cuda_key.key.key.ne(
@@ -392,6 +440,18 @@ impl FheEq<bool> for FheBool {
                     key.tag.clone(),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner = fpga_key
+                    .pbs_key()
+                    .key
+                    .scalar_equal(self.ciphertext.on_cpu().as_ref(), u8::from(other));
+                (
+                    InnerBoolean::Cpu(BooleanBlock::new_unchecked(inner)),
+                    fpga_key.tag.clone(),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner = cuda_key.key.key.scalar_eq(
@@ -435,6 +495,18 @@ impl FheEq<bool> for FheBool {
                     key.tag.clone(),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner = fpga_key
+                    .pbs_key()
+                    .key
+                    .scalar_not_equal(self.ciphertext.on_cpu().as_ref(), u8::from(other));
+                (
+                    InnerBoolean::Cpu(BooleanBlock::new_unchecked(inner)),
+                    fpga_key.tag.clone(),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner = cuda_key.key.key.scalar_ne(
@@ -509,6 +581,14 @@ where
                     .boolean_bitand(&self.ciphertext.on_cpu(), &rhs.borrow().ciphertext.on_cpu());
                 (InnerBoolean::Cpu(inner_ct), key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_ct = fpga_key
+                    .pbs_key()
+                    .boolean_bitand(&self.ciphertext.on_cpu(), &rhs.borrow().ciphertext.on_cpu());
+                (InnerBoolean::Cpu(inner_ct), fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_ct = cuda_key.key.key.bitand(
@@ -594,6 +674,18 @@ where
                     key.tag.clone(),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_ct = fpga_key.pbs_key().key.bitor(
+                    self.ciphertext.on_cpu().as_ref(),
+                    rhs.borrow().ciphertext.on_cpu().as_ref(),
+                );
+                (
+                    InnerBoolean::Cpu(BooleanBlock::new_unchecked(inner_ct)),
+                    fpga_key.tag.clone(),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_ct = cuda_key.key.key.bitor(
@@ -678,6 +770,18 @@ where
                     key.tag.clone(),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_ct = fpga_key.pbs_key().key.bitxor(
+                    self.ciphertext.on_cpu().as_ref(),
+                    rhs.borrow().ciphertext.on_cpu().as_ref(),
+                );
+                (
+                    InnerBoolean::Cpu(BooleanBlock::new_unchecked(inner_ct)),
+                    fpga_key.tag.clone(),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_ct = cuda_key.key.key.bitxor(
@@ -754,6 +858,18 @@ impl BitAnd<bool> for &FheBool {
                     key.tag.clone(),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_ct = fpga_key
+                    .pbs_key()
+                    .key
+                    .scalar_bitand(self.ciphertext.on_cpu().as_ref(), u8::from(rhs));
+                (
+                    InnerBoolean::Cpu(BooleanBlock::new_unchecked(inner_ct)),
+                    fpga_key.tag.clone(),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_ct = cuda_key.key.key.scalar_bitand(
@@ -830,6 +946,17 @@ impl BitOr<bool> for &FheBool {
                     key.tag.clone(),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_ct = fpga_key
+                    .pbs_key()
+                    .key
+                    .scalar_bitor(self.ciphertext.on_cpu().as_ref(), u8::from(rhs));
+                (
+                    InnerBoolean::Cpu(BooleanBlock::new_unchecked(inner_ct)),
+                    fpga_key.tag.clone(),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_ct = cuda_key.key.key.scalar_bitor(
@@ -906,6 +1033,18 @@ impl BitXor<bool> for &FheBool {
                     key.tag.clone(),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_ct = fpga_key
+                    .pbs_key()
+                    .key
+                    .scalar_bitxor(self.ciphertext.on_cpu().as_ref(), u8::from(rhs));
+                (
+                    InnerBoolean::Cpu(BooleanBlock::new_unchecked(inner_ct)),
+                    fpga_key.tag.clone(),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_ct = cuda_key.key.key.scalar_bitxor(
@@ -1110,6 +1249,14 @@ where
                     &rhs.ciphertext.on_cpu().0,
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().key.bitand_assign(
+                    &mut self.ciphertext.as_cpu_mut().0,
+                    &rhs.ciphertext.on_cpu().0,
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.bitand_assign(
@@ -1153,6 +1300,14 @@ where
                     &rhs.ciphertext.on_cpu().0,
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().key.bitor_assign(
+                    &mut self.ciphertext.as_cpu_mut().0,
+                    &rhs.ciphertext.on_cpu().0,
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.bitor_assign(
@@ -1196,6 +1351,14 @@ where
                     &rhs.ciphertext.on_cpu().0,
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().key.bitxor_assign(
+                    &mut self.ciphertext.as_cpu_mut().0,
+                    &rhs.ciphertext.on_cpu().0,
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.bitxor_assign(
@@ -1233,6 +1396,14 @@ impl BitAndAssign<bool> for FheBool {
                     .key
                     .scalar_bitand_assign(&mut self.ciphertext.as_cpu_mut().0, u8::from(rhs));
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                    .pbs_key()
+                    .key
+                    .scalar_bitand_assign(&mut self.ciphertext.as_cpu_mut().0, u8::from(rhs));
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.scalar_bitand_assign(
@@ -1270,6 +1441,14 @@ impl BitOrAssign<bool> for FheBool {
                     .key
                     .scalar_bitor_assign(&mut self.ciphertext.as_cpu_mut().0, u8::from(rhs));
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                    .pbs_key()
+                    .key
+                    .scalar_bitor_assign(&mut self.ciphertext.as_cpu_mut().0, u8::from(rhs));
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.scalar_bitor_assign(
@@ -1302,8 +1481,16 @@ impl BitXorAssign<bool> for FheBool {
     /// ```
     fn bitxor_assign(&mut self, rhs: bool) {
         global_state::with_internal_keys(|key| match key {
-            InternalServerKey::Cpu(key) => {
-                key.pbs_key()
+            InternalServerKey::Cpu(ServerKey { key, .. }) => {
+                key.key
+                    .key
+                    .scalar_bitxor_assign(&mut self.ciphertext.as_cpu_mut().0, u8::from(rhs));
+            }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                    .pbs_key()
                     .key
                     .scalar_bitxor_assign(&mut self.ciphertext.as_cpu_mut().0, u8::from(rhs));
             }
@@ -1370,6 +1557,12 @@ impl std::ops::Not for &FheBool {
                 let inner = key.pbs_key().boolean_bitnot(&self.ciphertext.on_cpu());
                 (InnerBoolean::Cpu(inner), key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner = fpga_key.pbs_key().boolean_bitnot(&self.ciphertext.on_cpu());
+                (InnerBoolean::Cpu(inner), fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner = cuda_key
diff --git a/tfhe/src/high_level_api/booleans/encrypt.rs b/tfhe/src/high_level_api/booleans/encrypt.rs
index c339a2b8..f603fd5a 100644
--- a/tfhe/src/high_level_api/booleans/encrypt.rs
+++ b/tfhe/src/high_level_api/booleans/encrypt.rs
@@ -89,6 +89,11 @@ impl FheTryTrivialEncrypt<bool> for FheBool {
                 let ct = InnerBoolean::Cpu(key.pbs_key().create_trivial_boolean_block(value));
                 (ct, key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let ct = InnerBoolean::Cpu(fpga_key.pbs_key().create_trivial_boolean_block(value));
+                (ct, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner: CudaUnsignedRadixCiphertext =
diff --git a/tfhe/src/high_level_api/booleans/inner.rs b/tfhe/src/high_level_api/booleans/inner.rs
index a9b40226..b19e0f93 100644
--- a/tfhe/src/high_level_api/booleans/inner.rs
+++ b/tfhe/src/high_level_api/booleans/inner.rs
@@ -200,6 +200,10 @@ impl InnerBoolean {
             (Self::Cpu(_), Device::Cpu) => {
                 // Nothing to do, we already are on the correct device
             }
+            #[cfg(feature = "fpga")]
+            (Self::Cpu(_), Device::Fpga) => {
+                panic!("No CPU->FPGA implementation")
+            }
             #[cfg(feature = "gpu")]
             (Self::Cuda(_), Device::CudaGpu) => {
                 // Nothing to do, we already are on the correct device
diff --git a/tfhe/src/high_level_api/booleans/oprf.rs b/tfhe/src/high_level_api/booleans/oprf.rs
index efd1d6c2..243c24cc 100644
--- a/tfhe/src/high_level_api/booleans/oprf.rs
+++ b/tfhe/src/high_level_api/booleans/oprf.rs
@@ -30,6 +30,15 @@ impl FheBool {
 
                 Self::new(BooleanBlock(ct), key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                let ct = fpga_key
+                    .pbs_key()
+                    .key
+                    .generate_oblivious_pseudo_random(seed, 1);
+
+                Self::new(BooleanBlock(ct), fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 todo!("Cuda devices do not yet support oblivious pseudo random generation")
diff --git a/tfhe/src/high_level_api/booleans/tests.rs b/tfhe/src/high_level_api/booleans/tests.rs
index e6127628..762bfff8 100644
--- a/tfhe/src/high_level_api/booleans/tests.rs
+++ b/tfhe/src/high_level_api/booleans/tests.rs
@@ -727,7 +727,7 @@ mod gpu {
 
     fn setup_gpu_default() -> ClientKey {
         let config = ConfigBuilder::default().build();
-        let cks = crate::ClientKey::generate(config);
+        let cks = ClientKey::generate(config);
         let csks = crate::CompressedServerKey::new(&cks);
 
         let server_keys = csks.decompress_to_gpu();
diff --git a/tfhe/src/high_level_api/compact_list.rs b/tfhe/src/high_level_api/compact_list.rs
index 6e52c6e5..69e922d6 100644
--- a/tfhe/src/high_level_api/compact_list.rs
+++ b/tfhe/src/high_level_api/compact_list.rs
@@ -7,7 +7,7 @@ use crate::conformance::ParameterSetConformant;
 use crate::core_crypto::commons::math::random::{Deserialize, Serialize};
 use crate::core_crypto::prelude::Numeric;
 use crate::high_level_api::global_state;
-use crate::high_level_api::keys::InternalServerKey;
+use crate::high_level_api::keys::{InternalServerKey, ServerKey};
 use crate::high_level_api::traits::Tagged;
 use crate::integer::ciphertext::{Compactable, DataKind, Expandable};
 use crate::integer::encryption::KnowsMessageModulus;
@@ -138,6 +138,15 @@ impl CompactCiphertextList {
                     inner,
                     tag: self.tag.clone(),
                 }),
+            // TODO: FPGA implementation
+            #[cfg(feature = "fpga")]
+            Some(InternalServerKey::Belfort(fpga_key)) => self
+                .inner
+                .expand(ServerKey::from(fpga_key).integer_compact_ciphertext_list_expansion_mode())
+                .map(|inner| CompactCiphertextListExpander {
+                    inner,
+                    tag: self.tag.clone(),
+                }),
             #[cfg(feature = "gpu")]
             Some(_) => Err(crate::Error::new("Expected a CPU server key".to_string())),
         })
diff --git a/tfhe/src/high_level_api/global_state.rs b/tfhe/src/high_level_api/global_state.rs
index 1593ede6..5ff13f46 100644
--- a/tfhe/src/high_level_api/global_state.rs
+++ b/tfhe/src/high_level_api/global_state.rs
@@ -115,6 +115,8 @@ pub(in crate::high_level_api) fn device_of_internal_keys() -> Option<crate::Devi
         let cell = keys.borrow();
         Some(match cell.as_ref()? {
             InternalServerKey::Cpu(_) => crate::Device::Cpu,
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(_) => crate::Device::Fpga,
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => crate::Device::CudaGpu,
         })
@@ -128,6 +130,8 @@ pub(in crate::high_level_api) fn tag_of_internal_server_key() -> crate::Result<c
         let cell = keys.borrow();
         Ok(match cell.as_ref().ok_or(UninitializedServerKey)? {
             InternalServerKey::Cpu(cpu_key) => cpu_key.tag.clone(),
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => fpga_key.tag.clone(),
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => cuda_key.tag.clone(),
         })
@@ -148,6 +152,8 @@ where
             .unwrap_display();
         match key {
             InternalServerKey::Cpu(key) => func(key),
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(key) => func(&key.into()),
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cpu key requested but only cuda key is available")
diff --git a/tfhe/src/high_level_api/integers/oprf.rs b/tfhe/src/high_level_api/integers/oprf.rs
index 4ee3ec10..8cc2ded8 100644
--- a/tfhe/src/high_level_api/integers/oprf.rs
+++ b/tfhe/src/high_level_api/integers/oprf.rs
@@ -4,42 +4,6 @@ use crate::high_level_api::keys::InternalServerKey;
 use crate::{FheInt, FheUint, Seed};
 
 impl<Id: FheUintId> FheUint<Id> {
-    /// Generates an encrypted unsigned integer
-    /// taken uniformly in its full range using the given seed.
-    /// The encryted value is oblivious to the server.
-    /// It can be useful to make server random generation deterministic.
-    ///
-    /// ```rust
-    /// use tfhe::prelude::FheDecrypt;
-    /// use tfhe::{generate_keys, set_server_key, ConfigBuilder, FheUint8, Seed};
-    ///
-    /// let config = ConfigBuilder::default().build();
-    /// let (client_key, server_key) = generate_keys(config);
-    ///
-    /// set_server_key(server_key);
-    ///
-    /// let ct_res = FheUint8::generate_oblivious_pseudo_random(Seed(0));
-    ///
-    /// let dec_result: u16 = ct_res.decrypt(&client_key);
-    /// ```
-    pub fn generate_oblivious_pseudo_random(seed: Seed) -> Self {
-        global_state::with_internal_keys(|key| match key {
-            InternalServerKey::Cpu(key) => {
-                let ct = key
-                    .pbs_key()
-                    .par_generate_oblivious_pseudo_random_unsigned_integer(
-                        seed,
-                        Id::num_blocks(key.message_modulus()) as u64,
-                    );
-
-                Self::new(ct, key.tag.clone())
-            }
-            #[cfg(feature = "gpu")]
-            InternalServerKey::Cuda(_) => {
-                todo!("Cuda devices do not yet support oblivious pseudo random generation")
-            }
-        })
-    }
     /// Generates an encrypted `num_block` blocks unsigned integer
     /// taken uniformly in `[0, 2^random_bits_count[` using the given seed.
     /// The encryted value is oblivious to the server.
@@ -61,7 +25,7 @@ impl<Id: FheUintId> FheUint<Id> {
     /// let dec_result: u16 = ct_res.decrypt(&client_key);
     /// assert!(dec_result < (1 << random_bits_count));
     /// ```
-    pub fn generate_oblivious_pseudo_random_bounded(seed: Seed, random_bits_count: u64) -> Self {
+    pub fn generate_oblivious_pseudo_random(seed: Seed, random_bits_count: u64) -> Self {
         global_state::with_internal_keys(|key| match key {
             InternalServerKey::Cpu(key) => {
                 let ct = key
@@ -74,6 +38,19 @@ impl<Id: FheUintId> FheUint<Id> {
 
                 Self::new(ct, key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let ct = fpga_key
+                    .pbs_key()
+                    .par_generate_oblivious_pseudo_random_unsigned_integer_bounded(
+                        seed,
+                        random_bits_count,
+                        Id::num_blocks(fpga_key.key.message_modulus()) as u64,
+                    );
+
+                Self::new(ct, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 todo!("Cuda devices do not yet support oblivious pseudo random generation")
@@ -114,6 +91,17 @@ impl<Id: FheIntId> FheInt<Id> {
                     );
                 Self::new(ct, key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA Implementation
+                let ct = fpga_key
+                    .pbs_key()
+                    .par_generate_oblivious_pseudo_random_signed_integer(
+                        seed,
+                        Id::num_blocks(fpga_key.key.message_modulus()) as u64,
+                    );
+                Self::new(ct, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 todo!("Cuda devices do not yet support oblivious pseudo random generation")
@@ -156,6 +144,19 @@ impl<Id: FheIntId> FheInt<Id> {
 
                 Self::new(ct, key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let ct = fpga_key
+                    .pbs_key()
+                    .par_generate_oblivious_pseudo_random_signed_integer_bounded(
+                        seed,
+                        random_bits_count,
+                        Id::num_blocks(fpga_key.key.message_modulus()) as u64,
+                    );
+
+                Self::new(ct, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 todo!("Cuda devices do not yet support oblivious pseudo random generation")
diff --git a/tfhe/src/high_level_api/integers/signed/base.rs b/tfhe/src/high_level_api/integers/signed/base.rs
index cc2e4987..6c94cdcb 100644
--- a/tfhe/src/high_level_api/integers/signed/base.rs
+++ b/tfhe/src/high_level_api/integers/signed/base.rs
@@ -186,6 +186,14 @@ where
                     .abs_parallelized(&*self.ciphertext.on_cpu());
                 Self::new(ciphertext, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let ciphertext = fpga_key
+                    .pbs_key()
+                    .abs_parallelized(&*self.ciphertext.on_cpu());
+                Self::new(ciphertext, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices does not support abs yet")
@@ -218,6 +226,14 @@ where
                     .is_even_parallelized(&*self.ciphertext.on_cpu());
                 FheBool::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .is_even_parallelized(&*self.ciphertext.on_cpu());
+                FheBool::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key
@@ -254,6 +270,14 @@ where
                     .is_odd_parallelized(&*self.ciphertext.on_cpu());
                 FheBool::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .is_odd_parallelized(&*self.ciphertext.on_cpu());
+                FheBool::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key.key.key.is_odd(&*self.ciphertext.on_gpu(), streams);
@@ -291,6 +315,18 @@ where
                 );
                 crate::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .leading_zeros_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    crate::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                crate::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key
@@ -336,6 +372,18 @@ where
                 );
                 crate::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .leading_ones_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    crate::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                crate::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key
@@ -381,6 +429,18 @@ where
                 );
                 crate::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .trailing_zeros_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    crate::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                crate::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key
@@ -426,6 +486,18 @@ where
                 );
                 crate::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .trailing_ones_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    crate::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                crate::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key
@@ -472,6 +544,18 @@ where
                 );
                 crate::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .count_ones_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    crate::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                crate::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support count_ones yet");
@@ -509,6 +593,18 @@ where
                 );
                 crate::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .count_zeros_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    crate::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                crate::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support count_zeros yet");
@@ -547,6 +643,18 @@ where
                 );
                 crate::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .ilog2_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    crate::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                crate::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key.key.key.ilog2(&*self.ciphertext.on_gpu(), streams);
@@ -598,6 +706,21 @@ where
                     FheBool::new(is_ok, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (result, is_ok) = fpga_key
+                    .pbs_key()
+                    .checked_ilog2_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    crate::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                (
+                    crate::FheUint32::new(result, fpga_key.tag.clone()),
+                    FheBool::new(is_ok, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let (result, is_ok) = cuda_key
@@ -684,6 +807,15 @@ where
 
                 Self::new(sk.reverse_bits_parallelized(&*ct), cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let sk = &fpga_key.pbs_key();
+
+                let ct = self.ciphertext.on_cpu();
+
+                Self::new(sk.reverse_bits_parallelized(&*ct), fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support reverse yet");
@@ -723,6 +855,15 @@ where
                     .cast_to_signed(input.ciphertext.into_cpu(), target_num_blocks);
                 Self::new(new_ciphertext, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let target_num_blocks = IntoId::num_blocks(fpga_key.key.message_modulus());
+                let new_ciphertext = fpga_key
+                    .pbs_key()
+                    .cast_to_signed(input.ciphertext.into_cpu(), target_num_blocks);
+                Self::new(new_ciphertext, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let target_num_blocks = IntoId::num_blocks(cuda_key.message_modulus());
@@ -768,6 +909,15 @@ where
                 );
                 Self::new(new_ciphertext, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let new_ciphertext = fpga_key.pbs_key().cast_to_signed(
+                    input.ciphertext.on_cpu().to_owned(),
+                    IntoId::num_blocks(fpga_key.key.message_modulus()),
+                );
+                Self::new(new_ciphertext, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let new_ciphertext = cuda_key.key.key.cast_to_signed(
@@ -815,6 +965,19 @@ where
                 );
                 Self::new(ciphertext, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO FPGA Implementation
+                let ciphertext = input
+                    .ciphertext
+                    .on_cpu()
+                    .into_owned()
+                    .into_radix::<crate::integer::SignedRadixCiphertext>(
+                    Id::num_blocks(fpga_key.key.message_modulus()),
+                    fpga_key.pbs_key(),
+                );
+                Self::new(ciphertext, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner = cuda_key.key.key.cast_to_signed(
diff --git a/tfhe/src/high_level_api/integers/signed/compressed.rs b/tfhe/src/high_level_api/integers/signed/compressed.rs
index 9fbe0463..c4a1a680 100644
--- a/tfhe/src/high_level_api/integers/signed/compressed.rs
+++ b/tfhe/src/high_level_api/integers/signed/compressed.rs
@@ -97,6 +97,18 @@ where
             tag,
         }
     }
+
+    pub fn from_integer_compressed_signed_radix_ciphertext(
+        ciphertext: IntegerCompressedSignedRadixCiphertext,
+        id: Id,
+        tag: Tag,
+    ) -> Self {
+        Self {
+            ciphertext: CompressedSignedRadixCiphertext::Seeded(ciphertext),
+            id,
+            tag,
+        }
+    }
 }
 
 impl<Id> CompressedFheInt<Id>
diff --git a/tfhe/src/high_level_api/integers/signed/inner.rs b/tfhe/src/high_level_api/integers/signed/inner.rs
index dfcc9e15..1a029239 100644
--- a/tfhe/src/high_level_api/integers/signed/inner.rs
+++ b/tfhe/src/high_level_api/integers/signed/inner.rs
@@ -190,6 +190,10 @@ impl RadixCiphertext {
             (Self::Cpu(_), Device::Cpu) => {
                 // Nothing to do, we already are on the correct device
             }
+            #[cfg(feature = "fpga")]
+            (Self::Cpu(_), Device::Fpga) => {
+                panic!("No CPU->FPGA implementation")
+            }
             #[cfg(feature = "gpu")]
             (Self::Cuda(_), Device::CudaGpu) => {
                 // Nothing to do, we already are on the correct device
diff --git a/tfhe/src/high_level_api/integers/signed/ops.rs b/tfhe/src/high_level_api/integers/signed/ops.rs
index fcf0b6e9..bbe0682a 100644
--- a/tfhe/src/high_level_api/integers/signed/ops.rs
+++ b/tfhe/src/high_level_api/integers/signed/ops.rs
@@ -66,6 +66,26 @@ where
                         |ct| Self::new(ct, cpu_key.tag.clone()),
                     )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let ciphertexts = iter
+                    .map(|elem| elem.ciphertext.on_cpu().to_owned())
+                    .collect::<Vec<_>>();
+                fpga_key
+                    .pbs_key()
+                    .sum_ciphertexts_parallelized(ciphertexts.iter())
+                    .map_or_else(
+                        || {
+                            let radix: crate::integer::SignedRadixCiphertext =
+                                fpga_key.pbs_key().create_trivial_zero_radix(Id::num_blocks(
+                                    fpga_key.key.message_modulus(),
+                                ));
+                            Self::new(radix, fpga_key.tag.clone())
+                        },
+                        |ct| Self::new(ct, fpga_key.tag.clone()),
+                    )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support sum of signed integers");
@@ -107,6 +127,14 @@ where
                     .max_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 Self::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .max_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                Self::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.max(
@@ -153,6 +181,14 @@ where
                     .min_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 Self::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .min_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                Self::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.min(
@@ -210,6 +246,14 @@ where
                     .eq_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .eq_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.eq(
@@ -249,6 +293,14 @@ where
                     .ne_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .ne_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.ne(
@@ -314,6 +366,14 @@ where
                     .lt_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .lt_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.lt(
@@ -353,6 +413,13 @@ where
                     .le_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .le_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.le(
@@ -392,6 +459,14 @@ where
                     .gt_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .gt_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.gt(
@@ -431,6 +506,13 @@ where
                     .ge_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .ge_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.ge(
@@ -513,6 +595,17 @@ where
                     FheInt::<Id>::new(r, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (q, r) = fpga_key
+                    .pbs_key()
+                    .div_rem_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                (
+                    FheInt::<Id>::new(q, fpga_key.tag.clone()),
+                    FheInt::<Id>::new(r, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices does not support division yet")
@@ -588,6 +681,14 @@ generic_integer_impl_operation!(
                         .add_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheInt::new(inner_result, cpu_key.tag.clone())
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .add_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheInt::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -631,6 +732,13 @@ generic_integer_impl_operation!(
                         .sub_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheInt::new(inner_result, cpu_key.tag.clone())
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .sub_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheInt::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -674,6 +782,14 @@ generic_integer_impl_operation!(
                         .mul_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheInt::new(inner_result, cpu_key.tag.clone())
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .mul_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheInt::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                      with_thread_local_cuda_streams(|streams| {
@@ -715,6 +831,14 @@ generic_integer_impl_operation!(
                         .bitand_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheInt::new(inner_result, cpu_key.tag.clone())
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .bitand_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheInt::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                      with_thread_local_cuda_streams(|streams| {
@@ -750,12 +874,20 @@ generic_integer_impl_operation!(
     implem: {
         |lhs: &FheInt<_>, rhs: &FheInt<_>| {
             global_state::with_internal_keys(|key| match key {
-                InternalServerKey::Cpu(cpu_key) => {
+                InternalServerKey::Cpu(cpu_key)=> {
                     let inner_result = cpu_key
                         .pbs_key()
                         .bitor_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheInt::new(inner_result, cpu_key.tag.clone())
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .bitor_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheInt::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                      with_thread_local_cuda_streams(|streams| {
@@ -797,6 +929,14 @@ generic_integer_impl_operation!(
                         .bitxor_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheInt::new(inner_result, cpu_key.tag.clone())
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .bitxor_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheInt::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                      with_thread_local_cuda_streams(|streams| {
@@ -846,6 +986,14 @@ generic_integer_impl_operation!(
                         .div_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheInt::new(inner_result, cpu_key.tag.clone())
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .div_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheInt::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(_cuda_key) => {
                     panic!("Division '/' is not yet supported by Cuda devices")
@@ -892,6 +1040,14 @@ generic_integer_impl_operation!(
                         .rem_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheInt::new(inner_result, cpu_key.tag.clone())
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .rem_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheInt::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(_cuda_key) => {
                     panic!("Remainder/Modulo '%' is not yet supported by Cuda devices")
@@ -1001,6 +1157,14 @@ generic_integer_impl_shift_rotate!(
                             .left_shift_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
                         FheInt::new(ciphertext, cpu_key.tag.clone())
                     }
+                    #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                        // TODO: FPGA implementation
+                        let ciphertext = fpga_key
+                            .pbs_key()
+                            .left_shift_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
+                        FheInt::new(ciphertext, fpga_key.tag.clone())
+                    }
                     #[cfg(feature = "gpu")]
                     InternalServerKey::Cuda(cuda_key) => {
                          with_thread_local_cuda_streams(|streams| {
@@ -1040,10 +1204,18 @@ generic_integer_impl_shift_rotate!(
             global_state::with_internal_keys(|key| {
                 match key {
                     InternalServerKey::Cpu(cpu_key) => {
-                        let ciphertext = cpu_key
+                                let ciphertext = cpu_key
+                                    .pbs_key()
+                                    .right_shift_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
+                                FheInt::new(ciphertext, cpu_key.tag.clone())
+                            }
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                        let ciphertext = fpga_key
                             .pbs_key()
                             .right_shift_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
-                        FheInt::new(ciphertext, cpu_key.tag.clone())
+                        FheInt::new(ciphertext, fpga_key.tag.clone())
                     }
                     #[cfg(feature = "gpu")]
                     InternalServerKey::Cuda(cuda_key) => {
@@ -1089,6 +1261,14 @@ generic_integer_impl_shift_rotate!(
                             .rotate_left_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
                         FheInt::new(ciphertext, cpu_key.tag.clone())
                     }
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                        let ciphertext = fpga_key
+                            .pbs_key()
+                            .rotate_left_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
+                        FheInt::new(ciphertext, fpga_key.tag.clone())
+                    }
                     #[cfg(feature = "gpu")]
                     InternalServerKey::Cuda(cuda_key) => {
                          with_thread_local_cuda_streams(|streams| {
@@ -1133,6 +1313,14 @@ generic_integer_impl_shift_rotate!(
                             .rotate_right_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
                         FheInt::new(ciphertext, cpu_key.tag.clone())
                     }
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                        let ciphertext = fpga_key
+                            .pbs_key()
+                            .rotate_right_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
+                        FheInt::new(ciphertext, fpga_key.tag.clone())
+                    }
                     #[cfg(feature = "gpu")]
                     InternalServerKey::Cuda(cuda_key) => {
                          with_thread_local_cuda_streams(|streams| {
@@ -1183,6 +1371,14 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().add_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &*rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -1230,6 +1426,14 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().sub_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &*rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -1277,6 +1481,14 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().mul_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &*rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -1322,6 +1534,14 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().bitand_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &*rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -1367,6 +1587,14 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().bitor_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &*rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -1412,6 +1640,14 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().bitxor_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &*rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -1462,6 +1698,14 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().div_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &*rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support division");
@@ -1506,6 +1750,14 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().rem_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &*rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support remainder");
@@ -1555,6 +1807,14 @@ where
                     &rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().left_shift_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 with_thread_local_cuda_streams(|streams| {
@@ -1609,6 +1869,14 @@ where
                     &rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().right_shift_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 with_thread_local_cuda_streams(|streams| {
@@ -1664,6 +1932,13 @@ where
                     &rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key.pbs_key().rotate_left_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 with_thread_local_cuda_streams(|streams| {
@@ -1721,6 +1996,14 @@ where
                     &rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().rotate_right_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 with_thread_local_cuda_streams(|streams| {
@@ -1794,6 +2077,14 @@ where
                     .neg_parallelized(&*self.ciphertext.on_cpu());
                 FheInt::new(ciphertext, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let ciphertext = fpga_key
+                    .pbs_key()
+                    .neg_parallelized(&*self.ciphertext.on_cpu());
+                FheInt::new(ciphertext, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.neg(&*self.ciphertext.on_gpu(), streams);
@@ -1860,6 +2151,12 @@ where
                 let ciphertext = cpu_key.pbs_key().bitnot(&*self.ciphertext.on_cpu());
                 FheInt::new(ciphertext, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let ciphertext = fpga_key.pbs_key().bitnot(&*self.ciphertext.on_cpu());
+                FheInt::new(ciphertext, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.bitnot(&*self.ciphertext.on_gpu(), streams);
diff --git a/tfhe/src/high_level_api/integers/signed/overflowing_ops.rs b/tfhe/src/high_level_api/integers/signed/overflowing_ops.rs
index c628ba03..1b3adb53 100644
--- a/tfhe/src/high_level_api/integers/signed/overflowing_ops.rs
+++ b/tfhe/src/high_level_api/integers/signed/overflowing_ops.rs
@@ -52,6 +52,17 @@ where
                     FheBool::new(overflow, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let (result, overflow) = fpga_key.pbs_key().signed_overflowing_add_parallelized(
+                    &self.ciphertext.on_cpu(),
+                    &other.ciphertext.on_cpu(),
+                );
+                (
+                    FheInt::new(result, fpga_key.tag.clone()),
+                    FheBool::new(overflow, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let (result, overflow) = cuda_key.key.key.signed_overflowing_add(
@@ -148,6 +159,17 @@ where
                     FheBool::new(overflow, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA Implementation
+                let (result, overflow) = fpga_key
+                    .pbs_key()
+                    .signed_overflowing_scalar_add_parallelized(&self.ciphertext.on_cpu(), other);
+                (
+                    FheInt::new(result, fpga_key.tag.clone()),
+                    FheBool::new(overflow, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let (result, overflow) = cuda_key.key.key.signed_overflowing_scalar_add(
@@ -282,6 +304,18 @@ where
                     FheBool::new(overflow, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (result, overflow) = fpga_key.pbs_key().signed_overflowing_sub_parallelized(
+                    &self.ciphertext.on_cpu(),
+                    &other.ciphertext.on_cpu(),
+                );
+                (
+                    FheInt::new(result, fpga_key.tag.clone()),
+                    FheBool::new(overflow, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let (result, overflow) = cuda_key.key.key.signed_overflowing_sub(
@@ -377,6 +411,17 @@ where
                     FheBool::new(overflow, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (result, overflow) = fpga_key
+                    .pbs_key()
+                    .signed_overflowing_scalar_sub_parallelized(&self.ciphertext.on_cpu(), other);
+                (
+                    FheInt::new(result, fpga_key.tag.clone()),
+                    FheBool::new(overflow, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let (result, overflow) = cuda_key.key.key.signed_overflowing_scalar_sub(
@@ -473,6 +518,18 @@ where
                     FheBool::new(overflow, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (result, overflow) = fpga_key.pbs_key().signed_overflowing_mul_parallelized(
+                    &self.ciphertext.on_cpu(),
+                    &other.ciphertext.on_cpu(),
+                );
+                (
+                    FheInt::new(result, fpga_key.tag.clone()),
+                    FheBool::new(overflow, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 todo!("Cuda devices do not support signed integer");
diff --git a/tfhe/src/high_level_api/integers/signed/scalar_ops.rs b/tfhe/src/high_level_api/integers/signed/scalar_ops.rs
index cb79e4ff..32799237 100644
--- a/tfhe/src/high_level_api/integers/signed/scalar_ops.rs
+++ b/tfhe/src/high_level_api/integers/signed/scalar_ops.rs
@@ -53,6 +53,14 @@ where
                     .scalar_max_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 Self::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_max_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                Self::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -101,6 +109,14 @@ where
                     .scalar_min_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 Self::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_min_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                Self::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -148,6 +164,14 @@ where
                     .scalar_eq_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_eq_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -189,6 +213,14 @@ where
                     .scalar_ne_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_ne_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -235,6 +267,14 @@ where
                     .scalar_lt_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_lt_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -275,6 +315,14 @@ where
                     .scalar_le_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_le_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -315,6 +363,14 @@ where
                     .scalar_gt_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_gt_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -355,6 +411,14 @@ where
                     .scalar_ge_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_ge_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 crate::high_level_api::global_state::with_thread_local_cuda_streams(|streams| {
@@ -406,6 +470,17 @@ macro_rules! generic_integer_impl_scalar_div_rem {
                                     <$concrete_type>::new(r, cpu_key.tag.clone())
                                 )
                             }
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                                let (q, r) = fpga_key
+                                    .pbs_key()
+                                    .signed_scalar_div_rem_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                                (
+                                    <$concrete_type>::new(q, fpga_key.tag.clone()),
+                                    <$concrete_type>::new(r, fpga_key.tag.clone())
+                                )
+                            }
                             #[cfg(feature = "gpu")]
                             InternalServerKey::Cuda(cuda_key) => {
                                 let (inner_q, inner_r) = with_thread_local_cuda_streams(|streams| {
@@ -460,6 +535,14 @@ generic_integer_impl_scalar_operation!(
                         .scalar_add_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                                    // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .scalar_add_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -493,7 +576,15 @@ generic_integer_impl_scalar_operation!(
         |lhs: &FheInt<_>, rhs| {
             global_state::with_internal_keys(|key| match key {
                 InternalServerKey::Cpu(cpu_key) => {
-                    let inner_result = cpu_key
+                        let inner_result = cpu_key
+                            .pbs_key()
+                            .scalar_sub_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                        RadixCiphertext::Cpu(inner_result)
+                    },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
                         .pbs_key()
                         .scalar_sub_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
@@ -530,12 +621,20 @@ generic_integer_impl_scalar_operation!(
     implem: {
         |lhs: &FheInt<_>, rhs| {
             global_state::with_internal_keys(|key| match key {
-                InternalServerKey::Cpu(cpu_key) => {
+                InternalServerKey::Cpu(cpu_key)=> {
                     let inner_result = cpu_key
                         .pbs_key()
                         .scalar_mul_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .scalar_mul_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -574,6 +673,14 @@ generic_integer_impl_scalar_operation!(
                         .scalar_bitand_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .scalar_bitand_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -612,6 +719,14 @@ generic_integer_impl_scalar_operation!(
                         .scalar_bitor_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                                    // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .scalar_bitor_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -644,13 +759,22 @@ generic_integer_impl_scalar_operation!(
     implem: {
         |lhs: &FheInt<_>, rhs| {
             global_state::with_internal_keys(|key| match key {
-                InternalServerKey::Cpu(cpu_key) => {
+                InternalServerKey::Cpu(cpu_key)=> {
                     let inner_result = cpu_key
                         .pbs_key()
                         .scalar_bitxor_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
 
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .scalar_bitxor_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
+
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -683,12 +807,20 @@ generic_integer_impl_scalar_operation!(
     implem: {
         |lhs: &FheInt<_>, rhs| {
             global_state::with_internal_keys(|key| match key {
-                InternalServerKey::Cpu(cpu_key) => {
+                InternalServerKey::Cpu(cpu_key)=> {
                     let inner_result = cpu_key
                         .pbs_key()
                         .scalar_left_shift_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .scalar_left_shift_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -727,6 +859,14 @@ generic_integer_impl_scalar_operation!(
                         .scalar_right_shift_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .scalar_right_shift_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -765,6 +905,14 @@ generic_integer_impl_scalar_operation!(
                         .scalar_rotate_left_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .scalar_rotate_left_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -797,12 +945,20 @@ generic_integer_impl_scalar_operation!(
     implem: {
         |lhs: &FheInt<_>, rhs| {
             global_state::with_internal_keys(|key| match key {
-                InternalServerKey::Cpu(cpu_key) => {
+                InternalServerKey::Cpu(cpu_key)=> {
                     let inner_result = cpu_key
                         .pbs_key()
                         .scalar_rotate_right_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .scalar_rotate_right_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -841,6 +997,14 @@ generic_integer_impl_scalar_operation!(
                         .signed_scalar_div_parallelized(&lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .signed_scalar_div_parallelized(&lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -873,12 +1037,20 @@ generic_integer_impl_scalar_operation!(
     implem: {
         |lhs: &FheInt<_>, rhs| {
             global_state::with_internal_keys(|key| match key {
-                InternalServerKey::Cpu(cpu_key) => {
+                InternalServerKey::Cpu(cpu_key)=> {
                     let inner_result = cpu_key
                         .pbs_key()
                         .signed_scalar_rem_parallelized(&lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .signed_scalar_rem_parallelized(&lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -968,6 +1140,17 @@ generic_integer_impl_scalar_left_operation!(
                         .sub_assign_parallelized(&mut result, &*rhs.ciphertext.on_cpu());
                     RadixCiphertext::Cpu(result)
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                    let mut result = fpga_key
+                        .pbs_key()
+                        .create_trivial_radix(lhs, rhs.ciphertext.on_cpu().blocks().len());
+                    fpga_key
+                        .pbs_key()
+                        .sub_assign_parallelized(&mut result, &*rhs.ciphertext.on_cpu());
+                    RadixCiphertext::Cpu(result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(_cuda_key) => {
                     with_thread_local_cuda_streams(|_stream| {
@@ -1196,11 +1379,18 @@ generic_integer_impl_scalar_operation_assign!(
     implem: {
         |lhs: &mut FheInt<_>, rhs| {
             global_state::with_internal_keys(|key| match key {
-                InternalServerKey::Cpu(cpu_key) => {
+                InternalServerKey::Cpu(cpu_key)=> {
                     cpu_key
                         .pbs_key()
                         .scalar_add_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                        .pbs_key()
+                        .scalar_add_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1253,11 +1443,18 @@ generic_integer_impl_scalar_operation_assign!(
     implem: {
         |lhs: &mut FheInt<_>, rhs| {
             global_state::with_internal_keys(|key| match key {
-                InternalServerKey::Cpu(cpu_key) => {
+                InternalServerKey::Cpu(cpu_key)=> {
                     cpu_key
                         .pbs_key()
                         .scalar_sub_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                        .pbs_key()
+                        .scalar_sub_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1288,11 +1485,18 @@ generic_integer_impl_scalar_operation_assign!(
     implem: {
         |lhs: &mut FheInt<_>, rhs| {
             global_state::with_internal_keys(|key| match key {
-                InternalServerKey::Cpu(cpu_key) => {
+                InternalServerKey::Cpu(cpu_key)=> {
                     cpu_key
                         .pbs_key()
                         .scalar_mul_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                        .pbs_key()
+                        .scalar_mul_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1328,6 +1532,13 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_bitand_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                        .pbs_key()
+                        .scalar_bitand_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1363,6 +1574,13 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_bitor_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                        .pbs_key()
+                        .scalar_bitor_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1398,6 +1616,13 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_bitxor_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                        .pbs_key()
+                        .scalar_bitxor_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1433,6 +1658,13 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_left_shift_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                        .pbs_key()
+                        .scalar_left_shift_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1468,6 +1700,13 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_right_shift_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+            #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                        .pbs_key()
+                        .scalar_right_shift_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1502,7 +1741,14 @@ generic_integer_impl_scalar_operation_assign!(
                     cpu_key
                         .pbs_key()
                         .scalar_rotate_left_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
-                },
+                }
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key
+                        .pbs_key()
+                        .scalar_rotate_left_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1537,7 +1783,14 @@ generic_integer_impl_scalar_operation_assign!(
                     cpu_key
                         .pbs_key()
                         .scalar_rotate_right_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
-                },
+                }
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    // TODO: FPGA implementation
+                    fpga_key
+                        .pbs_key()
+                        .scalar_rotate_right_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1572,6 +1825,13 @@ generic_integer_impl_scalar_operation_assign!(
                     cpu_key
                         .pbs_key()
                         .signed_scalar_div_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                }
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    // TODO: FPGA implementation
+                    fpga_key
+                        .pbs_key()
+                        .signed_scalar_div_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(_) => {
@@ -1601,10 +1861,17 @@ generic_integer_impl_scalar_operation_assign!(
         |lhs: &mut FheInt<_>, rhs| {
             global_state::with_internal_keys(|key| match key {
                 InternalServerKey::Cpu(cpu_key) => {
-                    cpu_key
+                        cpu_key
+                            .pbs_key()
+                            .signed_scalar_rem_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                    }
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    // TODO: FPGA implementation
+                    fpga_key
                         .pbs_key()
                         .signed_scalar_rem_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
-                },
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(_) => {
                     panic!("RemAssign '%=' with clear value is not yet supported by Cuda devices")
diff --git a/tfhe/src/high_level_api/integers/unsigned/base.rs b/tfhe/src/high_level_api/integers/unsigned/base.rs
index a0dda24f..f1785702 100644
--- a/tfhe/src/high_level_api/integers/unsigned/base.rs
+++ b/tfhe/src/high_level_api/integers/unsigned/base.rs
@@ -224,6 +224,14 @@ where
                     .is_even_parallelized(&*self.ciphertext.on_cpu());
                 FheBool::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .is_even_parallelized(&*self.ciphertext.on_cpu());
+                FheBool::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key
@@ -260,6 +268,14 @@ where
                     .is_odd_parallelized(&*self.ciphertext.on_cpu());
                 FheBool::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .is_odd_parallelized(&*self.ciphertext.on_cpu());
+                FheBool::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key.key.key.is_odd(&*self.ciphertext.on_gpu(), streams);
@@ -390,6 +406,18 @@ where
                 );
                 super::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .leading_zeros_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    super::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                super::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key
@@ -435,6 +463,18 @@ where
                 );
                 super::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .leading_ones_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    super::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                super::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key
@@ -480,6 +520,18 @@ where
                 );
                 super::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .trailing_zeros_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    super::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                super::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key
@@ -525,6 +577,18 @@ where
                 );
                 super::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .trailing_ones_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    super::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                super::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key
@@ -571,6 +635,18 @@ where
                 );
                 super::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .count_ones_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    super::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                super::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support count_ones yet");
@@ -608,6 +684,17 @@ where
                 );
                 super::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let result = fpga_key
+                    .pbs_key()
+                    .count_zeros_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    super::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                super::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support count_zeros yet");
@@ -646,6 +733,18 @@ where
                 );
                 super::FheUint32::new(result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .ilog2_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    super::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                super::FheUint32::new(result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let result = cuda_key.key.key.ilog2(&*self.ciphertext.on_gpu(), streams);
@@ -697,6 +796,21 @@ where
                     FheBool::new(is_ok, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (result, is_ok) = fpga_key
+                    .pbs_key()
+                    .checked_ilog2_parallelized(&*self.ciphertext.on_cpu());
+                let result = fpga_key.pbs_key().cast_to_unsigned(
+                    result,
+                    super::FheUint32Id::num_blocks(fpga_key.pbs_key().message_modulus()),
+                );
+                (
+                    super::FheUint32::new(result, fpga_key.tag.clone()),
+                    FheBool::new(is_ok, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let (result, is_ok) = cuda_key
@@ -779,6 +893,25 @@ where
                     Err(crate::Error::new("Output type does not have enough bits to represent all possible output values".to_string()))
                 }
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (result, matched) = fpga_key
+                    .pbs_key()
+                    .match_value_parallelized(&self.ciphertext.on_cpu(), matches);
+                let target_num_blocks = OutId::num_blocks(fpga_key.key.message_modulus());
+                if target_num_blocks >= result.blocks.len() {
+                    let result = fpga_key
+                        .pbs_key()
+                        .cast_to_unsigned(result, target_num_blocks);
+                    Ok((
+                        FheUint::new(result, fpga_key.tag.clone()),
+                        FheBool::new(matched, fpga_key.tag.clone()),
+                    ))
+                } else {
+                    Err(crate::Error::new("Output type does not have enough bits to represent all possible output values".to_string()))
+                }
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support match_value yet");
@@ -844,6 +977,24 @@ where
                     Err(crate::Error::new("Output type does not have enough bits to represent all possible output values".to_string()))
                 }
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key.pbs_key().match_value_or_parallelized(
+                    &self.ciphertext.on_cpu(),
+                    matches,
+                    or_value,
+                );
+                let target_num_blocks = OutId::num_blocks(fpga_key.key.message_modulus());
+                if target_num_blocks >= result.blocks.len() {
+                    let result = fpga_key
+                        .pbs_key()
+                        .cast_to_unsigned(result, target_num_blocks);
+                    Ok(FheUint::new(result, fpga_key.tag.clone()))
+                } else {
+                    Err(crate::Error::new("Output type does not have enough bits to represent all possible output values".to_string()))
+                }
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support match_value_or yet");
@@ -880,6 +1031,15 @@ where
 
                 Self::new(sk.reverse_bits_parallelized(&*ct), cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let sk = &fpga_key.pbs_key();
+
+                let ct = self.ciphertext.on_cpu();
+
+                Self::new(sk.reverse_bits_parallelized(&*ct), fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support reverse yet");
@@ -902,6 +1062,12 @@ where
                     sks.pbs_key().key.carry_modulus,
                     sks.pbs_key().key.message_modulus,
                 ),
+                #[cfg(feature = "fpga")]
+                InternalServerKey::Belfort(fpga_key) => (
+                    // TODO: FPGA implementation
+                    fpga_key.pbs_key().key.carry_modulus,
+                    fpga_key.pbs_key().key.message_modulus,
+                ),
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => (
                     cuda_key.key.key.carry_modulus,
@@ -984,6 +1150,15 @@ where
                 );
                 Self::new(casted, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let casted = fpga_key.pbs_key().cast_to_unsigned(
+                    input.ciphertext.into_cpu(),
+                    IntoId::num_blocks(fpga_key.key.message_modulus()),
+                );
+                Self::new(casted, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let casted = cuda_key.key.key.cast_to_unsigned(
@@ -1028,15 +1203,24 @@ where
                 );
                 Self::new(casted, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let casted = fpga_key.pbs_key().cast_to_unsigned(
+                    input.ciphertext.on_cpu().to_owned(),
+                    IntoId::num_blocks(fpga_key.key.message_modulus()),
+                );
+                Self::new(casted, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
-            InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
+            InternalServerKey::Cuda(_) => {
                 let casted = cuda_key.key.key.cast_to_unsigned(
                     input.ciphertext.into_gpu(),
                     IntoId::num_blocks(cuda_key.message_modulus()),
                     streams,
                 );
                 Self::new(casted, cuda_key.tag.clone())
-            }),
+            }
         })
     }
 }
@@ -1072,6 +1256,16 @@ where
                     .into_radix(Id::num_blocks(cpu_key.message_modulus()), cpu_key.pbs_key());
                 Self::new(ciphertext, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let ciphertext: crate::integer::RadixCiphertext =
+                    input.ciphertext.on_cpu().into_owned().into_radix(
+                        Id::num_blocks(fpga_key.key.message_modulus()),
+                        fpga_key.pbs_key(),
+                    );
+                Self::new(ciphertext, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner = cuda_key.key.key.cast_to_unsigned(
diff --git a/tfhe/src/high_level_api/integers/unsigned/compressed.rs b/tfhe/src/high_level_api/integers/unsigned/compressed.rs
index 6a667f20..0ea7ccf1 100644
--- a/tfhe/src/high_level_api/integers/unsigned/compressed.rs
+++ b/tfhe/src/high_level_api/integers/unsigned/compressed.rs
@@ -94,6 +94,18 @@ where
             tag,
         }
     }
+
+    pub fn from_integer_compressed_radix_ciphertext(
+        ciphertext: IntegerCompressedRadixCiphertext,
+        id: Id,
+        tag: Tag,
+    ) -> Self {
+        Self {
+            ciphertext: CompressedRadixCiphertext::Seeded(ciphertext),
+            id,
+            tag,
+        }
+    }
 }
 
 impl<Id> CompressedFheUint<Id>
diff --git a/tfhe/src/high_level_api/integers/unsigned/encrypt.rs b/tfhe/src/high_level_api/integers/unsigned/encrypt.rs
index 593e580e..5cea59a9 100644
--- a/tfhe/src/high_level_api/integers/unsigned/encrypt.rs
+++ b/tfhe/src/high_level_api/integers/unsigned/encrypt.rs
@@ -114,6 +114,14 @@ where
                     .create_trivial_radix(value, Id::num_blocks(key.message_modulus()));
                 Ok(Self::new(ciphertext, key.tag.clone()))
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let ciphertext: crate::integer::RadixCiphertext = fpga_key
+                    .pbs_key()
+                    .create_trivial_radix(value, Id::num_blocks(fpga_key.key.message_modulus()));
+                Ok(Self::new(ciphertext, fpga_key.tag.clone()))
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner: CudaUnsignedRadixCiphertext = cuda_key.key.key.create_trivial_radix(
diff --git a/tfhe/src/high_level_api/integers/unsigned/inner.rs b/tfhe/src/high_level_api/integers/unsigned/inner.rs
index 8ef5e288..c801db11 100644
--- a/tfhe/src/high_level_api/integers/unsigned/inner.rs
+++ b/tfhe/src/high_level_api/integers/unsigned/inner.rs
@@ -194,6 +194,10 @@ impl RadixCiphertext {
             (Self::Cpu(_), Device::Cpu) => {
                 // Nothing to do, we already are on the correct device
             }
+            #[cfg(feature = "fpga")]
+            (Self::Cpu(_), Device::Fpga) => {
+                // Nothing to do, FPGA uses the same RadixCiphertext as CPU
+            }
             #[cfg(feature = "gpu")]
             (Self::Cuda(_), Device::CudaGpu) => {
                 // Nothing to do, we already are on the correct device
diff --git a/tfhe/src/high_level_api/integers/unsigned/ops.rs b/tfhe/src/high_level_api/integers/unsigned/ops.rs
index de242b23..bfbef440 100644
--- a/tfhe/src/high_level_api/integers/unsigned/ops.rs
+++ b/tfhe/src/high_level_api/integers/unsigned/ops.rs
@@ -72,6 +72,25 @@ where
                         |ct| Self::new(ct, cpu_key.tag.clone()),
                     )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let ciphertexts = iter.map(|elem| elem.ciphertext.into_cpu()).collect();
+                fpga_key
+                    .pbs_key()
+                    .unchecked_sum_ciphertexts_vec_parallelized(ciphertexts)
+                    .map_or_else(
+                        || {
+                            Self::new(
+                                RadixCiphertext::Cpu(fpga_key.pbs_key().create_trivial_zero_radix(
+                                    Id::num_blocks(fpga_key.key.message_modulus()),
+                                )),
+                                fpga_key.tag.clone(),
+                            )
+                        },
+                        |ct| Self::new(ct, fpga_key.tag.clone()),
+                    )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let cts = iter
@@ -150,6 +169,30 @@ where
                         |ct| Self::new(ct, cpu_key.tag.clone()),
                     )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let ciphertexts = iter
+                    .map(|elem| elem.ciphertext.on_cpu().to_owned())
+                    .collect();
+                let msg_mod = fpga_key.pbs_key().message_modulus();
+                fpga_key
+                    .pbs_key()
+                    .unchecked_sum_ciphertexts_vec_parallelized(ciphertexts)
+                    .map_or_else(
+                        || {
+                            Self::new(
+                                RadixCiphertext::Cpu(
+                                    fpga_key
+                                        .pbs_key()
+                                        .create_trivial_zero_radix(Id::num_blocks(msg_mod)),
+                                ),
+                                fpga_key.tag.clone(),
+                            )
+                        },
+                        |ct| Self::new(ct, fpga_key.tag.clone()),
+                    )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 with_thread_local_cuda_streams(|streams| {
@@ -221,6 +264,12 @@ where
                     .max_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 Self::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result =
+                    fpga_key.max(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                Self::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.max(
@@ -267,6 +316,12 @@ where
                     .min_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 Self::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result =
+                    fpga_key.min(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                Self::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.min(
@@ -324,6 +379,12 @@ where
                     .eq_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result =
+                    fpga_key.eq(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.eq(
@@ -363,6 +424,12 @@ where
                     .ne_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result =
+                    fpga_key.ne(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.ne(
@@ -428,6 +495,12 @@ where
                     .lt_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result =
+                    fpga_key.lt(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.lt(
@@ -467,6 +540,12 @@ where
                     .le_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result =
+                    fpga_key.le(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.le(
@@ -506,6 +585,12 @@ where
                     .gt_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result =
+                    fpga_key.gt(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.gt(
@@ -545,6 +630,12 @@ where
                     .ge_parallelized(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result =
+                    fpga_key.ge(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.ge(
@@ -628,6 +719,15 @@ where
                     FheUint::<Id>::new(r, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let (q, r) =
+                    fpga_key.div_rem(&*self.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                (
+                    FheUint::<Id>::new(q, fpga_key.tag.clone()),
+                    FheUint::<Id>::new(r, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.div_rem(
@@ -707,12 +807,17 @@ generic_integer_impl_operation!(
     implem: {
         |lhs: &FheUint<_>, rhs: &FheUint<_>| {
             global_state::with_internal_keys(|key| match key {
-                InternalServerKey::Cpu(cpu_key) => {
+                InternalServerKey::Cpu(cpu_key)=> {
                     let inner_result = cpu_key
                         .pbs_key()
                         .add_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheUint::new(inner_result, cpu_key.tag.clone())
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result = fpga_key.add(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheUint::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -756,6 +861,11 @@ generic_integer_impl_operation!(
                         .sub_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheUint::new(inner_result, cpu_key.tag.clone())
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result = fpga_key.sub(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheUint::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -799,6 +909,11 @@ generic_integer_impl_operation!(
                         .mul_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheUint::new(inner_result, cpu_key.tag.clone())
                 },
+                #[cfg(feature = "fpga")]
+                InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result = fpga_key.mul(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheUint::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                      with_thread_local_cuda_streams(|streams| {
@@ -840,6 +955,12 @@ generic_integer_impl_operation!(
                         .bitand_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheUint::new(inner_result, cpu_key.tag.clone())
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.bitand(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheUint::new(inner_result, fpga_key.tag.clone())
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                      with_thread_local_cuda_streams(|streams| {
@@ -881,6 +1002,12 @@ generic_integer_impl_operation!(
                         .bitor_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheUint::new(inner_result, cpu_key.tag.clone())
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.bitor(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheUint::new(inner_result, fpga_key.tag.clone())
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                      with_thread_local_cuda_streams(|streams| {
@@ -922,6 +1049,12 @@ generic_integer_impl_operation!(
                         .bitxor_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheUint::new(inner_result, cpu_key.tag.clone())
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.bitxor(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheUint::new(inner_result, fpga_key.tag.clone())
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                      with_thread_local_cuda_streams(|streams| {
@@ -971,6 +1104,12 @@ generic_integer_impl_operation!(
                         .div_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheUint::new(inner_result, cpu_key.tag.clone())
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.div(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheUint::new(inner_result, fpga_key.tag.clone())
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                     let inner_result =
@@ -1022,6 +1161,12 @@ generic_integer_impl_operation!(
                         .rem_parallelized(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
                     FheUint::new(inner_result, cpu_key.tag.clone())
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.rem(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                    FheUint::new(inner_result, fpga_key.tag.clone())
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                     let inner_result =
@@ -1136,6 +1281,12 @@ generic_integer_impl_shift_rotate!(
                             .left_shift_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
                         FheUint::new(ciphertext, cpu_key.tag.clone())
                     }
+                    #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                        let inner_result =
+                            fpga_key.left_shift(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                        FheUint::new(inner_result, fpga_key.tag.clone())
+                    }
                     #[cfg(feature = "gpu")]
                     InternalServerKey::Cuda(cuda_key) => {
                          with_thread_local_cuda_streams(|streams| {
@@ -1180,6 +1331,12 @@ generic_integer_impl_shift_rotate!(
                             .right_shift_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
                         FheUint::new(ciphertext, cpu_key.tag.clone())
                     }
+                    #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                        let inner_result =
+                            fpga_key.right_shift(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                        FheUint::new(inner_result, fpga_key.tag.clone())
+                    }
                     #[cfg(feature = "gpu")]
                     InternalServerKey::Cuda(cuda_key) => {
                          with_thread_local_cuda_streams(|streams| {
@@ -1224,6 +1381,12 @@ generic_integer_impl_shift_rotate!(
                             .rotate_left_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
                         FheUint::new(ciphertext, cpu_key.tag.clone())
                     }
+                    #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                        let inner_result =
+                            fpga_key.rotate_left(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                        FheUint::new(inner_result, fpga_key.tag.clone())
+                    }
                     #[cfg(feature = "gpu")]
                     InternalServerKey::Cuda(cuda_key) => {
                          with_thread_local_cuda_streams(|streams| {
@@ -1268,6 +1431,12 @@ generic_integer_impl_shift_rotate!(
                             .rotate_right_parallelized(&*lhs.ciphertext.on_cpu(), &rhs.ciphertext.on_cpu());
                         FheUint::new(ciphertext, cpu_key.tag.clone())
                     }
+                    #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                        let inner_result =
+                            fpga_key.rotate_right(&*lhs.ciphertext.on_cpu(), &*rhs.ciphertext.on_cpu());
+                        FheUint::new(inner_result, fpga_key.tag.clone())
+                    }
                     #[cfg(feature = "gpu")]
                     InternalServerKey::Cuda(cuda_key) => {
                          with_thread_local_cuda_streams(|streams| {
@@ -1318,6 +1487,10 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key.add_assign(self.ciphertext.as_cpu_mut(), &*rhs.ciphertext.on_cpu());
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.add_assign(
@@ -1363,6 +1536,13 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key.pbs_key().sub_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &*rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.sub_assign(
@@ -1408,6 +1588,14 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                fpga_key.pbs_key().mul_assign_parallelized(
+                    self.ciphertext.as_cpu_mut(),
+                    &*rhs.ciphertext.on_cpu(),
+                );
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.mul_assign(
@@ -1451,6 +1639,10 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key.bitand_assign(self.ciphertext.as_cpu_mut(), &*rhs.ciphertext.on_cpu());
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.bitand_assign(
@@ -1494,6 +1686,10 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key.bitor_assign(self.ciphertext.as_cpu_mut(), &*rhs.ciphertext.on_cpu());
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.bitor_assign(
@@ -1537,6 +1733,10 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key.bitxor_assign(self.ciphertext.as_cpu_mut(), &*rhs.ciphertext.on_cpu());
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.bitxor_assign(
@@ -1585,6 +1785,10 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key.div_assign(self.ciphertext.as_cpu_mut(), &*rhs.ciphertext.on_cpu());
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.div_assign(
@@ -1633,6 +1837,10 @@ where
                     &*rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key.rem_assign(self.ciphertext.as_cpu_mut(), &*rhs.ciphertext.on_cpu());
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 cuda_key.key.key.rem_assign(
@@ -1686,6 +1894,10 @@ where
                     &rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key.left_shift_assign(self.ciphertext.as_cpu_mut(), &*rhs.ciphertext.on_cpu());
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 with_thread_local_cuda_streams(|streams| {
@@ -1740,6 +1952,11 @@ where
                     &rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key
+                    .right_shift_assign(self.ciphertext.as_cpu_mut(), &*rhs.ciphertext.on_cpu());
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 with_thread_local_cuda_streams(|streams| {
@@ -1795,6 +2012,11 @@ where
                     &rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key
+                    .rotate_left_assign(self.ciphertext.as_cpu_mut(), &*rhs.ciphertext.on_cpu());
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 with_thread_local_cuda_streams(|streams| {
@@ -1850,6 +2072,11 @@ where
                     &rhs.ciphertext.on_cpu(),
                 );
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                fpga_key
+                    .rotate_right_assign(self.ciphertext.as_cpu_mut(), &*rhs.ciphertext.on_cpu());
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => {
                 with_thread_local_cuda_streams(|streams| {
@@ -1931,6 +2158,14 @@ where
                     .neg_parallelized(&*self.ciphertext.on_cpu());
                 FheUint::new(ciphertext, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let ciphertext = fpga_key
+                    .pbs_key()
+                    .neg_parallelized(&*self.ciphertext.on_cpu());
+                FheUint::new(ciphertext, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.neg(&*self.ciphertext.on_gpu(), streams);
@@ -1997,6 +2232,11 @@ where
                 let ciphertext = cpu_key.pbs_key().bitnot(&*self.ciphertext.on_cpu());
                 FheUint::new(ciphertext, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result = fpga_key.bitnot(&*self.ciphertext.on_cpu());
+                FheUint::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.bitnot(&*self.ciphertext.on_gpu(), streams);
diff --git a/tfhe/src/high_level_api/integers/unsigned/overflowing_ops.rs b/tfhe/src/high_level_api/integers/unsigned/overflowing_ops.rs
index 309aae82..36244c41 100644
--- a/tfhe/src/high_level_api/integers/unsigned/overflowing_ops.rs
+++ b/tfhe/src/high_level_api/integers/unsigned/overflowing_ops.rs
@@ -52,6 +52,18 @@ where
                     FheBool::new(overflow, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (result, overflow) = fpga_key.pbs_key().unsigned_overflowing_add_parallelized(
+                    &self.ciphertext.on_cpu(),
+                    &other.ciphertext.on_cpu(),
+                );
+                (
+                    FheUint::new(result, fpga_key.tag.clone()),
+                    FheBool::new(overflow, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.unsigned_overflowing_add(
@@ -148,6 +160,17 @@ where
                     FheBool::new(overflow, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (result, overflow) = fpga_key
+                    .pbs_key()
+                    .unsigned_overflowing_scalar_add_parallelized(&self.ciphertext.on_cpu(), other);
+                (
+                    FheUint::new(result, fpga_key.tag.clone()),
+                    FheBool::new(overflow, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.unsigned_overflowing_scalar_add(
@@ -284,6 +307,18 @@ where
                     FheBool::new(overflow, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (result, overflow) = fpga_key.pbs_key().unsigned_overflowing_sub_parallelized(
+                    &self.ciphertext.on_cpu(),
+                    &other.ciphertext.on_cpu(),
+                );
+                (
+                    FheUint::new(result, fpga_key.tag.clone()),
+                    FheBool::new(overflow, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result = cuda_key.key.key.unsigned_overflowing_sub(
@@ -380,6 +415,17 @@ where
                     FheBool::new(overflow, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (result, overflow) = fpga_key
+                    .pbs_key()
+                    .unsigned_overflowing_scalar_sub_parallelized(&self.ciphertext.on_cpu(), other);
+                (
+                    FheUint::new(result, fpga_key.tag.clone()),
+                    FheBool::new(overflow, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support overflowing_add yet");
@@ -467,6 +513,18 @@ where
                     FheBool::new(overflow, cpu_key.tag.clone()),
                 )
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let (result, overflow) = fpga_key.pbs_key().unsigned_overflowing_mul_parallelized(
+                    &self.ciphertext.on_cpu(),
+                    &other.ciphertext.on_cpu(),
+                );
+                (
+                    FheUint::new(result, fpga_key.tag.clone()),
+                    FheBool::new(overflow, fpga_key.tag.clone()),
+                )
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 todo!("Cuda devices do not support overflowing_mul");
diff --git a/tfhe/src/high_level_api/integers/unsigned/scalar_ops.rs b/tfhe/src/high_level_api/integers/unsigned/scalar_ops.rs
index 7c35e50d..55664305 100644
--- a/tfhe/src/high_level_api/integers/unsigned/scalar_ops.rs
+++ b/tfhe/src/high_level_api/integers/unsigned/scalar_ops.rs
@@ -60,6 +60,11 @@ where
                     .scalar_eq_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result = fpga_key.scalar_eq(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result =
@@ -99,6 +104,11 @@ where
                     .scalar_ne_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                let inner_result = fpga_key.scalar_ne(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result =
@@ -144,6 +154,14 @@ where
                     .scalar_lt_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_lt_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result =
@@ -183,6 +201,14 @@ where
                     .scalar_le_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_le_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result =
@@ -222,6 +248,14 @@ where
                     .scalar_gt_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_gt_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result =
@@ -261,6 +295,14 @@ where
                     .scalar_ge_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 FheBool::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_ge_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                FheBool::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result =
@@ -308,6 +350,14 @@ where
                     .scalar_max_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 Self::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_max_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                Self::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result =
@@ -355,6 +405,14 @@ where
                     .scalar_min_parallelized(&*self.ciphertext.on_cpu(), rhs);
                 Self::new(inner_result, cpu_key.tag.clone())
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let inner_result = fpga_key
+                    .pbs_key()
+                    .scalar_min_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                Self::new(inner_result, fpga_key.tag.clone())
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(cuda_key) => with_thread_local_cuda_streams(|streams| {
                 let inner_result =
@@ -410,6 +468,14 @@ where
                     .scalar_bitslice_parallelized(&self.ciphertext.on_cpu(), range)?;
                 Ok(FheUint::new(result, cpu_key.tag.clone()))
             }
+            #[cfg(feature = "fpga")]
+            InternalServerKey::Belfort(fpga_key) => {
+                // TODO: FPGA implementation
+                let result = fpga_key
+                    .pbs_key()
+                    .scalar_bitslice_parallelized(&self.ciphertext.on_cpu(), range)?;
+                Ok(FheUint::new(result, fpga_key.tag.clone()))
+            }
             #[cfg(feature = "gpu")]
             InternalServerKey::Cuda(_) => {
                 panic!("Cuda devices do not support bitslice yet");
@@ -492,12 +558,20 @@ macro_rules! generic_integer_impl_scalar_div_rem {
                                         <$concrete_type>::new(r, cpu_key.tag.clone())
                                     )
                                 }
+                                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                                    let (q, r) = fpga_key.pbs_key().scalar_div_rem_parallelized(&*self.ciphertext.on_cpu(), rhs);
+                                    (
+                                        <$concrete_type>::new(q, fpga_key.tag.clone()),
+                                        <$concrete_type>::new(r, fpga_key.tag.clone())
+                                    )
+                                }
                                 #[cfg(feature = "gpu")]
                                 InternalServerKey::Cuda(cuda_key) => {
                                     let (inner_q, inner_r) = with_thread_local_cuda_streams(|streams| {
                                         cuda_key.key.key.scalar_div_rem(
                                             &*self.ciphertext.on_gpu(), rhs, streams
-                                            )
+                                        )
                                     });
                                     let (q, r) = (RadixCiphertext::Cuda(inner_q), RadixCiphertext::Cuda(inner_r));
                                     (
@@ -513,6 +587,7 @@ macro_rules! generic_integer_impl_scalar_div_rem {
         )* // Closing first repeating pattern
     };
 }
+
 generic_integer_impl_scalar_div_rem!(
     fhe_and_scalar_type:
         (super::FheUint2, u8),
@@ -587,6 +662,14 @@ generic_integer_impl_scalar_operation!(
                         .scalar_add_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .scalar_add_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -622,12 +705,20 @@ generic_integer_impl_scalar_operation!(
     implem: {
         |lhs: &FheUint<_>, rhs| {
             global_state::with_internal_keys(|key| match key {
-                InternalServerKey::Cpu(cpu_key) => {
+                InternalServerKey::Cpu(cpu_key)=> {
                     let inner_result = cpu_key
                         .pbs_key()
                         .scalar_sub_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
-                },
+                }
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    // TODO: FPGA implementation
+                    let inner_result = fpga_key
+                        .pbs_key()
+                        .scalar_sub_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -669,6 +760,12 @@ generic_integer_impl_scalar_operation!(
                         .scalar_mul_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.scalar_mul(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -710,6 +807,12 @@ generic_integer_impl_scalar_operation!(
                         .scalar_bitand_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.scalar_bitand(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -751,6 +854,12 @@ generic_integer_impl_scalar_operation!(
                         .scalar_bitor_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.scalar_bitor(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -792,7 +901,12 @@ generic_integer_impl_scalar_operation!(
                         .scalar_bitxor_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
-
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.scalar_bitxor(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -834,6 +948,12 @@ generic_integer_impl_scalar_operation!(
                         .scalar_left_shift_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.scalar_left_shift(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -875,6 +995,12 @@ generic_integer_impl_scalar_operation!(
                         .scalar_right_shift_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.scalar_right_shift(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -916,6 +1042,12 @@ generic_integer_impl_scalar_operation!(
                         .scalar_rotate_left_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.scalar_rotate_left(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -957,6 +1089,12 @@ generic_integer_impl_scalar_operation!(
                         .scalar_rotate_right_parallelized(&*lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.scalar_rotate_right(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -998,6 +1136,12 @@ generic_integer_impl_scalar_operation!(
                         .scalar_div_parallelized(&lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.scalar_div(&*lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -1039,6 +1183,12 @@ generic_integer_impl_scalar_operation!(
                         .scalar_rem_parallelized(&lhs.ciphertext.on_cpu(), rhs);
                     RadixCiphertext::Cpu(inner_result)
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    let inner_result =
+                        fpga_key.scalar_rem(&lhs.ciphertext.on_cpu(), rhs);
+                    RadixCiphertext::Cpu(inner_result)
+                }
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     let inner_result = with_thread_local_cuda_streams(|streams| {
@@ -1201,6 +1351,17 @@ generic_integer_impl_scalar_left_operation!(
                         .sub_assign_parallelized(&mut result, &*rhs.ciphertext.on_cpu());
                     RadixCiphertext::Cpu(result)
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    // TODO: FPGA implementation
+                    let mut result = fpga_key
+                        .pbs_key()
+                        .create_trivial_radix(lhs, rhs.ciphertext.on_cpu().blocks().len());
+                    fpga_key
+                        .pbs_key()
+                        .sub_assign_parallelized(&mut result, &*rhs.ciphertext.on_cpu());
+                    RadixCiphertext::Cpu(result)
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1479,6 +1640,13 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_add_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    // TODO: FPGA implementation
+                    fpga_key
+                        .pbs_key()
+                        .scalar_add_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1539,6 +1707,13 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_sub_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    // TODO: FPGA implementation
+                    fpga_key
+                        .pbs_key()
+                        .scalar_sub_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1577,6 +1752,10 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_mul_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    fpga_key.scalar_mul_assign(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1615,6 +1794,10 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_bitand_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    fpga_key.scalar_bitand_assign(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1653,6 +1836,10 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_bitor_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    fpga_key.scalar_bitor_assign(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1691,6 +1878,10 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_bitxor_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    fpga_key.scalar_bitxor_assign(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1729,6 +1920,10 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_left_shift_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    fpga_key.scalar_left_shift_assign(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1767,6 +1962,10 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_right_shift_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    fpga_key.scalar_right_shift_assign(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1805,6 +2004,10 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_rotate_left_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    fpga_key.scalar_rotate_left_assign(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1843,6 +2046,10 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_rotate_right_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    fpga_key.scalar_rotate_right_assign(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(cuda_key) => {
                     with_thread_local_cuda_streams(|streams| {
@@ -1881,6 +2088,10 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_div_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    fpga_key.scalar_div_assign(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(_) => {
                     panic!("DivAssign '/=' with clear value is not yet supported by Cuda devices")
@@ -1916,6 +2127,10 @@ generic_integer_impl_scalar_operation_assign!(
                         .pbs_key()
                         .scalar_rem_assign_parallelized(lhs.ciphertext.as_cpu_mut(), rhs);
                 },
+                #[cfg(feature = "fpga")]
+InternalServerKey::Belfort(fpga_key) => {
+                    fpga_key.scalar_rem_assign(lhs.ciphertext.as_cpu_mut(), rhs);
+                },
                 #[cfg(feature = "gpu")]
                 InternalServerKey::Cuda(_) => {
                     panic!("RemAssign '%=' with clear value is not yet supported by Cuda devices")
diff --git a/tfhe/src/high_level_api/keys/mod.rs b/tfhe/src/high_level_api/keys/mod.rs
index c803b455..b4037ca9 100644
--- a/tfhe/src/high_level_api/keys/mod.rs
+++ b/tfhe/src/high_level_api/keys/mod.rs
@@ -2,7 +2,7 @@ mod client;
 mod public;
 mod server;
 
-mod inner;
+pub mod inner;
 mod key_switching_key;
 
 use crate::high_level_api::config::Config;
@@ -13,7 +13,7 @@ pub use public::{CompactPublicKey, CompressedCompactPublicKey, CompressedPublicK
 #[cfg(feature = "gpu")]
 pub use server::CudaServerKey;
 pub(crate) use server::InternalServerKey;
-pub use server::{CompressedServerKey, ServerKey};
+pub use server::{BelfortServerKey, CompressedServerKey, ServerKey};
 
 pub(in crate::high_level_api) use inner::{
     IntegerClientKey, IntegerCompactPublicKey, IntegerCompressedCompactPublicKey,
diff --git a/tfhe/src/high_level_api/keys/server.rs b/tfhe/src/high_level_api/keys/server.rs
index f5e54670..d4a1c8e1 100644
--- a/tfhe/src/high_level_api/keys/server.rs
+++ b/tfhe/src/high_level_api/keys/server.rs
@@ -131,6 +131,16 @@ impl Named for ServerKey {
     const NAME: &'static str = "high_level_api::ServerKey";
 }
 
+#[cfg(feature = "fpga")]
+impl From<&BelfortServerKey> for ServerKey {
+    fn from(fpga_key: &BelfortServerKey) -> ServerKey {
+        ServerKey {
+            key: fpga_key.key.clone(),
+            tag: fpga_key.tag.clone(),
+        }
+    }
+}
+
 impl AsRef<crate::integer::ServerKey> for ServerKey {
     fn as_ref(&self) -> &crate::integer::ServerKey {
         &self.key.key
@@ -342,10 +352,16 @@ impl Tagged for CudaServerKey {
     }
 }
 
+// Use BelfortServerKey from
+// #[cfg(feature = "fpga")]
+pub use crate::integer::fpga::BelfortServerKey;
+
 pub enum InternalServerKey {
     Cpu(ServerKey),
     #[cfg(feature = "gpu")]
     Cuda(CudaServerKey),
+    #[cfg(feature = "fpga")]
+    Belfort(BelfortServerKey),
 }
 
 impl From<ServerKey> for InternalServerKey {
@@ -353,6 +369,7 @@ impl From<ServerKey> for InternalServerKey {
         Self::Cpu(value)
     }
 }
+
 #[cfg(feature = "gpu")]
 impl From<CudaServerKey> for InternalServerKey {
     fn from(value: CudaServerKey) -> Self {
@@ -360,6 +377,13 @@ impl From<CudaServerKey> for InternalServerKey {
     }
 }
 
+#[cfg(feature = "fpga")]
+impl From<BelfortServerKey> for InternalServerKey {
+    fn from(value: BelfortServerKey) -> Self {
+        Self::Belfort(value)
+    }
+}
+
 use crate::high_level_api::keys::inner::IntegerServerKeyConformanceParams;
 
 impl ParameterSetConformant for ServerKey {
diff --git a/tfhe/src/high_level_api/mod.rs b/tfhe/src/high_level_api/mod.rs
index 4caf58e2..b7e28a3a 100644
--- a/tfhe/src/high_level_api/mod.rs
+++ b/tfhe/src/high_level_api/mod.rs
@@ -55,8 +55,8 @@ pub use integers::{CompressedFheInt, CompressedFheUint, FheInt, FheUint, Integer
 #[cfg(feature = "gpu")]
 pub use keys::CudaServerKey;
 pub use keys::{
-    generate_keys, ClientKey, CompactPublicKey, CompressedCompactPublicKey, CompressedPublicKey,
-    CompressedServerKey, KeySwitchingKey, PublicKey, ServerKey,
+    generate_keys, BelfortServerKey, ClientKey, CompactPublicKey, CompressedCompactPublicKey,
+    CompressedPublicKey, CompressedServerKey, KeySwitchingKey, PublicKey, ServerKey,
 };
 
 #[cfg(test)]
@@ -105,7 +105,7 @@ mod config;
 mod errors;
 mod global_state;
 mod integers;
-mod keys;
+pub mod keys;
 mod traits;
 mod utils;
 
@@ -126,6 +126,8 @@ pub enum Device {
     Cpu,
     #[cfg(feature = "gpu")]
     CudaGpu,
+    #[cfg(feature = "fpga")]
+    Fpga,
 }
 
 #[derive(Copy, Clone, PartialEq, Eq, Debug)]
diff --git a/tfhe/src/high_level_api/tests/tags_on_entities.rs b/tfhe/src/high_level_api/tests/tags_on_entities.rs
index 457df174..fe6fd177 100644
--- a/tfhe/src/high_level_api/tests/tags_on_entities.rs
+++ b/tfhe/src/high_level_api/tests/tags_on_entities.rs
@@ -4,6 +4,7 @@ use crate::shortint::parameters::key_switching::p_fail_2_minus_64::ks_pbs::PARAM
 use crate::shortint::parameters::list_compression::COMP_PARAM_MESSAGE_2_CARRY_2_KS_PBS_TUNIFORM_2M64;
 use crate::shortint::parameters::*;
 use crate::shortint::ClassicPBSParameters;
+use crate::BelfortServerKey;
 use crate::{
     set_server_key, ClientKey, CompactCiphertextList, CompactCiphertextListExpander,
     CompactPublicKey, CompressedCiphertextList, CompressedCiphertextListBuilder, CompressedFheBool,
@@ -202,6 +203,12 @@ fn test_tag_propagation(
 
             set_server_key(sks);
         }
+        #[cfg(feature = "fpga")]
+        Device::Fpga => {
+            let sks = ServerKey::new(&cks);
+            let fpga_key = BelfortServerKey::from(&sks);
+            assert_eq!(fpga_key.tag(), cks.tag());
+        }
     }
 
     // Check encrypting regular ct with client key
diff --git a/tfhe/src/integer/fpga/mod.rs b/tfhe/src/integer/fpga/mod.rs
new file mode 100644
index 00000000..9e69b178
--- /dev/null
+++ b/tfhe/src/integer/fpga/mod.rs
@@ -0,0 +1,2 @@
+pub mod server_key;
+pub use server_key::BelfortServerKey;
diff --git a/tfhe/src/integer/fpga/server_key/comparator.rs b/tfhe/src/integer/fpga/server_key/comparator.rs
new file mode 100644
index 00000000..ff387cb0
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/comparator.rs
@@ -0,0 +1,1111 @@
+use crate::core_crypto::algorithms::{
+    lwe_ciphertext_plaintext_sub_assign, lwe_ciphertext_sub_assign,
+};
+use crate::core_crypto::fpga::luts::{BelfortLookupTable, IS_EQUAL, IS_INFERIOR, IS_SUPERIOR};
+use crate::core_crypto::fpga::BelfortFpgaLuts;
+use crate::core_crypto::prelude::Plaintext;
+use crate::integer::block_decomposition::{BlockDecomposer, DecomposableInto};
+use crate::integer::ciphertext::boolean_value::BooleanBlock;
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::integer::server_key::comparator::*;
+use crate::shortint::{ciphertext::Degree, Ciphertext};
+
+/// Simple enum to select which comparison we are performing
+#[derive(PartialEq, Clone)]
+pub enum ComparisonSelector {
+    Gt,
+    Ge,
+    Lt,
+    Le,
+    None,
+}
+
+/// struct to compare integers
+///
+/// This struct keeps in memory the LUTs that are used
+/// during the comparisons and min/max algorithms
+pub struct Comparator<'a> {
+    pub(crate) server_key: &'a BelfortServerKey,
+    // name of the lut to get the sign of (a - b), used as the backbone of comparisons
+    sign_lut: &'a str,
+    // name of the lut used to reduce 2 comparison blocks into 1
+    comparison_reduction_lut: &'a str,
+    // names of the lookup tablse for the lhs/rhs operands in min/max operations
+    lhs_lut: &'a str,
+    rhs_lut: &'a str,
+}
+
+impl<'a> Comparator<'a> {
+    /// Creates a new Comparator for the given ServerKey
+    ///
+    /// # Panics
+    ///
+    /// panics if the message space + carry space is inferior to 4 bits
+    pub fn new(server_key: &'a BelfortServerKey) -> Self {
+        let shortint_server_key = &server_key.key.key;
+        assert!(
+            shortint_server_key.message_modulus().0 * shortint_server_key.carry_modulus().0 >= 16,
+            "At least 4 bits of space (message + carry) are required to be able to do comparisons"
+        );
+
+        let sign_lut = "is_non_zero";
+        let comparison_reduction_lut = "reduce_two_orderings";
+        let lhs_lut = "lhs_min_max";
+        let rhs_lut = "rhs_min_max";
+
+        Self {
+            server_key,
+            sign_lut,
+            comparison_reduction_lut,
+            lhs_lut,
+            rhs_lut,
+        }
+    }
+
+    /// Takes 2 ciphertexts and packs them together assigning to high
+    ///
+    /// This requires the block parameters to have enough room for two ciphertexts,
+    /// so at least as many carry modulus as the message modulus
+    ///
+    /// Expects the carry buffer to be empty
+    fn pack_block_assign(&self, low: &Ciphertext, high: &mut Ciphertext) {
+        self.server_key.key.key.pack_block_assign(low, high);
+    }
+
+    /// This function compares two blocks
+    /// of two signed radix ciphertext which hold the 'sign' bit
+    /// (so the two most significant blocks).
+    ///
+    /// As for the blocks which holds the sign bit, the comparison
+    /// is different than for regular blocks.
+    fn compare_blocks_with_sign_bit(
+        &self,
+        lhs_block: &Ciphertext,
+        rhs_block: &Ciphertext,
+    ) -> Ciphertext {
+        let mut result = lhs_block.clone();
+
+        self.pack_block_assign(rhs_block, &mut result);
+
+        let mut result_vec = vec![result];
+
+        self.server_key
+            .apply_same_lookup_table_packed_assign(&mut result_vec, "compare_with_sign_bits");
+
+        result_vec[0].clone()
+    }
+
+    /// Takes a chunk of 2 ciphertexts and packs them together in a new ciphertext
+    ///
+    /// The first element of the chunk are the low bits, the second are the high bits
+    ///
+    /// This requires the block parameters to have enough room for two ciphertexts,
+    /// so at least as many carry modulus as the message modulus
+    ///
+    /// Expects the carry buffer to be empty
+    fn pack_block_chunk(&self, chunk: &[Ciphertext]) -> Ciphertext {
+        self.server_key.key.key.pack_block_chunk(chunk)
+    }
+
+    /// lhs will be assigned
+    /// - 0 if lhs < rhs
+    /// - 1 if lhs == rhs
+    /// - 2 if lhs > rhs
+    fn compare_blocks_pack(&self, lhs: &[Ciphertext], rhs: &[Ciphertext]) -> Vec<Ciphertext> {
+        let lhs_chunks_iter = lhs.chunks_exact(2);
+        let rhs_chunks_iter = rhs.chunks_exact(2);
+
+        let mut lhs_chunks: Vec<Ciphertext> = lhs
+            .chunks_exact(2)
+            .map(|chunk| self.pack_block_chunk(chunk))
+            .collect();
+
+        let mut rhs_chunks: Vec<Ciphertext> = rhs
+            .chunks_exact(2)
+            .map(|chunk: &[Ciphertext]| self.pack_block_chunk(chunk))
+            .collect();
+
+        // If there are remaining blocks, append them to the concatenated vectors
+        if let ([last_lhs_block], [last_rhs_block]) =
+            (lhs_chunks_iter.remainder(), rhs_chunks_iter.remainder())
+        {
+            lhs_chunks.push(last_lhs_block.clone());
+            rhs_chunks.push(last_rhs_block.clone());
+        };
+
+        // When rhs > lhs, the subtraction will overflow, and the bit of padding will be set to 1
+        // meaning that the output of the pbs will be the negative (modulo message space)
+        //
+        // Example:
+        // lhs: 1, rhs: 3, message modulus: 4, carry modulus 4
+        // lhs - rhs = -2 % (4 * 4) = 14 = 1|1110 (padding_bit|b4b3b2b1)
+        // Since there was an overflow the bit of padding is 1 and not 0.
+        // When applying the LUT for an input value of 14 we would expect 1,
+        // but since the bit of padding is 1, we will get -1 modulus our message space,
+        // so (-1) % (4 * 4) = 15 = 1|1111
+        // We then add one and get 0 = 0|0000
+
+        // Here we need the true lwe sub, not the one that comes from shortint.
+        lhs_chunks
+            .iter_mut()
+            .zip(rhs_chunks.iter())
+            .for_each(|(lhs_block, rhs_block)| {
+                lwe_ciphertext_sub_assign(&mut lhs_block.ct, &rhs_block.ct);
+                lhs_block.set_noise_level(lhs_block.noise_level() + rhs_block.noise_level());
+            });
+
+        self.server_key
+            .apply_same_lookup_table_packed_assign(&mut lhs_chunks, self.sign_lut);
+
+        // Here Lhs can have the following values: (-1) % (message modulus * carry modulus), 0, 1
+        // So the output values after the addition will be: 0, 1, 2
+        lhs_chunks
+            .iter_mut()
+            .for_each(|lhs_block: &mut Ciphertext| {
+                self.server_key
+                    .key
+                    .key
+                    .key
+                    .unchecked_scalar_add_assign(lhs_block, 1);
+            });
+
+        lhs_chunks
+    }
+
+    /// Reduces a vec containing shortint blocks that encrypts a sign
+    /// (inferior, equal, superior) to one single shortint block containing the
+    /// final sign
+    fn reduce_signs_pack(
+        &self,
+        mut sign_blocks: Vec<Ciphertext>,
+        selector: ComparisonSelector,
+    ) -> Ciphertext {
+        while sign_blocks.len() > 2 {
+            let mut sign_blocks_packed: Vec<Ciphertext> = sign_blocks
+                .chunks_exact(2)
+                .map(|chunk: &[Ciphertext]| self.pack_block_chunk(chunk))
+                .collect();
+
+            self.server_key.apply_same_lookup_table_packed_assign(
+                &mut sign_blocks_packed,
+                &self.comparison_reduction_lut,
+            );
+
+            if (sign_blocks.len() % 2) == 1 {
+                sign_blocks_packed.push(sign_blocks.last().unwrap().clone());
+            }
+
+            sign_blocks.clear();
+            sign_blocks.extend(sign_blocks_packed);
+        }
+
+        let final_lut_name: &str;
+        let mut result: Ciphertext;
+        if sign_blocks.len() == 2 {
+            final_lut_name = match selector {
+                ComparisonSelector::Gt => "gt_two_blocks",
+                ComparisonSelector::Ge => "ge_two_blocks",
+                ComparisonSelector::Lt => "lt_two_blocks",
+                ComparisonSelector::Le => "le_two_blocks",
+                ComparisonSelector::None => "general_two_blocks",
+            };
+
+            result = sign_blocks[1].clone();
+            self.pack_block_assign(&sign_blocks[0], &mut result);
+        } else {
+            final_lut_name = match selector {
+                ComparisonSelector::Gt => "gt_one_block",
+                ComparisonSelector::Ge => "ge_one_block",
+                ComparisonSelector::Lt => "lt_one_block",
+                ComparisonSelector::Le => "le_one_block",
+                ComparisonSelector::None => "general_one_block",
+            };
+
+            result = sign_blocks[0].clone();
+        };
+
+        let mut result_vec = vec![result];
+
+        self.server_key
+            .apply_same_lookup_table_packed_assign(&mut result_vec, final_lut_name);
+
+        result_vec[0].clone()
+    }
+
+    /// Reduces a vec containing shortint blocks that encrypts a sign
+    /// (inferior, equal, superior) to one single shortint block containing the
+    /// final sign based on min/max luts    
+    fn reduce_signs_for_min_max_pack(&self, mut sign_blocks: Vec<Ciphertext>) -> Ciphertext {
+        while sign_blocks.len() > 2 {
+            let mut sign_blocks_packed: Vec<Ciphertext> = sign_blocks
+                .chunks_exact(2)
+                .map(|chunk: &[Ciphertext]| self.pack_block_chunk(chunk))
+                .collect();
+
+            self.server_key.apply_same_lookup_table_packed_assign(
+                &mut sign_blocks_packed,
+                &self.comparison_reduction_lut,
+            );
+
+            if (sign_blocks.len() % 2) == 1 {
+                sign_blocks_packed.push(sign_blocks.last().unwrap().clone());
+            }
+
+            sign_blocks.clear();
+            sign_blocks.extend(sign_blocks_packed);
+        }
+
+        let final_lut_name: &str;
+        let mut result: Ciphertext;
+        if sign_blocks.len() == 2 {
+            final_lut_name = "two_blocks_min_max";
+            result = sign_blocks[1].clone();
+        } else {
+            final_lut_name = "one_block_min_max";
+            result = sign_blocks[0].clone();
+        };
+
+        self.pack_block_assign(&sign_blocks[0], &mut result);
+
+        let mut result_vec = vec![result];
+
+        self.server_key
+            .apply_same_lookup_table_packed_assign(&mut result_vec, final_lut_name);
+
+        result_vec[0].clone()
+    }
+
+    /// returns:
+    ///
+    /// - 0 if lhs < rhs
+    /// - 1 if lhs == rhs
+    /// - 2 if lhs > rhs
+    ///
+    /// Expects the carry buffers to be empty
+    ///
+    /// Requires that the RadixCiphertext block have 4 bits minimum (carry + message)    
+    fn unchecked_compare<T>(&self, lhs: &T, rhs: &T, selector: ComparisonSelector) -> Ciphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        assert_eq!(lhs.blocks().len(), rhs.blocks().len());
+
+        let comparisons = if T::IS_SIGNED {
+            let (lhs_last_block, lhs_ls_blocks) = lhs.blocks().split_last().unwrap();
+            let (rhs_last_block, rhs_ls_blocks) = rhs.blocks().split_last().unwrap();
+
+            let mut tmp_comparisons = self.compare_blocks_pack(&lhs_ls_blocks, &rhs_ls_blocks);
+
+            let last_block_cmp = self.compare_blocks_with_sign_bit(lhs_last_block, rhs_last_block);
+
+            tmp_comparisons.push(last_block_cmp);
+
+            tmp_comparisons
+        } else {
+            self.compare_blocks_pack(&lhs.blocks(), &rhs.blocks())
+        };
+
+        self.reduce_signs_pack(comparisons, selector)
+    }
+
+    fn smart_compare<T>(&self, lhs: &mut T, rhs: &mut T, selector: ComparisonSelector) -> Ciphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.server_key
+            .conditional_full_propagate_bivariate(lhs, rhs);
+
+        self.unchecked_compare(lhs, rhs, selector)
+    }
+
+    /// Expects the carry buffers to be empty
+    fn unchecked_compare_for_min_max<T>(&self, lhs: &T, rhs: &T) -> Ciphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        assert_eq!(lhs.blocks().len(), rhs.blocks().len());
+
+        let comparisons = if T::IS_SIGNED {
+            let (lhs_last_block, lhs_ls_blocks) = lhs.blocks().split_last().unwrap();
+            let (rhs_last_block, rhs_ls_blocks) = rhs.blocks().split_last().unwrap();
+
+            let mut tmp_comparisons = self.compare_blocks_pack(&lhs_ls_blocks, &rhs_ls_blocks);
+
+            let last_block_cmp = self.compare_blocks_with_sign_bit(lhs_last_block, rhs_last_block);
+
+            tmp_comparisons.push(last_block_cmp);
+
+            tmp_comparisons
+        } else {
+            self.compare_blocks_pack(&lhs.blocks(), &rhs.blocks())
+        };
+
+        self.reduce_signs_for_min_max_pack(comparisons)
+    }
+
+    /// Expects the carry buffers to be empty
+    fn unchecked_min_or_max<T>(&self, lhs: &T, rhs: &T, selector: MinMaxSelector) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let (lhs_lut, rhs_lut) = match selector {
+            MinMaxSelector::Max => (self.lhs_lut, self.rhs_lut),
+            MinMaxSelector::Min => (self.rhs_lut, self.lhs_lut),
+        };
+
+        let offset = self.unchecked_compare_for_min_max(lhs, rhs);
+        let shortint_server_key = &self.server_key.key.key.key;
+
+        let lhs_blocks: Vec<Ciphertext> = lhs
+            .blocks()
+            .iter()
+            .map(|block| shortint_server_key.unchecked_add(block, &offset))
+            .collect();
+
+        let rhs_blocks: Vec<Ciphertext> = rhs
+            .blocks()
+            .iter()
+            .map(|block| shortint_server_key.unchecked_add(block, &offset))
+            .collect();
+
+        let mut lhs_rhs_blocks: Vec<Ciphertext> = lhs_blocks
+            .iter()
+            .chain(rhs_blocks.iter())
+            .cloned()
+            .collect();
+
+        let lhs_lut = BelfortFpgaLuts::lut_by_name(lhs_lut, shortint_server_key);
+        let rhs_lut = BelfortFpgaLuts::lut_by_name(rhs_lut, shortint_server_key);
+
+        let mut luts: Vec<BelfortLookupTable> = vec![lhs_lut; lhs_blocks.len()];
+        luts.append(&mut vec![rhs_lut; rhs_blocks.len()]);
+
+        self.server_key
+            .apply_lookup_table_packed_assign(&mut lhs_rhs_blocks, &luts);
+
+        let (lhs_blocks, rhs_blocks) = lhs_rhs_blocks.split_at(lhs.blocks().len());
+
+        let result = lhs_blocks
+            .iter()
+            .zip(rhs_blocks.iter())
+            .map(|(lhs_block, rhs_block)| {
+                let mut result = shortint_server_key.unchecked_add(&lhs_block, &rhs_block);
+                // We know that one of either blocks is 0
+                result.degree = Degree::new(shortint_server_key.message_modulus.0 - 1);
+                result
+            })
+            .collect();
+
+        T::from_blocks(result)
+    }
+
+    fn smart_min_or_max<T>(&self, lhs: &mut T, rhs: &mut T, selector: MinMaxSelector) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.server_key
+            .conditional_full_propagate_bivariate(lhs, rhs);
+        self.unchecked_min_or_max(lhs, rhs, selector)
+    }
+
+    //======================================
+    // Unchecked operations
+    //======================================
+
+    pub fn unchecked_gt<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let comparison = self.unchecked_compare(lhs, rhs, ComparisonSelector::Gt);
+        BooleanBlock::new_unchecked(comparison)
+    }
+
+    pub fn unchecked_ge<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let comparison = self.unchecked_compare(lhs, rhs, ComparisonSelector::Ge);
+        BooleanBlock::new_unchecked(comparison)
+    }
+
+    pub fn unchecked_lt<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let comparison = self.unchecked_compare(lhs, rhs, ComparisonSelector::Lt);
+        BooleanBlock::new_unchecked(comparison)
+    }
+
+    pub fn unchecked_le<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let comparison = self.unchecked_compare(lhs, rhs, ComparisonSelector::Le);
+        BooleanBlock::new_unchecked(comparison)
+    }
+
+    pub fn unchecked_max<T>(&self, lhs: &T, rhs: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.unchecked_min_or_max(lhs, rhs, MinMaxSelector::Max)
+    }
+
+    pub fn unchecked_min<T>(&self, lhs: &T, rhs: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.unchecked_min_or_max(lhs, rhs, MinMaxSelector::Min)
+    }
+
+    //======================================
+    // Smart operations
+    //======================================
+
+    pub fn smart_gt<T>(&self, lhs: &mut T, rhs: &mut T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let comparison = self.smart_compare(lhs, rhs, ComparisonSelector::Gt);
+        BooleanBlock::new_unchecked(comparison)
+    }
+
+    pub fn smart_ge<T>(&self, lhs: &mut T, rhs: &mut T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let comparison = self.smart_compare(lhs, rhs, ComparisonSelector::Ge);
+        BooleanBlock::new_unchecked(comparison)
+    }
+
+    pub fn smart_lt<T>(&self, lhs: &mut T, rhs: &mut T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let comparison = self.smart_compare(lhs, rhs, ComparisonSelector::Lt);
+        BooleanBlock::new_unchecked(comparison)
+    }
+
+    pub fn smart_le<T>(&self, lhs: &mut T, rhs: &mut T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let comparison = self.smart_compare(lhs, rhs, ComparisonSelector::Le);
+        BooleanBlock::new_unchecked(comparison)
+    }
+
+    pub fn smart_max<T>(&self, lhs: &mut T, rhs: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.smart_min_or_max(lhs, rhs, MinMaxSelector::Max)
+    }
+
+    pub fn smart_min<T>(&self, lhs: &mut T, rhs: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.smart_min_or_max(lhs, rhs, MinMaxSelector::Min)
+    }
+
+    //======================================
+    // Default operations
+    //======================================
+
+    pub fn gt<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_lhs;
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (lhs.block_carries_are_empty(), rhs.block_carries_are_empty()) {
+            (true, true) => (lhs, rhs),
+            (true, false) => {
+                tmp_rhs = rhs.clone();
+                self.server_key.full_propagate(&mut tmp_rhs);
+                (lhs, &tmp_rhs)
+            }
+            (false, true) => {
+                tmp_lhs = lhs.clone();
+                self.server_key.full_propagate(&mut tmp_lhs);
+                (&tmp_lhs, rhs)
+            }
+            (false, false) => {
+                tmp_lhs = lhs.clone();
+                tmp_rhs = rhs.clone();
+
+                self.server_key.full_propagate(&mut tmp_lhs);
+                self.server_key.full_propagate(&mut tmp_rhs);
+
+                (&tmp_lhs, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_gt(lhs, rhs)
+    }
+
+    pub fn ge<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_lhs;
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (lhs.block_carries_are_empty(), rhs.block_carries_are_empty()) {
+            (true, true) => (lhs, rhs),
+            (true, false) => {
+                tmp_rhs = rhs.clone();
+                self.server_key.full_propagate(&mut tmp_rhs);
+                (lhs, &tmp_rhs)
+            }
+            (false, true) => {
+                tmp_lhs = lhs.clone();
+                self.server_key.full_propagate(&mut tmp_lhs);
+                (&tmp_lhs, rhs)
+            }
+            (false, false) => {
+                tmp_lhs = lhs.clone();
+                tmp_rhs = rhs.clone();
+
+                self.server_key.full_propagate(&mut tmp_lhs);
+                self.server_key.full_propagate(&mut tmp_rhs);
+
+                (&tmp_lhs, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_ge(lhs, rhs)
+    }
+
+    pub fn lt<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_lhs;
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (lhs.block_carries_are_empty(), rhs.block_carries_are_empty()) {
+            (true, true) => (lhs, rhs),
+            (true, false) => {
+                tmp_rhs = rhs.clone();
+                self.server_key.full_propagate(&mut tmp_rhs);
+                (lhs, &tmp_rhs)
+            }
+            (false, true) => {
+                tmp_lhs = lhs.clone();
+                self.server_key.full_propagate(&mut tmp_lhs);
+                (&tmp_lhs, rhs)
+            }
+            (false, false) => {
+                tmp_lhs = lhs.clone();
+                tmp_rhs = rhs.clone();
+
+                self.server_key.full_propagate(&mut tmp_lhs);
+                self.server_key.full_propagate(&mut tmp_rhs);
+
+                (&tmp_lhs, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_lt(lhs, rhs)
+    }
+
+    pub fn le<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_lhs;
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (lhs.block_carries_are_empty(), rhs.block_carries_are_empty()) {
+            (true, true) => (lhs, rhs),
+            (true, false) => {
+                tmp_rhs = rhs.clone();
+                self.server_key.full_propagate(&mut tmp_rhs);
+                (lhs, &tmp_rhs)
+            }
+            (false, true) => {
+                tmp_lhs = lhs.clone();
+                self.server_key.full_propagate(&mut tmp_lhs);
+                (&tmp_lhs, rhs)
+            }
+            (false, false) => {
+                tmp_lhs = lhs.clone();
+                tmp_rhs = rhs.clone();
+
+                self.server_key.full_propagate(&mut tmp_lhs);
+                self.server_key.full_propagate(&mut tmp_rhs);
+
+                (&tmp_lhs, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_le(lhs, rhs)
+    }
+
+    pub fn max<T>(&self, lhs: &T, rhs: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_lhs;
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (lhs.block_carries_are_empty(), rhs.block_carries_are_empty()) {
+            (true, true) => (lhs, rhs),
+            (true, false) => {
+                tmp_rhs = rhs.clone();
+                self.server_key.full_propagate(&mut tmp_rhs);
+                (lhs, &tmp_rhs)
+            }
+            (false, true) => {
+                tmp_lhs = lhs.clone();
+                self.server_key.full_propagate(&mut tmp_lhs);
+                (&tmp_lhs, rhs)
+            }
+            (false, false) => {
+                tmp_lhs = lhs.clone();
+                tmp_rhs = rhs.clone();
+
+                self.server_key.full_propagate(&mut tmp_lhs);
+                self.server_key.full_propagate(&mut tmp_rhs);
+
+                (&tmp_lhs, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_max(lhs, rhs)
+    }
+
+    pub fn min<T>(&self, lhs: &T, rhs: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_lhs;
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (lhs.block_carries_are_empty(), rhs.block_carries_are_empty()) {
+            (true, true) => (lhs, rhs),
+            (true, false) => {
+                tmp_rhs = rhs.clone();
+                self.server_key.full_propagate(&mut tmp_rhs);
+                (lhs, &tmp_rhs)
+            }
+            (false, true) => {
+                tmp_lhs = lhs.clone();
+                self.server_key.full_propagate(&mut tmp_lhs);
+                (&tmp_lhs, rhs)
+            }
+            (false, false) => {
+                tmp_lhs = lhs.clone();
+                tmp_rhs = rhs.clone();
+
+                self.server_key.full_propagate(&mut tmp_lhs);
+                self.server_key.full_propagate(&mut tmp_rhs);
+
+                (&tmp_lhs, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_min(lhs, rhs)
+    }
+
+    //======================================
+    // Unchecked operations
+    //======================================
+    pub fn unchecked_scalar_gt<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.unchecked_scalar_compare_handler(lhs, rhs, ComparisonSelector::Gt, |x| {
+            u64::from(x == IS_SUPERIOR)
+        })
+    }
+
+    pub fn unchecked_scalar_ge<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.unchecked_scalar_compare_handler(lhs, rhs, ComparisonSelector::Ge, |x| {
+            u64::from(x == IS_SUPERIOR || x == IS_EQUAL)
+        })
+    }
+
+    pub fn unchecked_scalar_lt<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.unchecked_scalar_compare_handler(lhs, rhs, ComparisonSelector::Lt, |x| {
+            u64::from(x == IS_INFERIOR)
+        })
+    }
+
+    pub fn unchecked_scalar_le<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.unchecked_scalar_compare_handler(lhs, rhs, ComparisonSelector::Le, |x| {
+            u64::from(x == IS_SUPERIOR || x == IS_EQUAL)
+        })
+    }
+
+    pub fn scalar_gt<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.default_scalar_compare_parallelized(lhs, rhs, ComparisonSelector::Gt, |x| {
+            u64::from(x == IS_SUPERIOR)
+        })
+    }
+
+    pub fn scalar_ge<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.default_scalar_compare_parallelized(lhs, rhs, ComparisonSelector::Ge, |x| {
+            u64::from(x == IS_SUPERIOR || x == IS_EQUAL)
+        })
+    }
+
+    pub fn scalar_lt<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.default_scalar_compare_parallelized(lhs, rhs, ComparisonSelector::Lt, |x| {
+            u64::from(x == IS_INFERIOR)
+        })
+    }
+
+    pub fn scalar_le<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.default_scalar_compare_parallelized(lhs, rhs, ComparisonSelector::Le, |x| {
+            u64::from(x == IS_INFERIOR || x == IS_EQUAL)
+        })
+    }
+
+    pub fn unchecked_scalar_compare_handler<T, Scalar, F>(
+        &self,
+        lhs: &T,
+        rhs: Scalar,
+        selector: ComparisonSelector,
+        sign_result_handler_fn: F,
+    ) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+        F: Fn(u64) -> u64 + Sync,
+    {
+        let comparison = self.unchecked_scalar_compare(lhs, rhs, selector, sign_result_handler_fn);
+        BooleanBlock::new_unchecked(comparison)
+    }
+    fn default_scalar_compare_parallelized<T, Scalar, F>(
+        &self,
+        lhs: &T,
+        rhs: Scalar,
+        selector: ComparisonSelector,
+        sign_result_handler_fn: F,
+    ) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+        F: Fn(u64) -> u64 + Sync,
+    {
+        let mut tmp_lhs;
+        let lhs = if lhs.block_carries_are_empty() {
+            lhs
+        } else {
+            tmp_lhs = lhs.clone();
+            self.server_key.full_propagate(&mut tmp_lhs);
+            &tmp_lhs
+        };
+        self.unchecked_scalar_compare_handler(lhs, rhs, selector, sign_result_handler_fn)
+    }
+    fn unchecked_scalar_compare<T, Scalar, F>(
+        &self,
+        lhs: &T,
+        rhs: Scalar,
+        selector: ComparisonSelector,
+        sign_result_handler_fn: F,
+    ) -> Ciphertext
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+        F: Fn(u64) -> u64 + Sync,
+    {
+        // TODO: change this for signed integers,
+        // Look up radix_parallel/scalar_comparison.rs
+        self.unsigned_unchecked_scalar_compare_blocks(
+            lhs.blocks(),
+            rhs,
+            selector,
+            sign_result_handler_fn,
+        )
+    }
+
+    fn unsigned_unchecked_scalar_compare_blocks<Scalar, F>(
+        &self,
+        lhs_blocks: &[Ciphertext],
+        rhs: Scalar,
+        selector: ComparisonSelector,
+        sign_result_handler_fn: F,
+    ) -> Ciphertext
+    where
+        Scalar: DecomposableInto<u64>,
+        F: Fn(u64) -> u64 + Sync,
+    {
+        assert!(!lhs_blocks.is_empty());
+        let shortint_key = &self.server_key.key.key.key;
+        if rhs < Scalar::ZERO {
+            // lhs_blocks represent an unsigned (always >= 0)
+            return shortint_key.create_trivial(sign_result_handler_fn(IS_SUPERIOR));
+        }
+
+        let message_modulus = shortint_key.message_modulus.0;
+
+        let mut scalar_blocks =
+            BlockDecomposer::with_early_stop_at_zero(rhs, message_modulus.ilog2())
+                .iter_as::<u64>()
+                .map(|x| x as u8)
+                .collect::<Vec<_>>();
+
+        // scalar is obviously bigger if it has non-zero
+        // blocks  after lhs's last block
+        let is_scalar_obviously_bigger = scalar_blocks
+            .get(lhs_blocks.len()..)
+            .is_some_and(|sub_slice| sub_slice.iter().any(|&scalar_block| scalar_block != 0));
+        if is_scalar_obviously_bigger {
+            return shortint_key.create_trivial(sign_result_handler_fn(IS_INFERIOR));
+        }
+        // If we are sill here, that means scalar_blocks above
+        // num_blocks are 0s, we can remove them
+        // as we will handle them separately.
+        scalar_blocks.truncate(lhs_blocks.len());
+
+        let (least_significant_blocks, most_significant_blocks) =
+            lhs_blocks.split_at(scalar_blocks.len());
+
+        // Reducing the signs is the bottleneck of the comparison algorithms,
+        // however if the scalar case there is an improvement:
+        //
+        // The idea is to reduce the number of signs block we have to
+        // reduce. We can do that by splitting the comparison problem in two parts.
+        //
+        // - One part where we compute the signs block between the scalar with just enough blocks
+        //   from the ciphertext that can represent the scalar value
+        //
+        // - The other part is to compare the ciphertext blocks not considered for the sign
+        //   computation with zero, and create a single sign block from that.
+        //
+        // The smaller the scalar value is compared to the ciphertext num bits encrypted,
+        // the more the comparisons with zeros we have to do,
+        // and the less signs block we will have to reduce.
+        //
+        // This will create a speedup as comparing a bunch of blocks with 0
+        // is faster
+
+        match (
+            least_significant_blocks.is_empty(),
+            most_significant_blocks.is_empty(),
+        ) {
+            (false, false) => {
+                // We have to handle both part of the work described above
+
+                let (lsb_sign, are_all_msb_equal_to_zero) = (
+                    {
+                        let lsb_signs = self.unchecked_scalar_block_slice_compare_parallelized(
+                            least_significant_blocks,
+                            &scalar_blocks,
+                        );
+
+                        self.reduce_signs_pack(lsb_signs, ComparisonSelector::None)
+                    },
+                    self.server_key.are_all_blocks_zero(most_significant_blocks),
+                );
+
+                // Reduce the two blocks into one final
+                let lut_func = shortint_key.generate_lookup_table_bivariate(|lsb, msb| {
+                    let msb = if msb == 1 { IS_EQUAL } else { IS_SUPERIOR };
+
+                    let x = (msb << 2) + lsb;
+
+                    let m = (x >> 2) & 3;
+                    let l = x & 3;
+
+                    let final_sign = if m == IS_EQUAL { l } else { m };
+
+                    sign_result_handler_fn(final_sign)
+                });
+
+                let lut_name = match selector {
+                    ComparisonSelector::Gt => "two_blocks_gt_scalar",
+                    ComparisonSelector::Ge => "two_blocks_ge_scalar",
+                    ComparisonSelector::Lt => "two_blocks_lt_scalar",
+                    ComparisonSelector::Le => "two_blocks_le_scalar",
+                    ComparisonSelector::None => "two_blocks_scalar_general",
+                };
+                let lut = BelfortFpgaLuts::lut_by_name(lut_name, shortint_key);
+                let mut prepared_blocks = self.server_key.prepare_bivariate(
+                    &mut vec![lsb_sign],
+                    &vec![are_all_msb_equal_to_zero],
+                    &lut_func,
+                );
+
+                self.server_key
+                    .apply_lookup_table_packed_assign(&mut prepared_blocks, &vec![lut]);
+
+                prepared_blocks[0].clone()
+            }
+            (false, true) => {
+                // We only have to do the regular comparison
+                // And not the part where we compare most significant blocks with zeros
+
+                let signs = self.unchecked_scalar_block_slice_compare_parallelized(
+                    least_significant_blocks,
+                    &scalar_blocks,
+                );
+
+                self.reduce_signs_pack(signs, selector)
+            }
+            (true, false) => {
+                // We only have to compare blocks with zero
+                // means scalar is zero
+                let are_all_msb_equal_to_zero =
+                    self.server_key.are_all_blocks_zero(most_significant_blocks);
+
+                let lut_name = match selector {
+                    ComparisonSelector::Gt => "two_blocks_gt_scalar",
+                    ComparisonSelector::Ge => "two_blocks_ge_scalar",
+                    ComparisonSelector::Lt => "two_blocks_lt_scalar",
+                    ComparisonSelector::Le => "two_blocks_le_scalar",
+                    ComparisonSelector::None => "two_blocks_scalar_general",
+                };
+                let lut = BelfortFpgaLuts::lut_by_name(lut_name, shortint_key);
+
+                let mut blocks = vec![are_all_msb_equal_to_zero];
+                self.server_key
+                    .apply_lookup_table_packed_assign(&mut blocks, &vec![lut]);
+
+                blocks[0].clone()
+            }
+            (true, true) => {
+                // assert should have  been hit earlier
+                unreachable!("Empty input ciphertext")
+            }
+        }
+    }
+
+    fn unchecked_scalar_block_slice_compare_parallelized(
+        &self,
+        lhs_blocks: &[Ciphertext],
+        scalar_blocks: &[u8],
+    ) -> Vec<Ciphertext> {
+        assert_eq!(lhs_blocks.len(), scalar_blocks.len());
+        let num_blocks = lhs_blocks.len();
+        let num_blocks_halved = (num_blocks / 2) + (num_blocks % 2);
+
+        let shortint_key = &self.server_key.key.key.key;
+        let message_modulus = shortint_key.message_modulus.0;
+
+        let mut signs: Vec<_> = lhs_blocks
+            .chunks(2)
+            .zip(scalar_blocks.chunks(2))
+            .map(|(lhs_chunk, scalar_chunk)| {
+                let packed_scalar = scalar_chunk[0]
+                    + (scalar_chunk.get(1).copied().unwrap_or(0) * message_modulus as u8);
+                let mut packed_lhs = self.pack_block_chunk(lhs_chunk);
+
+                let delta = (1u64 << (u64::BITS as u64 - 1))
+                    / (packed_lhs.carry_modulus.0 * packed_lhs.message_modulus.0) as u64;
+                let plaintext = Plaintext((packed_scalar as u64) * delta);
+
+                lwe_ciphertext_plaintext_sub_assign(&mut packed_lhs.ct, plaintext);
+                packed_lhs
+            })
+            .collect();
+
+        let lut = BelfortFpgaLuts::lut_by_name(self.sign_lut, shortint_key);
+
+        self.server_key
+            .apply_lookup_table_packed_assign(&mut signs, &vec![lut; num_blocks_halved]);
+        signs.iter_mut().for_each(|signs_block| {
+            shortint_key.unchecked_scalar_add_assign(signs_block, 1);
+        });
+
+        signs
+    }
+
+    pub fn scalar_max<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        let mut tmp_lhs;
+        let lhs = if lhs.block_carries_are_empty() {
+            lhs
+        } else {
+            tmp_lhs = lhs.clone();
+            self.server_key.full_propagate(&mut tmp_lhs);
+            &tmp_lhs
+        };
+        self.unchecked_scalar_min_or_max(lhs, rhs, MinMaxSelector::Max)
+    }
+
+    pub fn scalar_min<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        let mut tmp_lhs;
+        let lhs = if lhs.block_carries_are_empty() {
+            lhs
+        } else {
+            tmp_lhs = lhs.clone();
+            self.server_key.full_propagate(&mut tmp_lhs);
+            &tmp_lhs
+        };
+        self.unchecked_scalar_min_or_max(lhs, rhs, MinMaxSelector::Min)
+    }
+
+    pub fn unchecked_scalar_min_or_max<T, Scalar>(
+        &self,
+        lhs: &T,
+        rhs: Scalar,
+        selector: MinMaxSelector,
+    ) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        let return_lhs = match selector {
+            MinMaxSelector::Max => self.unchecked_scalar_gt(lhs, rhs),
+            MinMaxSelector::Min => self.unchecked_scalar_le(lhs, rhs),
+        };
+
+        let rhs = self
+            .server_key
+            .key
+            .key
+            .create_trivial_radix(rhs, lhs.blocks().len());
+
+        let do_clean_message = true;
+        self.server_key.unchecked_programmable_if_then_else(
+            &return_lhs.0,
+            lhs,
+            &rhs,
+            |x| x == 1,
+            String::from("predicate"),
+            do_clean_message,
+        )
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/mod.rs b/tfhe/src/integer/fpga/server_key/mod.rs
new file mode 100644
index 00000000..140c1ce4
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/mod.rs
@@ -0,0 +1,661 @@
+mod comparator;
+mod radix;
+
+use std::sync::Arc;
+
+use crate::core_crypto::fpga::keyswitch_bootstrap::KeyswitchBootstrapPacked;
+
+use crate::core_crypto::fpga::luts::BelfortLookupTable;
+use crate::core_crypto::fpga::{BelfortFpgaLuts, BelfortFpgaUtils};
+use crate::high_level_api::keys::inner::IntegerServerKey;
+use crate::high_level_api::keys::ServerKey;
+use crate::high_level_api::Tag;
+use crate::integer::IntegerRadixCiphertext;
+use crate::shortint::Ciphertext;
+
+use crate::core_crypto::commons::numeric::UnsignedInteger;
+use crate::core_crypto::fpga::luts::OutputCarry;
+use crate::shortint::parameters::Degree;
+use crate::shortint::server_key::BivariateLookupTableOwned;
+
+use rayon::iter::*;
+
+#[derive(Clone)]
+pub struct BelfortServerKey {
+    pub key: Arc<IntegerServerKey>,
+    pub fpga_utils: BelfortFpgaUtils,
+    pub tag: Tag,
+}
+
+impl From<&ServerKey> for BelfortServerKey {
+    fn from(value: &ServerKey) -> Self {
+        let ServerKey { key, tag } = value.clone();
+        BelfortServerKey::default(key, tag)
+    }
+}
+
+impl From<&IntegerServerKey> for BelfortServerKey {
+    fn from(value: &IntegerServerKey) -> Self {
+        BelfortServerKey::default(Arc::new(value.clone()), Tag::default())
+    }
+}
+
+impl From<&crate::integer::ServerKey> for BelfortServerKey {
+    fn from(value: &crate::integer::ServerKey) -> Self {
+        let integer_server_key = IntegerServerKey {
+            key: value.clone(),
+            cpk_key_switching_key_material: None,
+            compression_key: None,
+            decompression_key: None,
+        };
+        BelfortServerKey::default(Arc::new(integer_server_key), Tag::default())
+    }
+}
+
+impl From<Arc<crate::integer::ServerKey>> for BelfortServerKey {
+    fn from(value: Arc<crate::integer::ServerKey>) -> Self {
+        let server_key = Arc::unwrap_or_clone(value);
+        BelfortServerKey::from(&server_key)
+    }
+}
+
+impl BelfortServerKey {
+    pub fn default(key: Arc<IntegerServerKey>, tag: Tag) -> Self {
+        Self {
+            key,
+            tag,
+            fpga_utils: BelfortFpgaUtils::default_integer(),
+        }
+    }
+
+    pub fn connect(&mut self, fpga_count: usize) {
+        #[cfg(not(feature = "emulate_fpga"))]
+        {
+            use crate::core_crypto::fpga::utils::Connect;
+
+            let server_key = &self.key.key.key;
+
+            self.fpga_utils.connect(server_key, fpga_count);
+        }
+    }
+
+    pub fn disconnect(&mut self) {
+        #[cfg(not(feature = "emulate_fpga"))]
+        self.fpga_utils.disconnect();
+    }
+
+    pub fn pbs_key(&self) -> &crate::integer::ServerKey {
+        &self.key.key
+    }
+
+    pub fn tag(&self) -> &Tag {
+        &self.tag
+    }
+
+    pub fn apply_lookup_table_packed(
+        &self,
+        cts: Vec<&Ciphertext>,
+        luts: &Vec<BelfortLookupTable>,
+    ) -> Vec<Ciphertext> {
+        let mut ct_ress: Vec<Ciphertext> = cts.iter().map(|&ct| ct.clone()).collect();
+
+        self.fpga_utils
+            .keyswitch_bootstrap_packed(&mut ct_ress, luts);
+
+        ct_ress
+    }
+
+    fn apply_keyswitch_bootstrap_on_trivials(
+        &self,
+        cts: &mut Vec<Ciphertext>,
+        luts: &Vec<BelfortLookupTable>,
+    ) {
+        let arc_key: &Arc<IntegerServerKey> = &self.key;
+
+        cts.par_iter_mut()
+            .enumerate()
+            .filter(|(_, ct)| ct.is_trivial())
+            .for_each(|(index, ct)| {
+                let lut = &luts[index];
+                let shortint_key = &arc_key.key.key;
+                let acc = BelfortFpgaLuts::get_lut_acc(lut, &shortint_key);
+                shortint_key.trivial_pbs_assign(ct, &acc);
+            });
+    }
+
+    pub fn apply_lookup_table_packed_assign(
+        &self,
+        cts: &mut Vec<Ciphertext>,
+        luts: &Vec<BelfortLookupTable>,
+    ) {
+        #[cfg(not(feature = "emulate_fpga"))]
+        {
+            self.apply_keyswitch_bootstrap_on_trivials(cts, luts);
+            self.fpga_utils.keyswitch_bootstrap_packed(cts, luts);
+        }
+
+        #[cfg(feature = "emulate_fpga")]
+        {
+            let shortint_server_key = &self.key.key.key;
+            let accs: Vec<crate::shortint::server_key::LookupTable<Vec<u64>>> = luts
+                .iter()
+                .map(|l| BelfortFpgaLuts::lut_generator_by_index(l.index)(shortint_server_key))
+                .collect();
+
+            shortint_server_key.apply_lookup_table_packed_assign(cts, &accs);
+        }
+    }
+
+    pub fn apply_same_lookup_table_packed_assign(
+        &self,
+        ciphertexts: &mut Vec<Ciphertext>,
+        lut_name: &str,
+    ) {
+        let shortint_server_key = &self.key.key.key;
+        let lut = BelfortFpgaLuts::lut_by_name(lut_name, shortint_server_key);
+        let luts: Vec<BelfortLookupTable> = vec![lut; ciphertexts.len()];
+
+        self.apply_lookup_table_packed_assign(ciphertexts, &luts);
+    }
+
+    pub fn apply_lookup_table_single_assign(&self, ciphertext: &mut Ciphertext, lut_name: &str) {
+        let shortint_server_key = &self.key.key.key;
+
+        // Obtain the lut index by name
+        let lut = BelfortFpgaLuts::lut_by_name(lut_name, shortint_server_key);
+
+        // Create a vector of the same lut index for the ciphertext
+        let lut_vec = vec![lut];
+        let mut ct_vec = vec![ciphertext.clone()];
+
+        self.apply_lookup_table_packed_assign(&mut ct_vec, &lut_vec);
+
+        *ciphertext = ct_vec.first().unwrap().clone();
+    }
+
+    pub fn apply_lookup_table_mut_packed_assign(
+        &self,
+        ciphertext: &mut Vec<&mut Ciphertext>,
+        luts: &Vec<BelfortLookupTable>,
+    ) {
+        let mut ct_vec: Vec<Ciphertext> = ciphertext
+            .iter_mut()
+            .map(|block| (*block).clone())
+            .collect();
+
+        #[cfg(feature = "fpga")]
+        self.apply_lookup_table_packed_assign(&mut ct_vec, &luts);
+
+        #[cfg(not(feature = "fpga"))]
+        {
+            let accs: Vec<crate::shortint::server_key::LookupTable<Vec<u64>>> = luts
+                .iter()
+                .map(|l| BelfortFpgaLuts::lut_generator_by_index(l.index)(shortint_server_key))
+                .collect();
+
+            shortint_server_key.apply_lookup_table_packed_assign(&mut ct_vec, &accs);
+        }
+
+        ciphertext
+            .iter_mut()
+            .enumerate()
+            .for_each(|(i, block)| **block = ct_vec[i].clone());
+    }
+
+    pub fn conditional_full_propagate_bivariate<'a, T>(&self, lhs: &'a mut T, rhs: &'a mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(lhs);
+        self.conditional_full_propagate(rhs);
+    }
+
+    /// Executes a full propagate if there are carries.
+    pub fn conditional_full_propagate<'a, T>(&self, term: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        if !term.block_carries_are_empty() {
+            self.full_propagate(term);
+        }
+    }
+
+    pub fn full_propagate<T>(&self, ctxt: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.partial_propagate_parallelized(ctxt, 0);
+    }
+
+    // Uses work efficient Hillis Steele, apply function before calling this
+    pub fn full_propagate_work_efficient<T>(&self, ctxt: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let shortint_key = &self.key.key.key;
+        let generates_or_propagates = self.generate_init_carry_array(ctxt.blocks());
+        let carry_out =
+            self.compute_carry_propagation_parallelized_work_efficient(generates_or_propagates);
+
+        ctxt.blocks_mut()
+            .iter_mut()
+            .zip(carry_out.iter())
+            .for_each(|(block, carry_in)| {
+                shortint_key.unchecked_add_assign(block, carry_in);
+            });
+
+        let num_blocks = ctxt.blocks().len();
+        let msg_lut = BelfortFpgaLuts::lut_by_name("msg2_extract", shortint_key);
+        let msg_lut_indices = vec![msg_lut; num_blocks];
+
+        let mut blocks = ctxt.blocks_mut().to_vec();
+        self.apply_lookup_table_packed_assign(&mut blocks, &msg_lut_indices);
+
+        ctxt.blocks_mut()
+            .iter_mut()
+            .enumerate()
+            .for_each(|(i, block)| {
+                *block = blocks[i].clone();
+            });
+    }
+
+    /// This function takes an input slice of shortint ciphertext (aka blocks)
+    /// for which at most one bit of carry is consumed in each block, and
+    /// it does the carry propagation in place.
+    ///
+    /// It returns the output carry of the last block
+    ///
+    /// Used in (among other) 'default' addition:
+    /// - first unchecked_add
+    /// - at this point at most on bit of carry is taken
+    /// - use this function to propagate them in parallel
+    pub(crate) fn propagate_single_carry_parallelized_low_latency(
+        &self,
+        blocks: &mut [Ciphertext],
+    ) {
+        let generates_or_propagates = self.generate_init_carry_array(blocks);
+
+        let input_carries =
+            self.compute_carry_propagation_parallelized_low_latency(generates_or_propagates);
+
+        let key = &self.key.key.key;
+
+        blocks
+            .par_iter_mut()
+            .zip(input_carries.par_iter())
+            .for_each(|(block, input_carry)| {
+                key.unchecked_add_assign(block, input_carry);
+            });
+
+        let num_blocks = blocks.len();
+        let msg_lut = BelfortFpgaLuts::lut_by_name("msg2_extract", &self.key.key.key);
+        let msg_lut_indices = vec![msg_lut; num_blocks];
+
+        let mut blocks_vec = blocks.to_vec();
+        self.apply_lookup_table_packed_assign(&mut blocks_vec, &msg_lut_indices);
+
+        blocks
+            .par_iter_mut()
+            .zip(blocks_vec.par_iter())
+            .for_each(|(block, vec_block)| {
+                *block = vec_block.clone();
+            });
+    }
+
+    fn generate_init_carry_array(&self, sum_blocks: &[Ciphertext]) -> Vec<Ciphertext> {
+        let lut_does_block_generate_carry =
+            BelfortFpgaLuts::lut_by_name("does_block_generate_carry", &self.key.key.key);
+        let lut_does_block_generate_or_propagate =
+            BelfortFpgaLuts::lut_by_name("does_block_generate_or_propagate", &self.key.key.key);
+
+        let mut lut_indices: Vec<BelfortLookupTable> = Vec::with_capacity(sum_blocks.len());
+
+        sum_blocks
+            .par_iter()
+            .enumerate()
+            .map(|(i, _)| {
+                if i == 0 {
+                    lut_does_block_generate_carry
+                } else {
+                    lut_does_block_generate_or_propagate
+                }
+            })
+            .collect_into_vec(&mut lut_indices);
+
+        let mut generates_or_propagates = sum_blocks.to_vec();
+
+        self.apply_lookup_table_packed_assign(&mut generates_or_propagates, &lut_indices);
+
+        generates_or_propagates
+    }
+
+    /// Backbone algorithm of parallel carry (only one bit) propagation
+    ///
+    /// Uses the Hillis and Steele prefix scan
+    ///
+    /// Requires the blocks to have at least 4 bits
+    pub(crate) fn compute_carry_propagation_parallelized_low_latency(
+        &self,
+        generates_or_propagates: Vec<Ciphertext>,
+    ) -> Vec<Ciphertext> {
+        if generates_or_propagates.is_empty() {
+            return vec![];
+        }
+
+        let num_blocks = generates_or_propagates.len();
+
+        let mut carries_out = self.compute_prefix_sum_hillis_steele(
+            generates_or_propagates,
+            |msb, lsb| {
+                if msb == OutputCarry::Propagated as u64 {
+                    lsb
+                } else {
+                    msb
+                }
+            },
+            "carry_propagation_sum".to_owned(),
+        );
+
+        let mut last_block_out_carry = self.key.key.key.create_trivial(0u64);
+        std::mem::swap(&mut carries_out[num_blocks - 1], &mut last_block_out_carry);
+        last_block_out_carry.degree = Degree::new(1);
+
+        carries_out.rotate_right(1);
+        carries_out
+    }
+
+    /// Computes a prefix sum/scan in parallel using Hillis & Steel algorithm
+    pub(crate) fn compute_prefix_sum_hillis_steele<F>(
+        &self,
+        mut blocks: Vec<Ciphertext>,
+        sum_function: F,
+        lut_name: String,
+    ) -> Vec<Ciphertext>
+    where
+        F: for<'a, 'b> Fn(u64, u64) -> u64,
+    {
+        let shortint_key = &self.key.key.key;
+        debug_assert!(shortint_key.message_modulus.0 * shortint_key.carry_modulus.0 >= (1 << 4));
+
+        if blocks.is_empty() {
+            return vec![];
+        }
+
+        let num_blocks = blocks.len();
+        let num_steps = blocks.len().ceil_ilog2() as usize;
+
+        let mut space = 1;
+        let mut step_output = blocks.clone();
+
+        let lut_carry_propagation_sum_index = BelfortFpgaLuts::lut_by_name(&lut_name, shortint_key);
+
+        let lut_carry_propagation_sum = shortint_key.generate_lookup_table_bivariate(sum_function);
+
+        for _ in 0..num_steps {
+            let mut prev_block_carries = vec![];
+            for i in 0..(num_blocks - space) {
+                prev_block_carries.push(blocks[i].clone());
+            }
+
+            let lut_indices = vec![lut_carry_propagation_sum_index; num_blocks - space];
+
+            let mut step_output_vec = step_output[space..num_blocks].to_vec();
+
+            let mut prepared_blocks = self.prepare_bivariate(
+                &mut step_output_vec,
+                &prev_block_carries,
+                &lut_carry_propagation_sum,
+            );
+
+            self.apply_lookup_table_packed_assign(&mut prepared_blocks, &lut_indices);
+
+            for (i, block) in prepared_blocks.into_iter().enumerate() {
+                step_output[space + i] = block;
+            }
+
+            for i in space..num_blocks {
+                blocks[i].clone_from(&step_output[i]);
+            }
+
+            space *= 2;
+        }
+
+        blocks
+    }
+
+    pub fn propagate_parallelized<T>(&self, ctxt: &mut T, index: usize) -> Ciphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let shortint_server_key = &self.key.key.key;
+
+        let carry_lut = BelfortFpgaLuts::lut_by_name("carry2_extract", shortint_server_key);
+        let msg_lut = BelfortFpgaLuts::lut_by_name("msg2_extract", shortint_server_key);
+
+        let block = &ctxt.blocks()[index].clone();
+        let mut result = vec![block.clone(), block.clone()];
+        self.apply_lookup_table_packed_assign(&mut result, &vec![carry_lut, msg_lut]);
+
+        let (carry, message) = (result[0].clone(), result[1].clone());
+        ctxt.blocks_mut()[index] = message.clone();
+
+        if index < ctxt.blocks().len() - 1 {
+            shortint_server_key.unchecked_add_assign(&mut ctxt.blocks_mut()[index + 1], &carry);
+        }
+
+        carry.clone()
+    }
+
+    fn partial_propagate_parallelized<T>(&self, ctxt: &mut T, start_index: usize)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        if start_index >= ctxt.blocks().len() || ctxt.blocks().is_empty() {
+            return;
+        }
+        let shortint_key = &self.key.key.key;
+        let highest_degree = ctxt.blocks()[start_index..]
+            .iter()
+            .max_by(|block_a, block_b| block_a.degree.get().cmp(&block_b.degree.get()))
+            .map(|block| block.degree.get())
+            .unwrap();
+
+        if highest_degree <= (shortint_key.message_modulus.0 - 1) * 2 {
+            self.propagate_single_carry_parallelized_low_latency(
+                &mut ctxt.blocks_mut()[start_index..],
+            );
+        } else {
+            let (mut message_blocks, carry_blocks) =
+                self.extract_message_and_carry_blocks(&ctxt.blocks()[start_index..]);
+
+            ctxt.blocks_mut()[start_index..].swap_with_slice(&mut message_blocks);
+            for (block, carry) in ctxt.blocks_mut()[start_index + 1..]
+                .iter_mut()
+                .zip(carry_blocks.iter())
+            {
+                shortint_key.unchecked_add_assign(block, carry);
+            }
+
+            self.propagate_single_carry_parallelized_low_latency(
+                &mut ctxt.blocks_mut()[start_index + 1..],
+            );
+        }
+    }
+
+    fn extract_message_and_carry_blocks(
+        &self,
+        blocks: &[Ciphertext],
+    ) -> (Vec<Ciphertext>, Vec<Ciphertext>) {
+        let shortint_key = &self.key.key.key;
+
+        let carry_lut = BelfortFpgaLuts::lut_by_name("carry2_extract", shortint_key);
+        let msg_lut = BelfortFpgaLuts::lut_by_name("msg2_extract", shortint_key);
+
+        let num_blocks = blocks.len();
+        let mut lut_indices = vec![carry_lut; num_blocks];
+        let mut msg_lut_indices = vec![msg_lut; num_blocks];
+        lut_indices.append(&mut msg_lut_indices);
+
+        let mut prepared_blocks = vec![];
+        prepared_blocks.extend(blocks.to_vec().clone());
+        prepared_blocks.extend(blocks.to_vec().clone());
+
+        self.apply_lookup_table_packed_assign(&mut prepared_blocks, &lut_indices);
+
+        let half_len = prepared_blocks.len() / 2;
+        let carries: Vec<_> = prepared_blocks
+            .iter()
+            .take(half_len - 1) // -1, because last carry doesn't propagate
+            .map(|x| x.clone())
+            .collect();
+
+        let messages: Vec<_> = prepared_blocks
+            .iter()
+            .skip(half_len)
+            .map(|x| x.clone())
+            .collect();
+
+        (messages, carries)
+    }
+
+    pub fn prepare_bivariate(
+        &self,
+        lhs_blocks: &mut Vec<Ciphertext>,
+        rhs_blocks: &Vec<Ciphertext>,
+        lut: &BivariateLookupTableOwned,
+    ) -> Vec<Ciphertext> {
+        let mut prepared_blocks = Vec::new();
+
+        lhs_blocks
+            .iter_mut()
+            .zip(rhs_blocks.iter())
+            .for_each(|(lhs_block, rhs_block)| {
+                let mut block_clone_sum = lhs_block.clone();
+                self.key
+                    .key
+                    .key
+                    .unchecked_apply_lookup_table_bivariate_assign_prep(
+                        &mut block_clone_sum,
+                        rhs_block,
+                        &lut,
+                    );
+                prepared_blocks.push(block_clone_sum);
+            });
+
+        prepared_blocks
+    }
+
+    pub(crate) fn compute_carry_propagation_parallelized_work_efficient(
+        &self,
+        mut carry_out: Vec<Ciphertext>,
+    ) -> Vec<Ciphertext> {
+        let integer_key = &self.key.key.key;
+        debug_assert!(integer_key.message_modulus.0 * integer_key.carry_modulus.0 >= (1 << 3));
+
+        let num_blocks = carry_out.len();
+        let num_steps = num_blocks.ilog2();
+
+        let lut_carry_propagation_sum =
+            integer_key.generate_lookup_table_bivariate(|msb: u64, lsb: u64| -> u64 {
+                if msb == OutputCarry::Propagated as u64 {
+                    lsb
+                } else {
+                    msb
+                }
+            });
+
+        let lut_carry_propagation_sum_index: BelfortLookupTable =
+            BelfortFpgaLuts::lut_by_name("carry_propagation_sum", &integer_key);
+
+        for i in 0..num_steps {
+            let two_pow_i_plus_1 = 2_usize.checked_pow(i + 1).unwrap();
+            let two_pow_i = 2_usize.checked_pow(i).unwrap();
+
+            let mut current_blocks = vec![];
+            let mut previous_blocks = vec![];
+
+            carry_out
+                .chunks_exact_mut(two_pow_i_plus_1)
+                .for_each(|carry_out| {
+                    let (current_block, head) = carry_out.split_last_mut().unwrap();
+                    let previous_block = &head[two_pow_i - 1];
+
+                    current_blocks.push(current_block.clone());
+                    previous_blocks.push(previous_block.clone());
+                });
+
+            let mut prepared_blocks = self.prepare_bivariate(
+                &mut current_blocks,
+                &previous_blocks,
+                &lut_carry_propagation_sum,
+            );
+            let indices_num = prepared_blocks.len();
+            self.apply_lookup_table_packed_assign(
+                &mut prepared_blocks,
+                &vec![lut_carry_propagation_sum_index; indices_num],
+            );
+
+            let mut prepared_block_iter = prepared_blocks.into_iter();
+            carry_out
+                .chunks_exact_mut(two_pow_i_plus_1)
+                .for_each(|carry_out_chunk| {
+                    let (last, _) = carry_out_chunk.split_last_mut().unwrap();
+                    *last = prepared_block_iter.next().unwrap();
+                });
+        }
+
+        // Down-Sweep phase
+        integer_key.create_trivial_assign(&mut carry_out[num_blocks - 1], 0);
+
+        for i in (0..num_steps).rev() {
+            let two_pow_i_plus_1 = 2usize.checked_pow(i + 1).unwrap();
+            let two_pow_i = 2usize.checked_pow(i as u32).unwrap();
+
+            let mut blocks1 = vec![];
+            let mut blocks2 = vec![];
+
+            (0..num_blocks)
+                .into_iter()
+                .step_by(two_pow_i_plus_1)
+                .for_each(|k| {
+                    blocks1.push(carry_out[k + two_pow_i - 1].clone());
+                    blocks2.push(carry_out[k + two_pow_i_plus_1 - 1].clone());
+                });
+
+            let mut buffer =
+                self.prepare_bivariate(&mut blocks1, &blocks2, &lut_carry_propagation_sum);
+            let indices_num = buffer.len();
+            self.apply_lookup_table_packed_assign(
+                &mut buffer,
+                &vec![lut_carry_propagation_sum_index; indices_num],
+            );
+
+            let mut drainer = buffer.drain(..);
+            for k in (0..num_blocks).step_by(two_pow_i_plus_1) {
+                let b = drainer.next().unwrap();
+                carry_out.swap(k + two_pow_i - 1, k + two_pow_i_plus_1 - 1);
+                carry_out[k + two_pow_i_plus_1 - 1] = b;
+            }
+            drop(drainer);
+            assert!(buffer.is_empty());
+        }
+
+        // The first step of the Down-Sweep phase sets the
+        // first block to 0, so no need to re-do it
+        carry_out
+    }
+
+    pub(crate) fn pack_blocks<T>(&self, ct_left: &T, ct_right: &T) -> Vec<Ciphertext>
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result: Vec<Ciphertext> = ct_left.blocks().to_vec();
+        result
+            .iter_mut()
+            .zip(ct_right.blocks().iter())
+            .for_each(|(mut ct_left_i, ct_right_i)| {
+                self.key.key.pack_block_assign(ct_right_i, &mut ct_left_i)
+            });
+        result
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/abs.rs b/tfhe/src/integer/fpga/server_key/radix/abs.rs
new file mode 100644
index 00000000..de29a029
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/abs.rs
@@ -0,0 +1,34 @@
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use log::warn;
+
+impl BelfortServerKey {
+    pub fn unchecked_abs<T>(&self, ct: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key.key.unchecked_abs_parallelized(ct)
+    }
+
+    pub fn smart_abs<T>(&self, ct: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_abs(ct)
+    }
+
+    pub fn abs<T>(&self, ct: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        if ct.block_carries_are_empty() {
+            self.unchecked_abs(ct)
+        } else {
+            let mut cloned = ct.clone();
+            self.full_propagate(&mut cloned);
+            self.unchecked_abs(&cloned)
+        }
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/add.rs b/tfhe/src/integer/fpga/server_key/radix/add.rs
new file mode 100644
index 00000000..b6d1c9be
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/add.rs
@@ -0,0 +1,259 @@
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::{BelfortFpgaLuts, BelfortServerKey};
+use crate::integer::server_key::CheckError;
+
+impl BelfortServerKey {
+    /// Computes homomorphically an addition between two ciphertexts encrypting integer values.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    pub fn add<T>(&self, ct1: &T, ct2: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct1.clone();
+        self.add_assign(&mut ct_res, ct2);
+        ct_res
+    }
+
+    pub fn add_assign<T>(&self, ct1: &mut T, ct2: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (ct1.block_carries_are_empty(), ct2.block_carries_are_empty()) {
+            (true, true) => (ct1, ct2),
+            (true, false) => {
+                tmp_rhs = ct2.clone();
+                self.full_propagate(&mut tmp_rhs);
+                (ct1, &tmp_rhs)
+            }
+            (false, true) => {
+                self.full_propagate(ct1);
+                (ct1, ct2)
+            }
+            (false, false) => {
+                tmp_rhs = ct2.clone();
+                self.full_propagate(ct1);
+                self.full_propagate(&mut tmp_rhs);
+                (ct1, &tmp_rhs)
+            }
+        };
+
+        // TODO: if you go below 4 bits think about this
+        self.unchecked_add_assign_parallelized_low_latency(lhs, rhs);
+    }
+
+    pub fn unchecked_add<T>(&self, ct1: &T, ct2: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.key.key.unchecked_add(ct1, ct2)
+    }
+
+    pub fn unchecked_add_assign<T>(&self, ct1: &mut T, ct2: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.key.key.unchecked_add_assign(ct1, ct2);
+    }
+
+    pub fn checked_add<T>(&self, ct1: &T, ct2: &T) -> Result<T, CheckError>
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.key.key.is_add_possible(ct1, ct2)?;
+        Ok(self.key.key.unchecked_add(ct1, ct2))
+    }
+
+    pub fn smart_add<T>(&self, ct1: &mut T, ct2: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        if self.key.key.is_add_possible(ct1, ct2).is_err() {
+            self.full_propagate(ct1);
+            self.full_propagate(ct2);
+        }
+
+        self.key.key.is_add_possible(ct1, ct2).unwrap();
+        self.key.key.unchecked_add(ct1, ct2)
+    }
+
+    pub fn checked_add_assign<T>(&self, ct1: &mut T, ct2: &T) -> Result<(), CheckError>
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.key.key.is_add_possible(ct1, ct2)?;
+        self.unchecked_add_assign(ct1, ct2);
+        Ok(())
+    }
+
+    pub fn smart_add_assign<T>(&self, ct1: &mut T, ct2: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+        if integer_key.is_add_possible(ct1, ct2).is_err() {
+            self.full_propagate(ct1);
+            self.full_propagate(ct2);
+        }
+        integer_key.is_add_possible(ct1, ct2).unwrap();
+        self.unchecked_add_assign(ct1, ct2);
+    }
+
+    /// This add_assign two numbers
+    ///
+    /// It uses the Hillis and Steele algorithm to do
+    /// prefix sum / cumulative sum in parallel.
+    ///
+    /// It it not "work efficient" as in, it adds a lot
+    /// of work compared to the single threaded approach,
+    /// however it is highly parallelized and so is the fastest
+    /// assuming enough threads are available.
+    ///
+    /// At most num_block - 1 threads are used
+    ///
+    /// Returns the output carry that can be used to check for unsigned addition
+    /// overflow.
+    ///
+    /// # Requirements
+    ///
+    /// - The parameters have 4 bits in total
+    /// - Adding rhs to lhs must not consume more than one carry
+    ///
+    /// # Output
+    ///
+    /// - lhs will have its carries empty
+    pub(crate) fn unchecked_add_assign_parallelized_low_latency<T>(&self, lhs: &mut T, rhs: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+
+        let degree_after_add_does_not_go_beyond_first_carry = lhs
+            .blocks()
+            .iter()
+            .zip(rhs.blocks().iter())
+            .all(|(bl, br)| {
+                let degree_after_add = bl.degree.get() + br.degree.get();
+                degree_after_add < (integer_key.message_modulus().0 * 2)
+            });
+        assert!(degree_after_add_does_not_go_beyond_first_carry);
+
+        integer_key.unchecked_add_assign_parallelized(lhs, rhs);
+        self.propagate_single_carry_parallelized_low_latency(lhs.blocks_mut())
+    }
+
+    pub fn add_work_efficient<T>(&self, ct_left: &T, ct_right: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct_left.clone();
+        self.add_assign_work_efficient(&mut ct_res, ct_right);
+        ct_res
+    }
+
+    pub fn add_assign_work_efficient<T>(&self, ct_left: &mut T, ct_right: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_rhs: T;
+
+        let (lhs, rhs) = match (
+            ct_left.block_carries_are_empty(),
+            ct_right.block_carries_are_empty(),
+        ) {
+            (true, true) => (ct_left, ct_right),
+            (true, false) => {
+                tmp_rhs = ct_right.clone();
+                self.full_propagate(&mut tmp_rhs);
+                (ct_left, &tmp_rhs)
+            }
+            (false, true) => {
+                self.full_propagate(ct_left);
+                (ct_left, ct_right)
+            }
+            (false, false) => {
+                tmp_rhs = ct_right.clone();
+                self.full_propagate(ct_left);
+                self.full_propagate(&mut tmp_rhs);
+                (ct_left, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_add_assign_work_efficient(lhs, rhs);
+    }
+
+    /// This add_assign two numbers
+    ///
+    /// It is after the Blelloch algorithm to do
+    /// prefix sum / cumulative sum in parallel.
+    ///
+    /// It is not "work efficient" as in, it does not adds
+    /// that much work compared to other parallel algorithm,
+    /// thus requiring less threads.
+    ///
+    /// However it is slower.
+    ///
+    /// At most num_block / 2 threads are used
+    ///
+    /// # Requirements
+    ///
+    /// - The parameters have 4 bits in total
+    /// - Adding rhs to lhs must not consume more than one carry
+    ///
+    /// # Output
+    ///
+    /// - lhs will have its carries empty
+    pub(crate) fn unchecked_add_assign_work_efficient<T>(&self, lhs: &mut T, rhs: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+        let shortint_key = &integer_key.key;
+
+        let degree_after_add_does_not_go_beyond_first_carry = lhs
+            .blocks()
+            .iter()
+            .zip(rhs.blocks().iter())
+            .all(|(bl, br)| {
+                let degree_after_add = bl.degree.get() + br.degree.get();
+                degree_after_add < (integer_key.message_modulus().0 * 2)
+            });
+        assert!(degree_after_add_does_not_go_beyond_first_carry);
+        debug_assert!(integer_key.message_modulus().0 * integer_key.carry_modulus().0 >= (1 << 3));
+
+        self.unchecked_add_assign(lhs, rhs);
+        let generates_or_propagates = self.generate_init_carry_array(lhs.blocks());
+        let carry_out =
+            self.compute_carry_propagation_parallelized_work_efficient(generates_or_propagates);
+
+        lhs.blocks_mut()
+            .iter_mut()
+            .zip(carry_out.iter())
+            .for_each(|(block, carry_in)| {
+                shortint_key.unchecked_add_assign(block, carry_in);
+            });
+
+        let num_blocks = lhs.blocks().len();
+        let msg_lut = BelfortFpgaLuts::lut_by_name("msg2_extract", shortint_key);
+        let msg_lut_indices = vec![msg_lut; num_blocks];
+
+        let mut blocks = lhs.blocks_mut().to_vec();
+        self.apply_lookup_table_packed_assign(&mut blocks, &msg_lut_indices);
+
+        lhs.blocks_mut()
+            .iter_mut()
+            .enumerate()
+            .for_each(|(i, block)| {
+                *block = blocks[i].clone();
+            });
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/bit_extractor.rs b/tfhe/src/integer/fpga/server_key/radix/bit_extractor.rs
new file mode 100644
index 00000000..cefbd83d
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/bit_extractor.rs
@@ -0,0 +1,100 @@
+use crate::core_crypto::fpga::luts::BelfortLookupTable;
+use crate::core_crypto::fpga::BelfortFpgaLuts;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::shortint::Ciphertext;
+use itertools::iproduct;
+
+pub(crate) struct BitExtractor<'a> {
+    bit_extract_luts: Vec<BelfortLookupTable>,
+    bits_per_block: usize,
+    server_key: &'a BelfortServerKey,
+}
+
+impl<'a> BitExtractor<'a> {
+    pub(crate) fn msg_with_final_offset0(
+        server_key: &'a BelfortServerKey,
+        bits_per_block: usize,
+    ) -> Self {
+        let int_server_key = &server_key.key.key;
+
+        let mut bit_extract_luts: Vec<BelfortLookupTable> = Vec::new();
+
+        bit_extract_luts.push(BelfortFpgaLuts::lut_by_name(
+            "scalar_bitand_one",
+            &int_server_key.key,
+        ));
+
+        if int_server_key.message_modulus().0 == 4 {
+            bit_extract_luts.push(BelfortFpgaLuts::lut_by_name(
+                "msg_bit1_extract",
+                &int_server_key.key,
+            ));
+        }
+
+        Self {
+            bit_extract_luts,
+            bits_per_block,
+            server_key,
+        }
+    }
+
+    /// Creates a bit extractor that will extract bits from an input ciphertext
+    /// into single blocks.
+    ///
+    /// The offset which is 2 gives the position where the extracted bit shall be placed
+    /// in the resulting block.
+    /// It may be used to align the bit with a certain position to avoid
+    /// shifting it later (and increasing noise)
+    pub(crate) fn msg_with_final_offset2(
+        server_key: &'a BelfortServerKey,
+        bits_per_block: usize,
+    ) -> Self {
+        let int_server_key = &server_key.key.key;
+
+        let mut bit_extract_luts: Vec<BelfortLookupTable> = Vec::new();
+
+        bit_extract_luts.push(BelfortFpgaLuts::lut_by_name(
+            "msg_bit0_extract_offset2",
+            &int_server_key.key,
+        ));
+
+        if int_server_key.message_modulus().0 == 4 {
+            bit_extract_luts.push(BelfortFpgaLuts::lut_by_name(
+                "msg_bit1_extract_offset2",
+                &int_server_key.key,
+            ));
+        }
+
+        Self {
+            bit_extract_luts,
+            bits_per_block,
+            server_key,
+        }
+    }
+
+    pub(crate) fn extract_all_bits(&self, blocks: &[Ciphertext]) -> Vec<Ciphertext> {
+        let num_blocks: usize = blocks.len();
+        self.extract_n_bits(blocks, num_blocks * self.bits_per_block)
+    }
+
+    pub(crate) fn extract_n_bits(&self, blocks: &[Ciphertext], n: usize) -> Vec<Ciphertext> {
+        let num_blocks = blocks.len();
+        let jobs = iproduct!(0..num_blocks, 0..self.bits_per_block)
+            .take(n)
+            .collect::<Vec<_>>();
+        let (blocks_idxs, lut_idxs): (Vec<usize>, Vec<usize>) = jobs.into_iter().unzip();
+        let mut blocks = blocks_idxs
+            .iter()
+            .map(|block_idx| blocks[*block_idx].clone())
+            .collect::<Vec<_>>();
+
+        let luts = lut_idxs
+            .iter()
+            .map(|lut_idx| self.bit_extract_luts[*lut_idx])
+            .collect::<Vec<_>>();
+
+        self.server_key.apply_lookup_table_packed_assign(&mut blocks, &luts);
+
+        blocks
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/bitwise_op.rs b/tfhe/src/integer/fpga/server_key/radix/bitwise_op.rs
new file mode 100644
index 00000000..9612fe86
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/bitwise_op.rs
@@ -0,0 +1,519 @@
+use crate::core_crypto::prelude::lwe_ciphertext_opposite_assign;
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::shortint::ciphertext::Degree;
+
+impl BelfortServerKey {
+    pub fn unchecked_bitand<T>(&self, ct_left: &T, ct_right: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result = ct_left.clone();
+        self.unchecked_bitand_assign(&mut result, ct_right);
+        result
+    }
+
+    pub fn unchecked_bitand_assign<T>(&self, ct_left: &mut T, ct_right: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result = self.pack_blocks(ct_left, ct_right);
+
+        self.apply_same_lookup_table_packed_assign(&mut result, "bitand");
+
+        for (i, block) in result.into_iter().enumerate() {
+            ct_left.blocks_mut()[i] = block;
+        }
+    }
+
+    /// Computes homomorphically a bitand between two ciphertexts encrypting integer values.
+    ///
+    /// # Warning
+    ///
+    /// - Multithreaded
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 14;
+    /// let msg2 = 97;
+    ///
+    /// let mut ct1 = cks.encrypt(msg1);
+    /// let mut ct2 = cks.encrypt(msg2);
+    ///
+    /// let ct_res = sks.smart_bitand(&mut ct1, &mut ct2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, msg1 & msg2);
+    /// ```
+    pub fn smart_bitand<T>(&self, ct_left: &mut T, ct_right: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.full_propagate_if_degree_too_large(ct_left, ct_right);
+        self.unchecked_bitand(ct_left, ct_right)
+    }
+
+    pub fn smart_bitand_assign<T>(&self, ct_left: &mut T, ct_right: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.full_propagate_if_degree_too_large(ct_left, ct_right);
+        self.key.key.unchecked_bitand_assign(ct_left, ct_right);
+    }
+
+    /// Computes homomorphically a bitand between two ciphertexts encrypting integer values.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Warning
+    ///
+    /// - Multithreaded
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 14;
+    /// let msg2 = 97;
+    ///
+    /// let ct1 = cks.encrypt(msg1);
+    /// let ct2 = cks.encrypt(msg2);
+    ///
+    /// let ct_res = sks.bitand(&ct1, &ct2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, msg1 & msg2);
+    /// ```
+    pub fn bitand<T>(&self, ct_left: &T, ct_right: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct_left.clone();
+        self.bitand_assign(&mut ct_res, ct_right);
+        ct_res
+    }
+
+    pub fn bitand_assign<T>(&self, ct_left: &mut T, ct_right: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (
+            ct_left.block_carries_are_empty(),
+            ct_right.block_carries_are_empty(),
+        ) {
+            (true, true) => (ct_left, ct_right),
+            (true, false) => {
+                tmp_rhs = ct_right.clone();
+                self.full_propagate(&mut tmp_rhs);
+                (ct_left, &tmp_rhs)
+            }
+            (false, true) => {
+                self.full_propagate(ct_left);
+                (ct_left, ct_right)
+            }
+            (false, false) => {
+                tmp_rhs = ct_right.clone();
+
+                self.full_propagate(ct_left);
+                self.full_propagate(&mut tmp_rhs);
+
+                (ct_left, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_bitand_assign(lhs, rhs);
+    }
+
+    pub fn unchecked_bitor<T>(&self, ct_left: &T, ct_right: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result = ct_left.clone();
+        self.unchecked_bitor_assign(&mut result, ct_right);
+        result
+    }
+
+    pub fn unchecked_bitor_assign<T>(&self, ct_left: &mut T, ct_right: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result = self.pack_blocks(ct_left, ct_right);
+        self.apply_same_lookup_table_packed_assign(&mut result, "bitor");
+
+        for (i, block) in result.into_iter().enumerate() {
+            ct_left.blocks_mut()[i] = block;
+        }
+    }
+
+    /// Computes homomorphically a bitor between two ciphertexts encrypting integer values.
+    ///
+    /// # Warning
+    ///
+    /// - Multithreaded
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 14;
+    /// let msg2 = 97;
+    ///
+    /// let mut ct1 = cks.encrypt(msg1);
+    /// let mut ct2 = cks.encrypt(msg2);
+    ///
+    /// let ct_res = sks.smart_bitor(&mut ct1, &mut ct2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, msg1 | msg2);
+    /// ```
+    pub fn smart_bitor<T>(&self, ct_left: &mut T, ct_right: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.full_propagate_if_degree_too_large(ct_left, ct_right);
+        self.unchecked_bitor(ct_left, ct_right)
+    }
+
+    pub fn smart_bitor_assign<T>(&self, ct_left: &mut T, ct_right: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.full_propagate_if_degree_too_large(ct_left, ct_right);
+        self.unchecked_bitor_assign(ct_left, ct_right);
+    }
+
+    /// Computes homomorphically a bitor between two ciphertexts encrypting integer values.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Warning
+    ///
+    /// - Multithreaded
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 14;
+    /// let msg2 = 97;
+    ///
+    /// let ct1 = cks.encrypt(msg1);
+    /// let ct2 = cks.encrypt(msg2);
+    ///
+    /// let ct_res = sks.bitor(&ct1, &ct2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, msg1 | msg2);
+    /// ```
+    pub fn bitor<T>(&self, ct_left: &T, ct_right: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct_left.clone();
+        self.bitor_assign(&mut ct_res, ct_right);
+        ct_res
+    }
+
+    pub fn bitor_assign<T>(&self, ct_left: &mut T, ct_right: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (
+            ct_left.block_carries_are_empty(),
+            ct_right.block_carries_are_empty(),
+        ) {
+            (true, true) => (ct_left, ct_right),
+            (true, false) => {
+                tmp_rhs = ct_right.clone();
+                self.full_propagate(&mut tmp_rhs);
+                (ct_left, &tmp_rhs)
+            }
+            (false, true) => {
+                self.full_propagate(ct_left);
+                (ct_left, ct_right)
+            }
+            (false, false) => {
+                tmp_rhs = ct_right.clone();
+
+                self.full_propagate(ct_left);
+                self.full_propagate(&mut tmp_rhs);
+
+                (ct_left, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_bitor_assign(lhs, rhs);
+    }
+
+    pub fn unchecked_bitxor<T>(&self, ct_left: &T, ct_right: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result = ct_left.clone();
+        self.unchecked_bitxor_assign(&mut result, ct_right);
+        result
+    }
+
+    pub fn unchecked_bitxor_assign<T>(&self, ct_left: &mut T, ct_right: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result = self.pack_blocks(ct_left, ct_right);
+
+        self.apply_same_lookup_table_packed_assign(&mut result, "bitxor");
+
+        for (i, block) in result.into_iter().enumerate() {
+            ct_left.blocks_mut()[i] = block;
+        }
+    }
+
+    /// Computes homomorphically a bitxor between two ciphertexts encrypting integer values.
+    ///
+    /// # Warning
+    ///
+    /// - Multithreaded
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 14;
+    /// let msg2 = 97;
+    ///
+    /// let mut ct1 = cks.encrypt(msg1);
+    /// let mut ct2 = cks.encrypt(msg2);
+    ///
+    /// let ct_res = sks.smart_bitxor(&mut ct1, &mut ct2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, msg1 ^ msg2);
+    /// ```
+    pub fn smart_bitxor<T>(&self, ct_left: &mut T, ct_right: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.full_propagate_if_degree_too_large(ct_left, ct_right);
+        self.unchecked_bitxor(ct_left, ct_right)
+    }
+
+    pub fn smart_bitxor_assign<T>(&self, ct_left: &mut T, ct_right: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.full_propagate_if_degree_too_large(ct_left, ct_right);
+        self.unchecked_bitxor_assign(ct_left, ct_right);
+    }
+
+    /// Computes homomorphically a bitxor between two ciphertexts encrypting integer values.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Warning
+    ///
+    /// - Multithreaded
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 14;
+    /// let msg2 = 97;
+    ///
+    /// let ct1 = cks.encrypt(msg1);
+    /// let ct2 = cks.encrypt(msg2);
+    ///
+    /// let ct_res = sks.bitxor(&ct1, &ct2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, msg1 ^ msg2);
+    /// ```
+    pub fn bitxor<T>(&self, ct_left: &T, ct_right: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct_left.clone();
+        self.bitxor_assign(&mut ct_res, ct_right);
+        ct_res
+    }
+
+    pub fn bitxor_assign<T>(&self, ct_left: &mut T, ct_right: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (
+            ct_left.block_carries_are_empty(),
+            ct_right.block_carries_are_empty(),
+        ) {
+            (true, true) => (ct_left, ct_right),
+            (true, false) => {
+                tmp_rhs = ct_right.clone();
+                self.full_propagate(&mut tmp_rhs);
+                (ct_left, &tmp_rhs)
+            }
+            (false, true) => {
+                self.full_propagate(ct_left);
+                (ct_left, ct_right)
+            }
+            (false, false) => {
+                tmp_rhs = ct_right.clone();
+
+                self.full_propagate(ct_left);
+                self.full_propagate(&mut tmp_rhs);
+
+                (ct_left, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_bitxor_assign(lhs, rhs);
+    }
+
+    /// Computes homomorphically a bitnot on a ciphertext encrypting integer values.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertext block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg = 14;
+    ///
+    /// let ct = cks.encrypt(msg);
+    ///
+    /// let ct_res = sks.bitnot(&ct);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, (!msg) % (1 << 8));
+    /// ```
+    pub fn bitnot<T>(&self, ct: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct.clone();
+        self.bitnot_assign(&mut ct_res);
+        ct_res
+    }
+
+    pub fn bitnot_assign<T>(&self, ct: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+
+        ct.blocks_mut().iter_mut().for_each(|ct_block| {
+            assert!(ct_block.message_modulus.0.is_power_of_two());
+            if !ct_block.carry_is_empty() {
+                self.apply_lookup_table_single_assign(ct_block, "msg2_extract");
+            }
+            // We do (-ciphertext) + (msg_mod -1) as it allows to avoid an allocation
+            lwe_ciphertext_opposite_assign(&mut ct_block.ct);
+            self.key
+                .key
+                .key
+                .unchecked_scalar_add_assign(ct_block, ct_block.message_modulus.0 as u8 - 1);
+            ct_block.degree = Degree::new(ct_block.message_modulus.0 - 1)
+        });
+    }
+
+    fn full_propagate_if_degree_too_large<T>(&self, ct_left: &mut T, ct_right: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+        if integer_key
+            .is_functional_bivariate_pbs_possible(ct_left, ct_right)
+            .is_err()
+        {
+            self.full_propagate(ct_left);
+            self.full_propagate(ct_right);
+        }
+        integer_key
+            .is_functional_bivariate_pbs_possible(ct_left, ct_right)
+            .unwrap();
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/cmux.rs b/tfhe/src/integer/fpga/server_key/radix/cmux.rs
new file mode 100644
index 00000000..6a27c311
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/cmux.rs
@@ -0,0 +1,346 @@
+use crate::integer::ciphertext::boolean_value::BooleanBlock;
+use crate::integer::fpga::server_key::BelfortFpgaLuts;
+use crate::integer::IntegerRadixCiphertext;
+use crate::shortint::Ciphertext;
+use crate::BelfortServerKey;
+use rayon::prelude::*;
+use std::sync::Arc;
+
+impl BelfortServerKey {
+    /// FHE "if then else" selection.
+    ///
+    /// Returns a new ciphertext that encrypts the same value
+    /// as either true_ct or false_ct depending on the value of condition:
+    ///
+    /// - If condition == 1, the returned ciphertext will encrypt the same value as true_ct.
+    /// - If condition == 0, the returned ciphertext will encrypt the same value as false_ct.
+    ///
+    /// To ensure correct results, condition must encrypt either 0 or 1
+    /// (e.g result from a comparison).
+    ///
+    /// Note that while the returned ciphertext encrypts the same value as
+    /// either true_ct or false_ct, it won't exactly be true_ct or false_ct.
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let a = 128u8;
+    /// let b = 55u8;
+    ///
+    /// let ct_a = cks.encrypt(a);
+    /// let ct_b = cks.encrypt(b);
+    ///
+    /// let condition = sks.scalar_ge_parallelized(&ct_a, 66);
+    ///
+    /// let ct_res = sks.if_then_else_parallelized(&condition, &ct_a, &ct_b);
+    ///
+    /// // Decrypt:
+    /// let dec: u8 = cks.decrypt(&ct_res);
+    /// assert_eq!(if a >= 66 { a } else { b }, dec);
+    /// assert_ne!(ct_a, ct_res);
+    /// assert_ne!(ct_b, ct_res);
+    /// ```
+    pub fn if_then_else<T>(&self, condition: &BooleanBlock, true_ct: &T, false_ct: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_clones = [None, None];
+        let mut ct_refs = [true_ct, false_ct];
+
+        ct_refs
+            .iter_mut()
+            .zip(ct_clones.iter_mut())
+            .for_each(|(ct_ref, ct_clone)| {
+                if !ct_ref.block_carries_are_empty() {
+                    let mut cloned = ct_ref.clone();
+                    self.full_propagate(&mut cloned);
+                    *ct_ref = ct_clone.insert(cloned);
+                }
+            });
+
+        let [true_ct, false_ct] = ct_refs;
+        self.unchecked_if_then_else(condition, true_ct, false_ct)
+    }
+
+    /// Encrypted CMUX.
+    ///
+    /// It is another name for [Self::if_then_else_parallelized]
+    pub fn cmux<T>(&self, condition: &BooleanBlock, true_ct: &T, false_ct: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.if_then_else(condition, true_ct, false_ct)
+    }
+
+    /// FHE "if then else" selection.
+    ///
+    /// Returns a new ciphertext that encrypts the same value
+    /// as either true_ct or false_ct depending on the value of condition:
+    ///
+    /// - If condition == 1, the returned ciphertext will encrypt the same value as true_ct.
+    /// - If condition == 0, the returned ciphertext will encrypt the same value as false_ct.
+    ///
+    /// To ensure correct results, condition must encrypt either 0 or 1
+    /// (e.g result from a comparison).
+    ///
+    /// Note that while the returned ciphertext encrypts the same value as
+    /// either true_ct or false_ct, it won't exactly be true_ct or false_ct.
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let a = 128u8;
+    /// let b = 55u8;
+    ///
+    /// let mut ct_a = cks.encrypt(a);
+    /// let mut ct_b = cks.encrypt(b);
+    ///
+    /// let mut condition = sks.scalar_ge_parallelized(&ct_a, 66);
+    ///
+    /// let ct_res = sks.smart_if_then_else_parallelized(&mut condition, &mut ct_a, &mut ct_b);
+    ///
+    /// // Decrypt:
+    /// let dec: u8 = cks.decrypt(&ct_res);
+    /// assert_eq!(if a >= 66 { a } else { b }, dec);
+    /// assert_ne!(ct_a, ct_res);
+    /// assert_ne!(ct_b, ct_res);
+    /// ```
+    pub fn smart_if_then_else<T>(
+        &self,
+        condition: &mut BooleanBlock,
+        true_ct: &mut T,
+        false_ct: &mut T,
+    ) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        if !condition.0.carry_is_empty() {
+            let msg_lut = BelfortFpgaLuts::lut_by_name("msg2_extract", &self.key.key.key);
+            let msg_lut_indices = vec![msg_lut];
+            let mut block = vec![condition.0.clone()];
+
+            self.apply_lookup_table_packed_assign(&mut block, &msg_lut_indices);
+
+            condition.0 = block[0].clone();
+        }
+
+        let mut ct_refs = [true_ct, false_ct];
+
+        ct_refs.iter_mut().for_each(|ct_ref| {
+            self.conditional_full_propagate(*ct_ref);
+        });
+
+        let [true_ct, false_ct] = ct_refs;
+        self.unchecked_if_then_else(condition, true_ct, false_ct)
+    }
+
+    /// Encrypted CMUX.
+    ///
+    /// It is another name for [Self::smart_if_then_else_parallelized]
+    pub fn smart_cmux<T>(
+        &self,
+        condition: &mut BooleanBlock,
+        true_ct: &mut T,
+        false_ct: &mut T,
+    ) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.smart_if_then_else(condition, true_ct, false_ct)
+    }
+
+    pub fn unchecked_if_then_else<T>(
+        &self,
+        condition: &BooleanBlock,
+        true_ct: &T,
+        false_ct: &T,
+    ) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let condition_block = &condition.0;
+        let do_clean_message = true;
+        self.unchecked_programmable_if_then_else(
+            condition_block,
+            true_ct,
+            false_ct,
+            |x| x == 1,
+            "predicate".to_owned(),
+            do_clean_message,
+        )
+    }
+
+    pub fn unchecked_cmux<T>(&self, condition: &BooleanBlock, true_ct: &T, false_ct: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.unchecked_if_then_else(condition, true_ct, false_ct)
+    }
+
+    /// if do clean message is false, the resulting ciphertext won't be cleaned (message_extract)
+    /// meaning that yes, the resulting ciphertext's encrypted message is within 0..msg_msg
+    /// but its degree is the same as after adding to ciphertext
+    ///
+    /// TLDR: do_clean_message should be false only if you plan on doing your own PBS
+    /// soon after. (may need to force degree yourself not to trigger asserts)
+    // Note: do_clean_message is needed until degree is used for both
+    // message range and noise management.
+    pub(crate) fn unchecked_programmable_if_then_else<T, F>(
+        &self,
+        condition_block: &Ciphertext,
+        true_ct: &T,
+        false_ct: &T,
+        predicate_function: F,
+        predicate_name: String,
+        do_clean_message: bool,
+    ) -> T
+    where
+        T: IntegerRadixCiphertext,
+        F: Fn(u64) -> bool + Send + Sync + Copy,
+    {
+        let mut true_ct = true_ct.clone();
+        let mut false_ct = false_ct.clone();
+        self.zero_out_if(
+            &mut true_ct,
+            &mut false_ct,
+            predicate_function,
+            predicate_name,
+            condition_block,
+        );
+
+        if do_clean_message {
+            let key = Arc::new(&self.key.key.key);
+            true_ct
+                .blocks_mut()
+                .par_iter_mut()
+                .zip(false_ct.blocks().par_iter())
+                .for_each(|(lhs_block, rhs_block)| {
+                    key.unchecked_add_assign(lhs_block, rhs_block);
+                });
+
+            let num_blocks = true_ct.blocks().len();
+            let msg_lut = BelfortFpgaLuts::lut_by_name("msg2_extract", &key);
+            let msg_lut_indices = vec![msg_lut; num_blocks];
+
+            let mut blocks = true_ct.blocks_mut().to_vec();
+            self.apply_lookup_table_packed_assign(&mut blocks, &msg_lut_indices);
+
+            true_ct
+                .blocks_mut()
+                .par_iter_mut()
+                .zip(blocks.par_iter())
+                .for_each(|(block, vec_block)| {
+                    *block = vec_block.clone();
+                });
+        } else {
+            true_ct
+                .blocks_mut()
+                .iter_mut()
+                .zip(false_ct.blocks().iter())
+                .for_each(|(lhs_block, rhs_block)| {
+                    self.key.key.key.unchecked_add_assign(lhs_block, rhs_block);
+                });
+        }
+        true_ct
+    }
+
+    /// This function takes a ciphertext encrypting any integer value
+    /// and block encrypting a boolean value (0 or 1).
+    ///
+    /// The input integer ciphertext will have all its block zeroed if condition_block
+    /// encrypts 0, otherwise each block keeps its value.
+    pub(crate) fn zero_out_if<T, F>(
+        &self,
+        ct1: &mut T,
+        ct2: &mut T,
+        predicate_function: F,
+        predicate_name: String,
+        condition_block: &Ciphertext,
+    ) where
+        T: IntegerRadixCiphertext,
+        F: Fn(u64) -> bool,
+    {
+        let integer_key = &self.key.key;
+        assert!(condition_block.degree.get() < condition_block.message_modulus.0);
+
+        let inverted_predicate_function = |x| !predicate_function(x);
+
+        if condition_block.degree.get() == 0 {
+            if predicate_function(0u64) {
+                integer_key.create_trivial_zero_assign_radix(ct2);
+            }
+
+            if inverted_predicate_function(0u64) {
+                integer_key.create_trivial_zero_assign_radix(ct1);
+            }
+
+            return;
+        }
+        let num_blocks = ct1.blocks().len();
+
+        let predicate_lut_index = BelfortFpgaLuts::lut_by_name(&predicate_name, &integer_key.key);
+
+        let inverted_predicate_lut_index = BelfortFpgaLuts::lut_by_name(
+            &("inverted_".to_owned() + &predicate_name),
+            &integer_key.key,
+        );
+
+        let mut lut_indices = vec![inverted_predicate_lut_index; num_blocks];
+        lut_indices.extend(vec![predicate_lut_index; num_blocks]);
+
+        let inverted_predicate_lut = integer_key.key.generate_lookup_table_bivariate(|x, y| {
+            if inverted_predicate_function(y) {
+                0
+            } else {
+                x
+            }
+        });
+
+        let predicate_lut = integer_key.key.generate_lookup_table_bivariate(|x, y| {
+            if predicate_function(y) {
+                0
+            } else {
+                x
+            }
+        });
+
+        let condition_vec = vec![condition_block.clone(); num_blocks];
+        let mut prepared_blocks = vec![];
+
+        let ct1_blocks = ct1.blocks_mut();
+        let ct2_blocks = ct2.blocks_mut();
+
+        prepared_blocks.extend(self.prepare_bivariate(
+            &mut ct1_blocks.to_vec(),
+            &condition_vec,
+            &inverted_predicate_lut,
+        ));
+        prepared_blocks.extend(self.prepare_bivariate(
+            &mut ct2_blocks.to_vec(),
+            &condition_vec,
+            &predicate_lut,
+        ));
+
+        self.apply_lookup_table_packed_assign(&mut prepared_blocks, &lut_indices);
+
+        let half_len = prepared_blocks.len() / 2;
+
+        for (i, block) in prepared_blocks.iter().take(half_len).enumerate() {
+            ct1_blocks[i] = block.clone();
+        }
+
+        for (i, block) in prepared_blocks.iter().skip(half_len).enumerate() {
+            ct2_blocks[i] = block.clone();
+        }
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/comparison.rs b/tfhe/src/integer/fpga/server_key/radix/comparison.rs
new file mode 100644
index 00000000..6860fdae
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/comparison.rs
@@ -0,0 +1,247 @@
+use crate::integer::ciphertext::boolean_value::BooleanBlock;
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::comparator::Comparator;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::shortint::Ciphertext;
+
+impl BelfortServerKey {
+    pub fn unchecked_eq<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        assert_eq!(lhs.blocks().len(), rhs.blocks().len());
+
+        let mut result = self.pack_blocks(lhs, rhs);
+
+        self.apply_same_lookup_table_packed_assign(&mut result, "equal_to");
+
+        let is_equal_result: Ciphertext = self.are_all_comparisons_block_true(result);
+
+        BooleanBlock::new_unchecked(is_equal_result)
+    }
+
+    pub fn unchecked_ne<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        assert_eq!(lhs.blocks().len(), rhs.blocks().len());
+
+        let mut result = self.pack_blocks(lhs, rhs);
+
+        self.apply_same_lookup_table_packed_assign(&mut result, "not_equal_to");
+
+        let is_not_equal_result: Ciphertext = self.is_at_least_one_comparisons_block_true(result);
+
+        BooleanBlock::new_unchecked(is_not_equal_result)
+    }
+
+    pub fn unchecked_gt<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).unchecked_gt(lhs, rhs)
+    }
+
+    pub fn unchecked_ge<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).unchecked_ge(lhs, rhs)
+    }
+
+    pub fn unchecked_lt<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).unchecked_lt(lhs, rhs)
+    }
+
+    pub fn unchecked_le<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).unchecked_le(lhs, rhs)
+    }
+
+    pub fn unchecked_max<T>(&self, lhs: &T, rhs: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).unchecked_max(lhs, rhs)
+    }
+
+    pub fn unchecked_min<T>(&self, lhs: &T, rhs: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).unchecked_min(lhs, rhs)
+    }
+
+    pub fn smart_eq<T>(&self, lhs: &mut T, rhs: &mut T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate_bivariate(lhs, rhs);
+
+        self.unchecked_eq(lhs, rhs)
+    }
+
+    pub fn smart_ne<T>(&self, lhs: &mut T, rhs: &mut T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate_bivariate(lhs, rhs);
+
+        self.unchecked_ne(lhs, rhs)
+    }
+
+    pub fn smart_gt<T>(&self, lhs: &mut T, rhs: &mut T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).smart_gt(lhs, rhs)
+    }
+
+    pub fn smart_ge<T>(&self, lhs: &mut T, rhs: &mut T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).smart_ge(lhs, rhs)
+    }
+
+    pub fn smart_lt<T>(&self, lhs: &mut T, rhs: &mut T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).smart_lt(lhs, rhs)
+    }
+
+    pub fn smart_le<T>(&self, lhs: &mut T, rhs: &mut T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).smart_le(lhs, rhs)
+    }
+
+    pub fn smart_max<T>(&self, lhs: &mut T, rhs: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).smart_max(lhs, rhs)
+    }
+
+    pub fn smart_min<T>(&self, lhs: &mut T, rhs: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).smart_min(lhs, rhs)
+    }
+
+    pub fn eq<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_lhs;
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (lhs.block_carries_are_empty(), rhs.block_carries_are_empty()) {
+            (true, true) => (lhs, rhs),
+            (true, false) => {
+                tmp_rhs = rhs.clone();
+                self.full_propagate(&mut tmp_rhs);
+                (lhs, &tmp_rhs)
+            }
+            (false, true) => {
+                tmp_lhs = lhs.clone();
+                self.full_propagate(&mut tmp_lhs);
+                (&tmp_lhs, rhs)
+            }
+            (false, false) => {
+                tmp_lhs = lhs.clone();
+                tmp_rhs = rhs.clone();
+
+                self.full_propagate(&mut tmp_lhs);
+                self.full_propagate(&mut tmp_rhs);
+
+                (&tmp_lhs, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_eq(lhs, rhs)
+    }
+
+    pub fn ne<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_lhs;
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (lhs.block_carries_are_empty(), rhs.block_carries_are_empty()) {
+            (true, true) => (lhs, rhs),
+            (true, false) => {
+                tmp_rhs = rhs.clone();
+                self.full_propagate(&mut tmp_rhs);
+                (lhs, &tmp_rhs)
+            }
+            (false, true) => {
+                tmp_lhs = lhs.clone();
+                self.full_propagate(&mut tmp_lhs);
+                (&tmp_lhs, rhs)
+            }
+            (false, false) => {
+                tmp_lhs = lhs.clone();
+                tmp_rhs = rhs.clone();
+
+                self.full_propagate(&mut tmp_lhs);
+                self.full_propagate(&mut tmp_rhs);
+
+                (&tmp_lhs, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_ne(lhs, rhs)
+    }
+
+    pub fn gt<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).gt(lhs, rhs)
+    }
+
+    pub fn ge<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).ge(lhs, rhs)
+    }
+
+    pub fn lt<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).lt(lhs, rhs)
+    }
+
+    pub fn le<T>(&self, lhs: &T, rhs: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).le(lhs, rhs)
+    }
+
+    pub fn max<T>(&self, lhs: &T, rhs: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).max(lhs, rhs)
+    }
+
+    pub fn min<T>(&self, lhs: &T, rhs: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        Comparator::new(self).min(lhs, rhs)
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/count_zeros_ones.rs b/tfhe/src/integer/fpga/server_key/radix/count_zeros_ones.rs
new file mode 100644
index 00000000..b3ca9dcd
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/count_zeros_ones.rs
@@ -0,0 +1,88 @@
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::integer::server_key::radix_parallel::count_zeros_ones::BitCountKind;
+use crate::integer::{IntegerRadixCiphertext, RadixCiphertext};
+use log::warn;
+
+impl BelfortServerKey {
+    /// Returns the number of ones in the binary representation of `ct`
+    ///
+    /// * ct must not have any carries
+    /// * The returned result has enough blocks to encrypt 32bits (e.g. 1_1 parameters -> 32 blocks,
+    ///   3_3 parameters -> 11 blocks == 33 bits)
+    pub fn unchecked_count_ones<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .unchecked_count_bits_parallelized(ct, BitCountKind::One)
+    }
+
+    /// Returns the number of zeros in the binary representation of `ct`
+    ///
+    /// * ct must not have any carries
+    /// * The returned result has enough blocks to encrypt 32bits (e.g. 1_1 parameters -> 32 blocks,
+    ///   3_3 parameters -> 11 blocks == 33 bits)
+    pub fn unchecked_count_zeros<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .unchecked_count_bits_parallelized(ct, BitCountKind::Zero)
+    }
+
+    /// Returns the number of ones in the binary representation of `ct`
+    ///
+    /// * The returned result has enough blocks to encrypt 32bits (e.g. 1_1 parameters -> 32 blocks,
+    ///   3_3 parameters -> 11 blocks == 33 bits)
+    pub fn smart_count_ones<T>(&self, ct: &mut T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .smart_count_bits_parallelized(ct, BitCountKind::One)
+    }
+
+    /// Returns the number of zeros in the binary representation of `ct`
+    ///
+    /// * The returned result has enough blocks to encrypt 32bits (e.g. 1_1 parameters -> 32 blocks,
+    ///   3_3 parameters -> 11 blocks == 33 bits)
+    pub fn smart_count_zeros<T>(&self, ct: &mut T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .smart_count_bits_parallelized(ct, BitCountKind::Zero)
+    }
+
+    /// Returns the number of ones in the binary representation of `ct`
+    ///
+    /// * The returned result has enough blocks to encrypt 32bits (e.g. 1_1 parameters -> 32 blocks,
+    ///   3_3 parameters -> 11 blocks == 33 bits)
+    pub fn count_ones<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key.key.count_bits_parallelized(ct, BitCountKind::One)
+    }
+
+    /// Returns the number of zeros in the binary representation of `ct`
+    ///
+    /// * The returned result has enough blocks to encrypt 32bits (e.g. 1_1 parameters -> 32 blocks,
+    ///   3_3 parameters -> 11 blocks == 33 bits)
+    pub fn count_zeros<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key.key.count_bits_parallelized(ct, BitCountKind::Zero)
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/div_mod.rs b/tfhe/src/integer/fpga/server_key/radix/div_mod.rs
new file mode 100644
index 00000000..56227409
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/div_mod.rs
@@ -0,0 +1,683 @@
+use crate::core_crypto::fpga::{luts::BelfortLookupTable, BelfortFpgaLuts};
+use crate::integer::ciphertext::{IntegerRadixCiphertext, RadixCiphertext};
+use crate::integer::server_key::comparator::ZeroComparisonType;
+use crate::integer::IntegerCiphertext;
+use crate::shortint::{Ciphertext, MessageModulus};
+use crate::BelfortServerKey;
+
+impl BelfortServerKey {
+    //======================================================================
+    //                Div Rem
+    //======================================================================
+    pub fn unchecked_div_rem<T>(&self, numerator: &T, divisor: &T) -> (T, T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let n = RadixCiphertext::from_blocks(numerator.blocks().to_vec());
+        let d = RadixCiphertext::from_blocks(divisor.blocks().to_vec());
+        let (q, r) = self.unsigned_unchecked_div_rem(&n, &d);
+        let q = T::from_blocks(q.into_blocks());
+        let r = T::from_blocks(r.into_blocks());
+        (q, r)
+    }
+
+    fn unsigned_unchecked_div_rem(
+        &self,
+        numerator: &RadixCiphertext,
+        divisor: &RadixCiphertext,
+    ) -> (RadixCiphertext, RadixCiphertext) {
+        // Pseudocode of the school-book / long-division algorithm:
+        //
+        //
+        // div(N/D):
+        // Q := 0                  -- Initialize quotient and remainder to zero
+        // R := 0
+        // for i := n − 1 .. 0 do  -- Where n is number of bits in N
+        //   R := R << 1           -- Left-shift R by 1 bit
+        //   R(0) := N(i)          -- Set the least-significant bit of R equal to bit i of the
+        //                         -- numerator
+        //   if R ≥ D then
+        //     R := R − D
+        //     Q(i) := 1
+        //   end
+        // end
+        let integer_key = &self.key.key;
+        let shortint_key = &integer_key.key;
+        let message_modulus = integer_key.message_modulus();
+        let carry_modulus = integer_key.carry_modulus();
+
+        assert_eq!(
+            numerator.blocks.len(),
+            divisor.blocks.len(),
+            "numerator and divisor must have same number of blocks \
+            numerator: {} blocks, divisor: {} blocks",
+            numerator.blocks.len(),
+            divisor.blocks.len(),
+        );
+        assert!(
+            message_modulus.0.is_power_of_two(),
+            "The message modulus ({}) needs to be a power of two",
+            message_modulus.0
+        );
+        assert!(
+            numerator.block_carries_are_empty(),
+            "The numerator must have its carries empty"
+        );
+        assert!(
+            divisor.block_carries_are_empty(),
+            "The numerator must have its carries empty"
+        );
+
+        assert!(numerator
+            .blocks()
+            .iter()
+            .all(|block| block.message_modulus == message_modulus
+                && block.carry_modulus == carry_modulus));
+        assert!(divisor
+            .blocks()
+            .iter()
+            .all(|block| block.message_modulus == message_modulus
+                && block.carry_modulus == carry_modulus));
+
+        let num_blocks = numerator.blocks.len();
+        let num_bits_in_message = message_modulus.0.ilog2() as u64;
+        let total_bits = num_bits_in_message * num_blocks as u64;
+
+        let mut quotient: RadixCiphertext = integer_key.create_trivial_zero_radix(num_blocks);
+        let mut remainder1: RadixCiphertext = integer_key.create_trivial_zero_radix(num_blocks);
+        let mut remainder2: RadixCiphertext = integer_key.create_trivial_zero_radix(num_blocks);
+
+        let mut numerator_block_stack = numerator.blocks.clone();
+
+        let merge_overflow_flags_lut = self.generate_overflow_luts();
+
+        for i in (0..total_bits).rev() {
+            let block_of_bit = (i / num_bits_in_message) as usize;
+            let pos_in_block = (i % num_bits_in_message) as usize;
+
+            // msb_bit_set goes from [0 to total_bits - 1]
+            let msb_bit_set = (total_bits - 1 - i) as usize;
+
+            let last_non_trivial_block = msb_bit_set / (num_bits_in_message as usize);
+            // Index to the first block of the remainder that is fully trivial 0
+            // and all blocks after it are also trivial zeros
+            // This number is in range 1..=num_blocks - 1
+            let first_trivial_block = last_non_trivial_block + 1;
+
+            // All blocks starting from the first_trivial_block are known to be trivial
+            // So we can avoid work.
+            // Note that, these are always non-empty (i.e. there is always at least one non trivial
+            // block)
+            let mut interesting_remainder1 =
+                RadixCiphertext::from(remainder1.blocks[..=last_non_trivial_block].to_vec());
+            let mut interesting_remainder2 =
+                RadixCiphertext::from(remainder2.blocks[..=last_non_trivial_block].to_vec());
+            let mut interesting_divisor =
+                RadixCiphertext::from(divisor.blocks[..=last_non_trivial_block].to_vec());
+            let mut divisor_ms_blocks = RadixCiphertext::from(
+                divisor.blocks[((msb_bit_set + 1) / num_bits_in_message as usize)..].to_vec(),
+            );
+
+            let mut blocks = Vec::new();
+            let mut luts = Vec::new();
+
+            // We split the divisor at a block position, when in reality the split should be at a
+            // bit position meaning that potentially (depending on msb_bit_set) the
+            // split versions share some bits they should not. So we do one PBS on the
+            // last block of the interesting_divisor, and first block of divisor_ms_blocks
+            // to trim out bits which should not be there
+
+            if ((msb_bit_set + 1) % num_bits_in_message as usize) != 0 {
+                // The last block of the interesting part of the remainder
+                // can contain bits which we should not account for
+                // we have to zero them out
+                blocks.push(interesting_divisor.blocks.last_mut().unwrap());
+                luts.push(BelfortFpgaLuts::lut_by_name(
+                    "scalar_bitand_one",
+                    &shortint_key,
+                ));
+            }
+
+            if !divisor_ms_blocks.blocks.is_empty()
+                && ((msb_bit_set + 1) % num_bits_in_message as usize) != 0
+            {
+                // As above, we need to zero out some bits, but here it's in the
+                // first block of most significant blocks of the divisor.
+                // The block has the same value as the last block of interesting_divisor.
+                // Here we will zero out the bits that the trim_last_interesting_divisor_bits
+                // above wanted to keep.
+                blocks.push(divisor_ms_blocks.blocks.first_mut().unwrap());
+                luts.push(BelfortFpgaLuts::lut_by_name(
+                    "scalar_bitand_two",
+                    &shortint_key,
+                ));
+            }
+
+            self.apply_lookup_table_mut_packed_assign(&mut blocks, &luts);
+
+            // This does
+            //  R := R << 1; R(0) := N(i)
+            //
+            // We could do that by left shifting R by one, then unchecked_add the correct numerator
+            // bit.
+            //
+            // However, to keep the remainder clean (noise wise), what we do is that we put the
+            // remainder block from which we need to extract the bit, as the LSB of the
+            // Remainder, so that left shifting will pull the bit we need.
+            let numerator_block = numerator_block_stack
+                .pop()
+                .expect("internal error: empty numerator block stack in div");
+            // prepend block and then shift
+            interesting_remainder1.blocks.insert(0, numerator_block);
+            self.unchecked_scalar_left_shift_assign(&mut interesting_remainder1, 1);
+
+            // Extract the block we inserted earlier, and see if it should be dropped
+            // or added back for processing
+            let numerator_block = interesting_remainder1.blocks.remove(0);
+            if pos_in_block != 0 {
+                // We have not yet extracted all the bits from this numerator
+                // so, we put it back on the front so that it gets taken next iteration
+                numerator_block_stack.push(numerator_block);
+            }
+
+            self.unchecked_scalar_left_shift_assign(&mut interesting_remainder2, 1);
+
+            // if interesting_remainder1 != 0 -> interesting_remainder2 == 0
+            // if interesting_remainder1 == 0 -> interesting_remainder2 != 0
+            // In practice interesting_remainder1 contains the numerator bit,
+            // but in that position, interesting_remainder2 always has a 0
+            let mut merged_interesting_remainder = interesting_remainder1;
+
+            self.unchecked_add_assign(&mut merged_interesting_remainder, &interesting_remainder2);
+
+            let (mut new_remainder, subtraction_overflowed) = self
+                .unchecked_unsigned_overflowing_sub(
+                    &merged_interesting_remainder,
+                    &interesting_divisor,
+                );
+
+            // Returns 1 if all divisor upper blocks = 0
+            let at_least_one_upper_block_is_non_zero = {
+                // Do a comparison (==) with 0 for trivial blocks
+                let trivial_blocks = &divisor_ms_blocks.blocks;
+                if trivial_blocks.is_empty() {
+                    shortint_key.create_trivial(0)
+                } else {
+                    // We could call unchecked_scalar_ne_parallelized
+                    // But we are in the special case where scalar == 0
+                    // So we can skip some stuff
+                    let tmp = self
+                        .compare_blocks_with_zero(trivial_blocks, ZeroComparisonType::Difference);
+                    self.is_at_least_one_comparisons_block_true(tmp)
+                }
+            };
+
+            // Creates a cleaned version (noise wise) of the merged remainder
+            // so that it can be safely used in bivariate PBSes
+            self.apply_same_lookup_table_packed_assign(
+                &mut merged_interesting_remainder.blocks,
+                "msg2_extract",
+            );
+
+            let overflow_sum = integer_key.key.unchecked_add(
+                subtraction_overflowed.as_ref(),
+                &at_least_one_upper_block_is_non_zero,
+            );
+
+            // Here, we will do what zero_out_if does, but to stay within noise constraints,
+            // we do it by hand so that we apply the factor (shift) to the correct block
+            //conditionally_zero_out_merged_interesting_remainder
+            assert!(overflow_sum.degree.get() <= 2); // at_least_one_upper_block_is_non_zero maybe be a trivial 0
+            let factor = MessageModulus(overflow_sum.degree.get() + 1);
+
+            let (zero_out_if_overflow_did_not_happen_lut, zero_out_if_overflow_happened_lut) =
+                match factor {
+                    MessageModulus(1) => (
+                        "zero_out_if_overflow_did_not_happen_with_f1",
+                        "zero_out_if_overflow_happened_with_f1",
+                    ),
+                    MessageModulus(2) => (
+                        "zero_out_if_overflow_did_not_happen_with_f2",
+                        "zero_out_if_overflow_happened_with_f2",
+                    ),
+                    MessageModulus(3) => (
+                        "zero_out_if_overflow_did_not_happen_with_f3",
+                        "zero_out_if_overflow_happened_with_f3",
+                    ),
+                    _ => panic!("Unexpected factor value: {:?}", factor),
+                };
+
+            merged_interesting_remainder
+                .blocks_mut()
+                .iter_mut()
+                .for_each(|block| {
+                    shortint_key.unchecked_scalar_mul_assign(block, factor.0 as u8);
+                    shortint_key.unchecked_add_assign(block, &overflow_sum);
+                });
+
+            new_remainder.blocks_mut().iter_mut().for_each(|block| {
+                shortint_key.unchecked_scalar_mul_assign(block, factor.0 as u8);
+                shortint_key.unchecked_add_assign(block, &overflow_sum);
+            });
+
+            let mut did_not_overflow_flag = at_least_one_upper_block_is_non_zero.clone();
+            integer_key
+                .pack_block_assign(subtraction_overflowed.as_ref(), &mut did_not_overflow_flag);
+
+            let cutoff = merged_interesting_remainder.blocks.len();
+
+            let zero_out_if_overflow_did_not_happen_lut = BelfortFpgaLuts::lut_by_name(
+                zero_out_if_overflow_did_not_happen_lut,
+                &shortint_key,
+            );
+            let zero_out_if_overflow_happened_lut =
+                BelfortFpgaLuts::lut_by_name(zero_out_if_overflow_happened_lut, &shortint_key);
+
+            let cleaned_merged_interesting_remainder_luts: Vec<_> = merged_interesting_remainder
+                .blocks
+                .iter()
+                .map(|_| zero_out_if_overflow_did_not_happen_lut.clone())
+                .collect();
+
+            let new_remainder_luts: Vec<_> = new_remainder
+                .blocks
+                .iter()
+                .map(|_| zero_out_if_overflow_happened_lut.clone())
+                .collect();
+
+            // Combine both vectors into a single vector
+            let mut combined_luts: Vec<_> = cleaned_merged_interesting_remainder_luts
+                .into_iter()
+                .chain(new_remainder_luts.into_iter())
+                .collect();
+
+            combined_luts.push(merge_overflow_flags_lut[pos_in_block]);
+
+            // Combine both vectors into a single vector
+            let mut combined_cts: Vec<_> = merged_interesting_remainder
+                .blocks
+                .into_iter()
+                .chain(new_remainder.blocks.into_iter())
+                .collect();
+
+            combined_cts.push(did_not_overflow_flag);
+
+            self.apply_lookup_table_packed_assign(&mut combined_cts, &combined_luts);
+
+            let (cleaned_merged_interesting_remainder, new_remainder, did_not_overflow_flag) = {
+                (
+                    RadixCiphertext::from(combined_cts[0..cutoff].to_vec()),
+                    RadixCiphertext::from(combined_cts[cutoff..combined_cts.len() - 1].to_vec()),
+                    combined_cts.last().unwrap(),
+                )
+            };
+
+            shortint_key
+                .unchecked_add_assign(&mut quotient.blocks[block_of_bit], &did_not_overflow_flag);
+
+            assert_eq!(
+                remainder1.blocks[..first_trivial_block].len(),
+                cleaned_merged_interesting_remainder.blocks.len()
+            );
+            assert_eq!(
+                remainder2.blocks[..first_trivial_block].len(),
+                new_remainder.blocks.len()
+            );
+
+            remainder1.blocks[..first_trivial_block]
+                .iter_mut()
+                .zip(cleaned_merged_interesting_remainder.blocks.iter())
+                .for_each(|(remainder_block, new_value)| {
+                    remainder_block.clone_from(new_value);
+                });
+            remainder2.blocks[..first_trivial_block]
+                .iter_mut()
+                .zip(new_remainder.blocks.iter())
+                .for_each(|(remainder_block, new_value)| {
+                    remainder_block.clone_from(new_value);
+                });
+        }
+
+        // Clean the quotient and remainder
+        // as even though they have no carries, they are not at nominal noise level
+        remainder1
+            .blocks_mut()
+            .iter_mut()
+            .zip(remainder2.blocks.iter())
+            .for_each(|(r1_block, r2_block)| {
+                shortint_key.unchecked_add_assign(r1_block, r2_block);
+            });
+
+        let mut remainder_and_quotient: Vec<Ciphertext> = remainder1
+            .blocks
+            .iter()
+            .chain(quotient.blocks.iter())
+            .cloned()
+            .collect();
+
+        self.apply_same_lookup_table_packed_assign(&mut remainder_and_quotient, "msg2_extract");
+        let (remainder1_arr, quotient_arr) =
+            remainder_and_quotient.split_at(remainder1.blocks.len());
+
+        remainder1 = RadixCiphertext::from(remainder1_arr.to_vec());
+
+        quotient = RadixCiphertext::from(quotient_arr.to_vec());
+
+        (quotient, remainder1)
+    }
+    /// Computes homomorphically the quotient and remainder of the division between two ciphertexts
+    ///
+    /// # Notes
+    ///
+    /// When the divisor is 0:
+    ///
+    /// - For unsigned operands, the returned quotient will be the max value (i.e. all bits set to
+    ///   1),
+    /// the remainder will have the value of the numerator.
+    ///
+    /// - For signed operands, remainder will have the same value as the numerator, and,
+    /// if the numerator is < 0, quotient will be -1 else 1
+    ///
+    /// This behaviour should not be relied on.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2, num_blocks);
+    ///
+    /// let msg1 = 97;
+    /// let msg2 = 14;
+    ///
+    /// let ct1 = cks.encrypt(msg1);
+    /// let ct2 = cks.encrypt(msg2);
+    ///
+    /// // Compute homomorphically the quotient and remainder:
+    /// let (q_res, r_res) = sks.div_rem(&ct1, &ct2);
+    ///
+    /// // Decrypt:
+    /// let q: u64 = cks.decrypt(&q_res);
+    /// let r: u64 = cks.decrypt(&r_res);
+    /// assert_eq!(q, msg1 / msg2);
+    /// assert_eq!(r, msg1 % msg2);
+    /// ```
+    pub fn div_rem<T>(&self, numerator: &T, divisor: &T) -> (T, T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_numerator;
+        let mut tmp_divisor;
+
+        let (numerator, divisor) = match (
+            numerator.block_carries_are_empty(),
+            divisor.block_carries_are_empty(),
+        ) {
+            (true, true) => (numerator, divisor),
+            (true, false) => {
+                tmp_divisor = divisor.clone();
+                self.full_propagate(&mut tmp_divisor);
+                (numerator, &tmp_divisor)
+            }
+            (false, true) => {
+                tmp_numerator = numerator.clone();
+                self.full_propagate(&mut tmp_numerator);
+                (&tmp_numerator, divisor)
+            }
+            (false, false) => {
+                tmp_divisor = divisor.clone();
+                tmp_numerator = numerator.clone();
+                self.full_propagate(&mut tmp_numerator);
+                self.full_propagate(&mut tmp_divisor);
+                (&tmp_numerator, &tmp_divisor)
+            }
+        };
+
+        self.unchecked_div_rem(numerator, divisor)
+    }
+
+    pub fn smart_div_rem<T>(&self, numerator: &mut T, divisor: &mut T) -> (T, T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate_bivariate(numerator, divisor);
+        self.unchecked_div_rem(numerator, divisor)
+    }
+
+    //======================================================================
+    //                Div
+    //======================================================================
+
+    pub fn unchecked_div_assign<T>(&self, numerator: &mut T, divisor: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let (q, _r) = self.unchecked_div_rem(numerator, divisor);
+        *numerator = q;
+    }
+
+    pub fn unchecked_div<T>(&self, numerator: &T, divisor: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let (q, _r) = self.unchecked_div_rem(numerator, divisor);
+        q
+    }
+
+    pub fn smart_div_assign<T>(&self, numerator: &mut T, divisor: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let (q, _r) = self.smart_div_rem(numerator, divisor);
+        *numerator = q;
+    }
+
+    pub fn smart_div<T>(&self, numerator: &mut T, divisor: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let (q, _r) = self.smart_div_rem(numerator, divisor);
+        q
+    }
+
+    pub fn div_assign<T>(&self, numerator: &mut T, divisor: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_divisor;
+
+        let (numerator, divisor) = match (
+            numerator.block_carries_are_empty(),
+            divisor.block_carries_are_empty(),
+        ) {
+            (true, true) => (numerator, divisor),
+            (true, false) => {
+                tmp_divisor = divisor.clone();
+                self.full_propagate(&mut tmp_divisor);
+                (numerator, &tmp_divisor)
+            }
+            (false, true) => {
+                self.full_propagate(numerator);
+                (numerator, divisor)
+            }
+            (false, false) => {
+                tmp_divisor = divisor.clone();
+
+                self.full_propagate(numerator);
+                self.full_propagate(&mut tmp_divisor);
+                (numerator, &tmp_divisor)
+            }
+        };
+
+        let (q, _r) = self.unchecked_div_rem(numerator, divisor);
+        *numerator = q;
+    }
+
+    /// Computes homomorphically the quotient of the division between two ciphertexts
+    ///
+    /// # Note
+    ///
+    /// If you need both the quotient and remainder use [Self::div_rem].
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2, num_blocks);
+    ///
+    /// let msg1 = 97;
+    /// let msg2 = 14;
+    ///
+    /// let ct1 = cks.encrypt(msg1);
+    /// let ct2 = cks.encrypt(msg2);
+    ///
+    /// // Compute homomorphically a division:
+    /// let ct_res = sks.div(&ct1, &ct2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, msg1 / msg2);
+    /// ```
+    pub fn div<T>(&self, numerator: &T, divisor: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let (q, _r) = self.div_rem(numerator, divisor);
+        q
+    }
+
+    //======================================================================
+    //                Rem
+    //======================================================================
+
+    pub fn unchecked_rem_assign<T>(&self, numerator: &mut T, divisor: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let (_q, r) = self.unchecked_div_rem(numerator, divisor);
+        *numerator = r;
+    }
+
+    pub fn unchecked_rem<T>(&self, numerator: &T, divisor: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let (_q, r) = self.unchecked_div_rem(numerator, divisor);
+        r
+    }
+
+    pub fn smart_rem_assign<T>(&self, numerator: &mut T, divisor: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let (_q, r) = self.smart_div_rem(numerator, divisor);
+        *numerator = r;
+    }
+
+    pub fn smart_rem<T>(&self, numerator: &mut T, divisor: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let (_q, r) = self.smart_div_rem(numerator, divisor);
+        r
+    }
+
+    pub fn rem_assign<T>(&self, numerator: &mut T, divisor: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_divisor;
+
+        let (numerator, divisor) = match (
+            numerator.block_carries_are_empty(),
+            divisor.block_carries_are_empty(),
+        ) {
+            (true, true) => (numerator, divisor),
+            (true, false) => {
+                tmp_divisor = divisor.clone();
+                self.full_propagate(&mut tmp_divisor);
+                (numerator, &tmp_divisor)
+            }
+            (false, true) => {
+                self.full_propagate(numerator);
+                (numerator, divisor)
+            }
+            (false, false) => {
+                tmp_divisor = divisor.clone();
+
+                self.full_propagate(numerator);
+                self.full_propagate(&mut tmp_divisor);
+                (numerator, &tmp_divisor)
+            }
+        };
+
+        let (_q, r) = self.unchecked_div_rem(numerator, divisor);
+        *numerator = r;
+    }
+
+    /// Computes homomorphically the remainder (rest) of the division between two ciphertexts
+    ///
+    /// # Note
+    ///
+    /// If you need both the quotient and remainder use [Self::div_rem].
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2, num_blocks);
+    ///
+    /// let msg1 = 97;
+    /// let msg2 = 14;
+    ///
+    /// let ct1 = cks.encrypt(msg1);
+    /// let ct2 = cks.encrypt(msg2);
+    ///
+    /// // Compute homomorphically the remainder:
+    /// let ct_res = sks.rem(&ct1, &ct2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, msg1 % msg2);
+    /// ```
+    pub fn rem<T>(&self, numerator: &T, divisor: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let (_q, r) = self.div_rem(numerator, divisor);
+        r
+    }
+
+    /// The overflow flag is computed by combining 2 separate values,
+    /// this vec will contain the lut that merges these two flags.
+    ///
+    /// Normally only one lut should be needed, and that lut would output a block
+    /// encrypting 0 or 1.
+    /// However, since the resulting block would then be left shifted and added to
+    /// another existing noisy block, we create many LUTs that shift the boolean value
+    /// to the correct position, to reduce noise growth
+    fn generate_overflow_luts(&self) -> Vec<BelfortLookupTable> {
+        let shortint_key = &self.key.key.key;
+
+        let mut merge_overflow_flags_lut_names = vec!["msg_bit0_overflow_flag"];
+        if shortint_key.message_modulus.0 == 4 {
+            merge_overflow_flags_lut_names.push("msg_bit1_overflow_flag");
+        }
+
+        merge_overflow_flags_lut_names
+            .into_iter()
+            .map(|name| BelfortFpgaLuts::lut_by_name(name, &shortint_key))
+            .collect::<Vec<_>>()
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/ilog2.rs b/tfhe/src/integer/fpga/server_key/radix/ilog2.rs
new file mode 100644
index 00000000..8b388032
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/ilog2.rs
@@ -0,0 +1,375 @@
+use crate::integer::fpga::server_key::BelfortFpgaLuts;
+use crate::integer::server_key::radix_parallel::ilog2::{BitValue, Direction};
+use crate::integer::{
+    IntegerCiphertext, IntegerRadixCiphertext, RadixCiphertext, SignedRadixCiphertext,
+};
+use crate::shortint::Ciphertext;
+use crate::BelfortServerKey;
+use log::warn;
+
+impl BelfortServerKey {
+    fn count_consecutive_bits<T>(
+        &self,
+        ct: &T,
+        direction: Direction,
+        bit_value: BitValue,
+    ) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+        if ct.blocks().is_empty() {
+            return integer_key.create_trivial_zero_radix(0);
+        }
+
+        let num_bits_in_message = integer_key.message_modulus().0.ilog2();
+        let num_blocks = ct.blocks().len();
+
+        let num_bits_in_ciphertext = num_bits_in_message
+            .checked_mul(num_blocks as u32)
+            .expect("Number of bits encrypted exceeds u32::MAX");
+
+        let leading_count_per_blocks =
+            self.prepare_count_of_consecutive_bits(ct.clone(), direction, bit_value);
+
+        // `num_bits_in_ciphertext` is the max value to represent
+        // its ilog2 + 1 gives how many bits are required to represent it.
+        let counter_num_blocks = (num_bits_in_ciphertext.ilog2() + 1).div_ceil(num_bits_in_message);
+
+        let cts = leading_count_per_blocks
+            .into_iter()
+            .map(|block| {
+                let mut ct: RadixCiphertext =
+                    integer_key.create_trivial_zero_radix(counter_num_blocks as usize);
+                ct.blocks[0] = block;
+                ct
+            })
+            .collect::<Vec<_>>();
+
+        self.unchecked_sum_ciphertexts_vec(cts)
+            .expect("internal error, empty ciphertext count")
+    }
+
+    fn prepare_count_of_consecutive_bits<T>(
+        &self,
+        ct: T,
+        direction: Direction,
+        bit_value: BitValue,
+    ) -> Vec<Ciphertext>
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+        let message_modulus = integer_key.message_modulus().0;
+        assert!(
+            integer_key.carry_modulus().0 >= message_modulus,
+            "A carry modulus as least as big as the message modulus is required"
+        );
+
+        let mut blocks = ct.into_blocks();
+
+        let lut_name = match (direction, bit_value) {
+            (Direction::Trailing, BitValue::One) => "trailing_bits_one",
+            (Direction::Trailing, BitValue::Zero) => "trailing_bits_zero",
+            (Direction::Leading, BitValue::One) => "leading_bits_one",
+            (Direction::Leading, BitValue::Zero) => "leading_bits_zero",
+        };
+
+        let lut = BelfortFpgaLuts::lut_by_name(lut_name, &integer_key.key);
+        let lut_indexes = vec![lut; blocks.len()];
+        // Assign to each block its number of leading/trailing zeros/ones
+        // in the message space
+
+        self.apply_lookup_table_packed_assign(&mut blocks, &lut_indexes);
+
+        if direction == Direction::Leading {
+            // Our blocks are from lsb to msb
+            // `leading` means starting from the msb, so we reverse block
+            // for the cum sum process done later
+            blocks.reverse();
+        }
+
+        // Use hillis-steele cumulative-sum algorithm
+        // Here, each block either keeps his value (the number of leading zeros)
+        // or becomes 0 if the preceding block
+        // had a bit set to one in it (leading_zeros != num bits in message)
+
+        self.compute_prefix_sum_hillis_steele(
+            blocks,
+            |block_num_bit_count, more_significant_block_bit_count| {
+                if more_significant_block_bit_count == message_modulus.ilog2() as u64 {
+                    block_num_bit_count
+                } else {
+                    0
+                }
+            },
+            "trailing_bits_sum".to_owned(),
+        )
+    }
+
+    //==============================================================================================
+    //  Unchecked
+    //==============================================================================================
+    pub fn unchecked_trailing_zeros<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.count_consecutive_bits(ct, Direction::Trailing, BitValue::Zero)
+    }
+
+    pub fn unchecked_trailing_ones<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.count_consecutive_bits(ct, Direction::Trailing, BitValue::One)
+    }
+
+    pub fn unchecked_leading_zeros<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.count_consecutive_bits(ct, Direction::Leading, BitValue::Zero)
+    }
+
+    pub fn unchecked_leading_ones<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.count_consecutive_bits(ct, Direction::Leading, BitValue::One)
+    }
+
+    /// Returns the base 2 logarithm of the number, rounded down.
+    ///
+    /// See [Self::ilog2_parallelized] for an example
+    ///
+    /// Expects ct to have clean carries
+    pub fn unchecked_ilog2<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+
+        if ct.blocks().is_empty() {
+            return integer_key.create_trivial_zero_radix(ct.blocks().len());
+        }
+
+        let num_bits_in_message = integer_key.message_modulus().0.ilog2();
+        let original_num_blocks = ct.blocks().len();
+
+        let num_bits_in_ciphertext = num_bits_in_message
+            .checked_mul(original_num_blocks as u32)
+            .expect("Number of bits encrypted exceeds u32::MAX");
+
+        // `num_bits_in_ciphertext-1` is the max value we want to represent
+        // its ilog2 + 1 gives use how many bits we need to be able to represent it.
+        // We add `1` to this number as we are going to use signed numbers later
+        //
+        // The ilog2 of a number that is on n bits, is in range 1..=n-1
+        let counter_num_blocks =
+            ((num_bits_in_ciphertext - 1).ilog2() + 1 + 1).div_ceil(num_bits_in_message) as usize;
+
+        // 11111000
+        // x.ilog2() = (x.num_bit() - 1) - x.leading_zeros()
+        // - (x.num_bit() - 1) is trivially known
+        // - we can get leading zeros via a sum
+        //
+        // However, the sum include a full propagation, thus the subtraction
+        // will add another full propagation which is costly.
+        //
+        // However, we can do better:
+        // let N = (x.num_bit() - 1)
+        // let L0 = x.leading_zeros()
+        // ```
+        // x.ilog2() = N - L0
+        // x.ilog2() = -(-(N - L0))
+        // x.ilog2() = -(-N + L0)
+        // ```
+        // Since N is a clear number, getting -N is free,
+        // meaning -N + L0 where L0 is actually `sum(L0[b0], .., L0[num_blocks-1])`
+        // can be done with `sum(-N, L0[b0], .., L0[num_blocks-1]), by switching to signed
+        // numbers.
+        //
+        // Also, to do -(-N + L0) aka -sum(-N, L0[b0], .., L0[num_blocks-1])
+        // we can make the sum not return a fully propagated result,
+        // and extract message/carry blocks while negating them at the same time
+        // using the fact that in twos complement -X = bitnot(X) + 1
+        // so given a non propagated `C`, we can compute the fully propagated `PC`
+        // PC = bitnot(message(C)) + bitnot(blockshift(carry(C), 1)) + 2
+
+        let leading_zeros_per_blocks =
+            self.prepare_count_of_consecutive_bits(ct.clone(), Direction::Leading, BitValue::Zero);
+
+        let mut cts = leading_zeros_per_blocks
+            .into_iter()
+            .map(|block| {
+                let mut ct: SignedRadixCiphertext =
+                    integer_key.create_trivial_zero_radix(counter_num_blocks);
+                ct.blocks[0] = block;
+                ct
+            })
+            .collect::<Vec<_>>();
+        cts.push(
+            integer_key
+                .create_trivial_radix(-(num_bits_in_ciphertext as i32 - 1i32), counter_num_blocks),
+        );
+
+        let result = self
+            .unchecked_partial_sum_ciphertexts_vec(cts)
+            .expect("internal error, empty ciphertext count");
+
+        let msg_lut = BelfortFpgaLuts::lut_by_name("extract_bitnot_msg", &integer_key.key);
+        let carry_lut = BelfortFpgaLuts::lut_by_name("extract_bitnot_carry", &integer_key.key);
+
+        let mut message_blocks = result.blocks().to_vec();
+        let lut_indices = vec![msg_lut; message_blocks.len()];
+        self.apply_lookup_table_packed_assign(&mut message_blocks, &lut_indices);
+
+        let mut carry_blocks = result.blocks()[..counter_num_blocks - 1].to_vec();
+        let lut_indices = vec![carry_lut; carry_blocks.len()];
+        self.apply_lookup_table_packed_assign(&mut carry_blocks, &lut_indices);
+
+        carry_blocks.insert(
+            0,
+            integer_key
+                .key
+                .create_trivial((num_bits_in_message - 1) as u64),
+        );
+        let message = SignedRadixCiphertext::from(message_blocks);
+        let carry = SignedRadixCiphertext::from(carry_blocks);
+        let result = self
+            .sum_ciphertexts(
+                [
+                    message,
+                    carry,
+                    integer_key.create_trivial_radix(2u32, counter_num_blocks),
+                ]
+                .iter(),
+            )
+            .unwrap();
+
+        self.cast_to_unsigned(result, counter_num_blocks)
+    }
+
+    //==============================================================================================
+    //  Default
+    //==============================================================================================
+    pub fn trailing_zeros<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp;
+        let ct = if ct.block_carries_are_empty() {
+            ct
+        } else {
+            tmp = ct.clone();
+            self.full_propagate(&mut tmp);
+            &tmp
+        };
+        self.unchecked_trailing_zeros(ct)
+    }
+
+    pub fn trailing_ones<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp;
+        let ct = if ct.block_carries_are_empty() {
+            ct
+        } else {
+            tmp = ct.clone();
+            self.full_propagate(&mut tmp);
+            &tmp
+        };
+        self.unchecked_trailing_ones(ct)
+    }
+    pub fn leading_zeros<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp;
+        let ct = if ct.block_carries_are_empty() {
+            ct
+        } else {
+            tmp = ct.clone();
+            self.full_propagate(&mut tmp);
+            &tmp
+        };
+        self.unchecked_leading_zeros(ct)
+    }
+
+    pub fn leading_ones<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp;
+        let ct = if ct.block_carries_are_empty() {
+            ct
+        } else {
+            tmp = ct.clone();
+            self.full_propagate(&mut tmp);
+            &tmp
+        };
+        self.unchecked_leading_ones(ct)
+    }
+
+    /// Returns the base 2 logarithm of the number, rounded down.
+    pub fn ilog2<T>(&self, ct: &T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key.key.ilog2_parallelized(ct)
+
+        // TODO: fix ilog2
+        // let mut tmp;
+        // let ct = if ct.block_carries_are_empty() {
+        //     ct
+        // } else {
+        //     tmp = ct.clone();
+        //     self.full_propagate(&mut tmp);
+        //     &tmp
+        // };
+
+        // self.unchecked_ilog2(ct)
+    }
+
+    //==============================================================================================
+    //  Smart
+    //==============================================================================================
+
+    /// See [Self::trailing_zeros]
+    pub fn smart_trailing_zeros<T>(&self, ct: &mut T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_trailing_zeros(ct)
+    }
+
+    /// See [Self::trailing_ones]
+    pub fn smart_trailing_ones<T>(&self, ct: &mut T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_trailing_ones(ct)
+    }
+
+    /// See [Self::leading_zeros]
+    pub fn smart_leading_zeros<T>(&self, ct: &mut T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_leading_zeros(ct)
+    }
+
+    /// See [Self::leading_ones]
+    pub fn smart_leading_ones<T>(&self, ct: &mut T) -> RadixCiphertext
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_leading_ones(ct)
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/mod.rs b/tfhe/src/integer/fpga/server_key/radix/mod.rs
new file mode 100644
index 00000000..45a12853
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/mod.rs
@@ -0,0 +1,152 @@
+use crate::core_crypto::fpga::BelfortFpgaLuts;
+use crate::integer::{
+    IntegerCiphertext, IntegerRadixCiphertext, RadixCiphertext, SignedRadixCiphertext,
+};
+
+use super::BelfortServerKey;
+
+mod abs;
+mod add;
+mod bit_extractor;
+mod bitwise_op;
+mod cmux;
+mod comparison;
+mod count_zeros_ones;
+mod div_mod;
+mod ilog2;
+mod modulus_switch_compression;
+mod mul;
+mod neg;
+mod reverse_bits;
+mod rotate;
+mod scalar_add;
+mod scalar_bitwise_op;
+mod scalar_comparison;
+mod scalar_div_mod;
+mod scalar_mul;
+mod scalar_rotate;
+mod scalar_shift;
+mod scalar_sub;
+mod shift;
+mod slice;
+mod sub;
+mod sum;
+mod vector_comparisons;
+mod vector_find;
+
+#[cfg(test)]
+pub(crate) mod tests;
+
+impl BelfortServerKey {
+    /// Cast a RadixCiphertext or SignedRadixCiphertext to a RadixCiphertext
+    /// with a possibly different number of blocks
+    ///
+    /// # Example
+    ///
+    ///```rust
+    /// use tfhe::integer::{gen_keys_radix, IntegerCiphertext};
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// let num_blocks = 4;
+    ///
+    /// // Generate the client key and the server key:
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg = -2i8;
+    ///
+    /// let ct1 = cks.encrypt_signed(msg);
+    /// assert_eq!(ct1.blocks().len(), 4);
+    ///
+    /// let ct_res = sks.cast_to_unsigned(ct1, 8);
+    /// assert_eq!(ct_res.blocks().len(), 8);
+    ///
+    /// // Decrypt
+    /// let res: u16 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg as u16, res);
+    /// ```
+    pub fn cast_to_unsigned<T: IntegerRadixCiphertext>(
+        &self,
+        mut source: T,
+        target_num_blocks: usize,
+    ) -> RadixCiphertext {
+        if !source.block_carries_are_empty() {
+            self.full_propagate(&mut source);
+        }
+
+        let blocks = source.into_blocks();
+        let current_num_blocks = blocks.len();
+
+        let blocks = if T::IS_SIGNED {
+            // Casting from signed to unsigned
+            // We have to trim or sign extend first
+            if target_num_blocks > current_num_blocks {
+                let mut ct_as_signed_radix = SignedRadixCiphertext::from_blocks(blocks);
+
+                let num_blocks_to_add = target_num_blocks - current_num_blocks;
+                self.extend_radix_with_sign_msb_assign(&mut ct_as_signed_radix, num_blocks_to_add);
+                ct_as_signed_radix.blocks
+            } else {
+                let mut ct_as_unsigned_radix = crate::integer::RadixCiphertext::from_blocks(blocks);
+                let num_blocks_to_remove = current_num_blocks - target_num_blocks;
+                self.trim_radix_blocks_msb_assign(&mut ct_as_unsigned_radix, num_blocks_to_remove);
+                ct_as_unsigned_radix.blocks
+            }
+        } else {
+            // Casting from unsigned to unsigned, this is just about trimming/extending with zeros
+            let mut ct_as_unsigned_radix = crate::integer::RadixCiphertext::from_blocks(blocks);
+            if target_num_blocks > current_num_blocks {
+                let num_blocks_to_add = target_num_blocks - current_num_blocks;
+                self.key
+                    .key
+                    .extend_radix_with_trivial_zero_blocks_msb_assign(
+                        &mut ct_as_unsigned_radix,
+                        num_blocks_to_add,
+                    );
+            } else {
+                let num_blocks_to_remove = current_num_blocks - target_num_blocks;
+                self.trim_radix_blocks_msb_assign(&mut ct_as_unsigned_radix, num_blocks_to_remove);
+            };
+            ct_as_unsigned_radix.blocks
+        };
+
+        assert_eq!(
+            blocks.len(),
+            target_num_blocks,
+            "internal error, wrong number of blocks after casting"
+        );
+        crate::integer::RadixCiphertext::from(blocks)
+    }
+
+    /// Remove MSB blocks from an existing [`RadixCiphertext`]. This can be useful for
+    /// casting operations.
+    pub fn trim_radix_blocks_msb_assign(&self, ct: &mut RadixCiphertext, num_blocks: usize) {
+        let len = ct.blocks.len();
+        ct.blocks.truncate(len - num_blocks);
+        if !ct.block_carries_are_empty() {
+            self.full_propagate(ct);
+        }
+    }
+
+    /// Extends the most significant blocks using the sign bit.
+    /// Used to cast [SignedRadixCiphertext]
+    pub fn extend_radix_with_sign_msb_assign(
+        &self,
+        ct: &mut SignedRadixCiphertext,
+        num_blocks: usize,
+    ) {
+        self.conditional_full_propagate(ct);
+
+        let last_block = ct
+            .blocks
+            .last()
+            .expect("Cannot sign extend an empty ciphertext");
+
+        let mut blocks = vec![last_block.clone()];
+        let padding_creator_lut =
+            BelfortFpgaLuts::lut_by_name("padding_block_creator", &self.key.key.key);
+        self.apply_lookup_table_packed_assign(&mut blocks, &vec![padding_creator_lut]);
+
+        let new_len = num_blocks + ct.blocks.len();
+        ct.blocks.resize(new_len, blocks[0].clone());
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/modulus_switch_compression.rs b/tfhe/src/integer/fpga/server_key/radix/modulus_switch_compression.rs
new file mode 100644
index 00000000..ee61f20c
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/modulus_switch_compression.rs
@@ -0,0 +1,59 @@
+use crate::integer::ciphertext::{
+    BaseRadixCiphertext, BaseSignedRadixCiphertext, CompressedModulusSwitchedRadixCiphertext,
+    CompressedModulusSwitchedSignedRadixCiphertext,
+};
+use crate::integer::{RadixCiphertext, SignedRadixCiphertext};
+use crate::BelfortServerKey;
+use log::warn;
+
+impl BelfortServerKey {
+    pub fn switch_modulus_and_compress(
+        &self,
+        ct: &RadixCiphertext,
+    ) -> CompressedModulusSwitchedRadixCiphertext {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        CompressedModulusSwitchedRadixCiphertext(
+            self.key
+                .key
+                .switch_modulus_and_compress_generic_parallelized(&ct.blocks),
+        )
+    }
+
+    pub fn decompress(
+        &self,
+        compressed_ct: &CompressedModulusSwitchedRadixCiphertext,
+    ) -> RadixCiphertext {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        BaseRadixCiphertext {
+            blocks: self
+                .key
+                .key
+                .decompress_generic_parallelized(&compressed_ct.0),
+        }
+    }
+
+    pub fn switch_modulus_and_compress_signed(
+        &self,
+        ct: &SignedRadixCiphertext,
+    ) -> CompressedModulusSwitchedSignedRadixCiphertext {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        CompressedModulusSwitchedSignedRadixCiphertext(
+            self.key
+                .key
+                .switch_modulus_and_compress_generic_parallelized(&ct.blocks),
+        )
+    }
+
+    pub fn decompress_signed(
+        &self,
+        compressed_ct: &CompressedModulusSwitchedSignedRadixCiphertext,
+    ) -> SignedRadixCiphertext {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        BaseSignedRadixCiphertext {
+            blocks: self
+                .key
+                .key
+                .decompress_generic_parallelized(&compressed_ct.0),
+        }
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/mul.rs b/tfhe/src/integer/fpga/server_key/radix/mul.rs
new file mode 100644
index 00000000..210c2683
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/mul.rs
@@ -0,0 +1,783 @@
+use log::warn;
+
+use crate::core_crypto::fpga::luts::BelfortLookupTable;
+use crate::core_crypto::fpga::BelfortFpgaLuts;
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::integer::{BooleanBlock, RadixCiphertext};
+use crate::shortint::Ciphertext;
+use std::rc::Rc;
+
+impl BelfortServerKey {
+    /// Computes homomorphically a multiplication between a ciphertext encrypting an integer value
+    /// and another encrypting a shortint value.
+    ///
+    /// This function computes the operation without checking if it exceeds the capacity of the
+    /// ciphertext.
+    ///
+    /// The result is assigned to the `ct_left` ciphertext.
+    ///
+    /// # Warning
+    ///
+    /// - Multithreaded
+    ///
+    /// # Example
+    ///
+    ///```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let clear_1 = 170;
+    /// let clear_2 = 3;
+    ///
+    /// // Encrypt two messages
+    /// let mut ct_left = cks.encrypt(clear_1);
+    /// let ct_right = cks.encrypt_one_block(clear_2);
+    ///
+    /// // Compute homomorphically a multiplication
+    /// sks.unchecked_block_mul_assign(&mut ct_left, &ct_right, 0);
+    ///
+    /// // Decrypt
+    /// let res: u64 = cks.decrypt(&ct_left);
+    /// assert_eq!((clear_1 * clear_2) % 256, res);
+    /// ```
+    pub fn unchecked_block_mul_assign<T>(
+        &self,
+        ct_left: &mut T,
+        ct_right: &crate::shortint::Ciphertext,
+        index: usize,
+    ) where
+        T: IntegerRadixCiphertext,
+    {
+        *ct_left = self.unchecked_block_mul(ct_left, ct_right, index);
+    }
+
+    /// Computes homomorphically a multiplication between a ciphertexts encrypting an integer
+    /// value and another encrypting a shortint value.
+    ///
+    /// This function computes the operation without checking if it exceeds the capacity of the
+    /// ciphertext.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    ///
+    /// # Example
+    ///
+    ///```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let clear_1 = 55;
+    /// let clear_2 = 3;
+    ///
+    /// // Encrypt two messages
+    /// let ct_left = cks.encrypt(clear_1);
+    /// let ct_right = cks.encrypt_one_block(clear_2);
+    ///
+    /// // Compute homomorphically a multiplication
+    /// let ct_res = sks.unchecked_block_mul(&ct_left, &ct_right, 0);
+    ///
+    /// // Decrypt
+    /// let res: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!((clear_1 * clear_2) % 256, res);
+    /// ```
+    pub fn unchecked_block_mul<T>(
+        &self,
+        ct1: &T,
+        ct2: &crate::shortint::Ciphertext,
+        index: usize,
+    ) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        let shifted_ct = self.blockshift(ct1, index);
+
+        let mut result_lsb = shifted_ct.clone();
+        let mut result_msb = shifted_ct;
+        self.key.key.unchecked_block_mul_lsb_msb_parallelized(
+            &mut result_lsb,
+            &mut result_msb,
+            ct2,
+            index,
+        );
+        result_msb = self.blockshift(&result_msb, 1);
+
+        self.unchecked_add(&result_lsb, &result_msb)
+    }
+
+    /// Computes homomorphically a multiplication between a ciphertext encrypting integer value
+    /// and another encrypting a shortint value.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// # Warning
+    ///
+    /// - Multithreaded
+    ///
+    /// # Example
+    ///
+    ///```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let clear_1 = 170;
+    /// let clear_2 = 3;
+    ///
+    /// // Encrypt two messages
+    /// let mut ctxt_1 = cks.encrypt(clear_1);
+    /// let mut ctxt_2 = cks.encrypt_one_block(clear_2);
+    ///
+    /// // Compute homomorphically a multiplication
+    /// let ct_res = sks.smart_block_mul(&mut ctxt_1, &mut ctxt_2, 0);
+    ///
+    /// // Decrypt
+    /// let res: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!((clear_1 * clear_2) % 256, res);
+    /// ```
+    // by convention smart operations take mut refs to their inputs, even if they do not modify them
+    #[allow(clippy::needless_pass_by_ref_mut)]
+    pub fn smart_block_mul<T>(
+        &self,
+        ct1: &mut T,
+        ct2: &mut crate::shortint::Ciphertext,
+        index: usize,
+    ) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        // Makes sure we can do the multiplications
+        self.full_propagate(ct1);
+
+        let shifted_ct = self.blockshift(ct1, index);
+
+        let mut result_lsb = shifted_ct.clone();
+        let mut result_msb = shifted_ct;
+        self.key.key.unchecked_block_mul_lsb_msb_parallelized(
+            &mut result_lsb,
+            &mut result_msb,
+            ct2,
+            index,
+        );
+        result_msb = self.blockshift(&result_msb, 1);
+
+        self.smart_add(&mut result_lsb, &mut result_msb)
+    }
+
+    pub fn smart_block_mul_assign<T>(
+        &self,
+        ct1: &mut T,
+        ct2: &mut crate::shortint::Ciphertext,
+        index: usize,
+    ) where
+        T: IntegerRadixCiphertext,
+    {
+        *ct1 = self.smart_block_mul(ct1, ct2, index);
+    }
+
+    /// Computes homomorphically a multiplication between a ciphertext encrypting integer value
+    /// and another encrypting a shortint value.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Warning
+    ///
+    /// - Multithreaded
+    ///
+    /// # Example
+    ///
+    ///```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let clear_1 = 170;
+    /// let clear_2 = 3;
+    ///
+    /// // Encrypt two messages
+    /// let ctxt_1 = cks.encrypt(clear_1);
+    /// let ctxt_2 = cks.encrypt_one_block(clear_2);
+    ///
+    /// // Compute homomorphically a multiplication
+    /// let ct_res = sks.block_mul(&ctxt_1, &ctxt_2, 0);
+    ///
+    /// // Decrypt
+    /// let res: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!((clear_1 * clear_2) % 256, res);
+    /// ```
+    pub fn block_mul<T>(&self, ct1: &T, ct2: &crate::shortint::Ciphertext, index: usize) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct1.clone();
+        self.block_mul_assign(&mut ct_res, ct2, index);
+        ct_res
+    }
+
+    pub fn block_mul_assign<T>(&self, ct1: &mut T, ct2: &crate::shortint::Ciphertext, index: usize)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_rhs: crate::shortint::Ciphertext;
+        let shortint_key = &self.key.key.key;
+        let (lhs, rhs) = match (ct1.block_carries_are_empty(), ct2.carry_is_empty()) {
+            (true, true) => (ct1, ct2),
+            (true, false) => {
+                tmp_rhs = ct2.clone();
+                shortint_key.message_extract_assign(&mut tmp_rhs);
+                (ct1, &tmp_rhs)
+            }
+            (false, true) => {
+                self.full_propagate(ct1);
+                (ct1, ct2)
+            }
+            (false, false) => {
+                tmp_rhs = ct2.clone();
+                // TODO: parallelize full_propagate & message_extract
+                self.full_propagate(ct1);
+                shortint_key.message_extract_assign(&mut tmp_rhs);
+                (ct1, &tmp_rhs)
+            }
+        };
+        self.unchecked_block_mul_assign(lhs, rhs, index);
+        self.full_propagate(lhs);
+    }
+
+    /// Computes homomorphically a multiplication between two ciphertexts encrypting integer values.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked)
+    /// checks that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let clear_1 = 170;
+    /// let clear_2 = 6;
+    ///
+    /// // Encrypt two messages
+    /// let ctxt_1 = cks.encrypt(clear_1);
+    /// let ctxt_2 = cks.encrypt(clear_2);
+    ///
+    /// // Compute homomorphically a multiplication
+    /// let ct_res = sks.mul(&ctxt_1, &ctxt_2);
+    /// // Decrypt
+    /// let res: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!((clear_1 * clear_2) % 256, res);
+    /// ```
+    pub fn mul<T>(&self, lhs: &T, rhs: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = lhs.clone();
+        self.mul_assign(&mut ct_res, rhs);
+        ct_res
+    }
+
+    pub fn mul_assign<T>(&self, lhs: &mut T, rhs: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (lhs.block_carries_are_empty(), rhs.block_carries_are_empty()) {
+            (true, true) => (lhs, rhs),
+            (true, false) => {
+                tmp_rhs = rhs.clone();
+                self.full_propagate(&mut tmp_rhs);
+                (lhs, &tmp_rhs)
+            }
+            (false, true) => {
+                self.full_propagate(lhs);
+                (lhs, rhs)
+            }
+            (false, false) => {
+                tmp_rhs = rhs.clone();
+                self.full_propagate(lhs);
+                self.full_propagate(&mut tmp_rhs);
+                (lhs, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_mul_assign(lhs, rhs);
+    }
+
+    /// Smart_mul always checks whether there is a need for full_propagate() and
+    /// continues by performing the multiplication.
+    pub fn smart_mul<T>(&self, lhs: &mut T, rhs: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate_bivariate(lhs, rhs);
+        self.unchecked_mul(lhs, rhs)
+    }
+
+    pub fn smart_mul_assign<T>(&self, lhs: &mut T, rhs: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate_bivariate(lhs, rhs);
+        self.unchecked_mul_assign(lhs, rhs);
+    }
+
+    pub fn unchecked_unsigned_overflowing_mul(
+        &self,
+        lhs: &RadixCiphertext,
+        rhs: &RadixCiphertext,
+    ) -> (RadixCiphertext, BooleanBlock) {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .unchecked_unsigned_overflowing_mul_parallelized(lhs, rhs)
+    }
+
+    pub fn unchecked_unsigned_overflowing_mul_assign(
+        &self,
+        lhs: &mut RadixCiphertext,
+        rhs: &RadixCiphertext,
+    ) -> BooleanBlock {
+        let (result, overflowed) = self.unchecked_unsigned_overflowing_mul(lhs, rhs);
+        *lhs = result;
+        overflowed
+    }
+
+    /// Computes homomorphically a multiplication along with an overflow flag
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let clear_1 = 128u8;
+    /// let clear_2 = 5u8;
+    ///
+    /// // Encrypt two messages
+    /// let ctxt_1 = cks.encrypt(clear_1);
+    /// let ctxt_2 = cks.encrypt(clear_2);
+    ///
+    /// // Compute homomorphically a multiplication
+    /// let (ct_res, ct_overflowed) = sks.unsigned_overflowing_mul(&ctxt_1, &ctxt_2);
+    /// // Decrypt
+    /// let res: u8 = cks.decrypt(&ct_res);
+    /// let overflowed = cks.decrypt_bool(&ct_overflowed);
+    ///
+    /// let (expected_result, expected_overflowed) = clear_1.overflowing_mul(clear_2);
+    /// assert_eq!(res, expected_result);
+    /// assert_eq!(overflowed, expected_overflowed);
+    /// ```
+    pub fn unsigned_overflowing_mul(
+        &self,
+        ct1: &RadixCiphertext,
+        ct2: &RadixCiphertext,
+    ) -> (RadixCiphertext, BooleanBlock) {
+        let mut ct_res = ct1.clone();
+        let overflowed = self.unsigned_overflowing_mul_assign(&mut ct_res, ct2);
+        (ct_res, overflowed)
+    }
+
+    pub fn unsigned_overflowing_mul_assign(
+        &self,
+        ct1: &mut RadixCiphertext,
+        ct2: &RadixCiphertext,
+    ) -> BooleanBlock {
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (ct1.block_carries_are_empty(), ct2.block_carries_are_empty()) {
+            (true, true) => (ct1, ct2),
+            (true, false) => {
+                tmp_rhs = ct2.clone();
+                self.full_propagate(&mut tmp_rhs);
+                (ct1, &tmp_rhs)
+            }
+            (false, true) => {
+                self.full_propagate(ct1);
+                (ct1, ct2)
+            }
+            (false, false) => {
+                tmp_rhs = ct2.clone();
+                self.full_propagate(ct1);
+                self.full_propagate(&mut tmp_rhs);
+                (ct1, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_unsigned_overflowing_mul_assign(lhs, rhs)
+    }
+
+    /// Computes homomorphically a multiplication between two ciphertexts encrypting integer values.
+    ///
+    /// This function computes the operation without checking if it exceeds the capacity of the
+    /// ciphertext.
+    ///
+    /// The result is assigned to the `ct_left` ciphertext.
+    ///
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let clear_1 = 255;
+    /// let clear_2 = 143;
+    ///
+    /// // Encrypt two messages
+    /// let mut ctxt_1 = cks.encrypt(clear_1);
+    /// let ctxt_2 = cks.encrypt(clear_2);
+    ///
+    /// // Compute homomorphically a multiplication
+    /// let ct_res = sks.unchecked_mul(&mut ctxt_1, &ctxt_2);
+    ///
+    /// // Decrypt
+    /// let res: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!((clear_1 * clear_2) % 256, res);
+    /// ```
+    pub fn unchecked_mul<T>(&self, lhs: &T, rhs: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = lhs.clone();
+        self.unchecked_mul_assign(&mut ct_res, rhs);
+        ct_res
+    }
+
+    pub fn unchecked_mul_assign<T>(&self, lhs: &mut T, rhs: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+        if rhs.holds_boolean_value() {
+            integer_key.zero_out_if_condition_is_false(lhs, &rhs.blocks()[0]);
+            return;
+        }
+
+        if lhs.holds_boolean_value() {
+            let mut cloned_rhs = rhs.clone();
+            integer_key.zero_out_if_condition_is_false(&mut cloned_rhs, &lhs.blocks()[0]);
+            *lhs = cloned_rhs;
+            return;
+        }
+
+        self.compute_terms_for_mul_low(lhs, rhs);
+    }
+
+    /// This functions computes the terms resulting from multiplying each block
+    /// of rhs with lhs. When summed these terms will give the low part of the result.
+    /// i.e. in a (lhs: Nbit * rhs: Nbit) multiplication, summing the terms will give a N bit result
+    /// This function is written to exploit the available parallellism on fpga
+    fn compute_terms_for_mul_low<T>(&self, lhs: &mut T, rhs: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+        let shortint_key = &integer_key.key;
+        let message_modulus = integer_key.message_modulus().0;
+        let max_index = lhs.blocks().len() - 1;
+
+        let mut ciphertexts: Vec<Ciphertext> = vec![];
+        let mut luts: Vec<BelfortLookupTable> = vec![];
+        let mut block_indexes: Vec<usize> = vec![];
+
+        let lut_index_mult_2lsb = BelfortFpgaLuts::lut_by_name("mult_2lsb", shortint_key);
+        let lut_index_mult_2msb = BelfortFpgaLuts::lut_by_name("mult_2msb", shortint_key);
+
+        let lsb_block_mul_lut = Rc::new(
+            shortint_key.generate_lookup_table_bivariate(|x, y| (x * y) % message_modulus as u64),
+        );
+        let msb_block_mul_lut = Rc::new(
+            shortint_key.generate_lookup_table_bivariate(|x, y| (x * y) / message_modulus as u64),
+        );
+
+        let multiplication_iter = rhs
+            .blocks()
+            .iter()
+            .enumerate()
+            .filter(|(_, block)| block.degree.get() != 0)
+            .flat_map(|(index_rhs, block_rhs)| {
+                let lsb_block_mul_lut = Rc::clone(&lsb_block_mul_lut);
+                // Further blocks will overflow as computation happens in modulo
+                lhs.blocks()[0..=max_index - index_rhs]
+                    .iter()
+                    .enumerate()
+                    .filter(|(_, block_lhs)| block_lhs.degree.get() != 0)
+                    .map(move |(index_lhs, bl_lhs)| {
+                        let mut block_lhs = bl_lhs.clone();
+                        // Combines the two blocks to serve as an input for LUT of multiplication
+                        shortint_key.unchecked_apply_lookup_table_bivariate_assign_prep(
+                            &mut block_lhs,
+                            block_rhs,
+                            &Rc::clone(&lsb_block_mul_lut),
+                        );
+                        (block_lhs, lut_index_mult_2lsb, index_rhs + index_lhs)
+                    })
+            });
+
+        let multiplication_terms: Vec<(Ciphertext, BelfortLookupTable, usize)>;
+
+        // The modulus defines the number of bits of the message.
+        // If the modulus is smaller than 2, the carry won't overflow,
+        // since the message is either 0 or 1.
+        if message_modulus > 2 {
+            multiplication_terms = multiplication_iter
+                .chain(
+                    rhs.blocks()[..rhs.blocks().len() - 1]
+                        .iter()
+                        .enumerate()
+                        .filter(|(_, block)| block.degree.get() != 0)
+                        .flat_map(|(index_rhs, block_rhs)| {
+                            let msb_block_mul_lut = Rc::clone(&msb_block_mul_lut);
+                            lhs.blocks()[0..=max_index - index_rhs - 1]
+                                .iter()
+                                .enumerate()
+                                .filter(|(_, block_lhs)| block_lhs.degree.get() != 0)
+                                .map(move |(index_lhs, bl_lhs)| {
+                                    let mut block_lhs = bl_lhs.clone();
+
+                                    shortint_key
+                                        .unchecked_apply_lookup_table_bivariate_assign_prep(
+                                            &mut block_lhs,
+                                            block_rhs,
+                                            &Rc::clone(&msb_block_mul_lut),
+                                        );
+                                    (block_lhs, lut_index_mult_2msb, index_rhs + index_lhs + 1)
+                                })
+                        }),
+                )
+                .collect();
+        } else {
+            multiplication_terms = multiplication_iter.collect();
+        }
+
+        multiplication_terms
+            .into_iter()
+            .for_each(|(ct, lut, index)| {
+                ciphertexts.push(ct);
+                luts.push(lut);
+                block_indexes.push(index);
+            });
+
+        let mut to_add: Vec<Vec<&mut Ciphertext>> = self.execute_short_int_multiplications(
+            &mut ciphertexts,
+            luts,
+            block_indexes,
+            max_index,
+        );
+
+        self.adder_tree_assign_batched(&mut to_add);
+
+        let result_blocks: Vec<&mut Ciphertext> = to_add.into_iter().flatten().collect();
+        lhs.blocks_mut()
+            .iter_mut()
+            .enumerate()
+            .for_each(|(index, block)| {
+                *block = result_blocks[index].clone();
+            });
+    }
+
+    fn adder_tree_assign_batched<'a>(&self, input_list: &mut Vec<Vec<&'a mut Ciphertext>>) {
+        let shortint_key = &self.key.key.key;
+
+        let max_additions_per_slot = self.calculate_addition_size();
+        let max_index = input_list.len() - 1;
+
+        let mut ready_index = 0; // index of the first column that still has work left
+        let mut current_index; // index of the slot where we now look for extra bootstraps
+        let pbs_slots_parallel = 32; // TODO: determine best value (32, 64 or 84) with script depending on FPGA parallelism
+
+        let mut ciphertext_stack =
+            Vec::<(&mut Ciphertext, usize, BelfortLookupTable)>::with_capacity(pbs_slots_parallel);
+        let mut take_amount;
+
+        let msg_extract = BelfortFpgaLuts::lut_by_name("msg2_extract", shortint_key);
+        let carry_extract = BelfortFpgaLuts::lut_by_name("carry2_extract", shortint_key);
+
+        while ready_index <= max_index {
+            let mut pbs_slots_open = pbs_slots_parallel;
+            current_index = ready_index;
+
+            while current_index <= max_index && pbs_slots_open > 0 {
+                let input_column = &mut input_list[current_index as usize];
+
+                let max_additions = if current_index == max_index {
+                    pbs_slots_open * max_additions_per_slot
+                } else {
+                    // If not at the highest index, every set of inputs results in two PBS: msg and
+                    // carry extract
+                    (pbs_slots_open / 2) * max_additions_per_slot
+                };
+
+                take_amount = input_column.len().min(max_additions);
+                let mut slots_filled = take_amount / max_additions_per_slot;
+
+                if current_index == ready_index {
+                    // The first unfinished column needs to be processed first.
+                    // Carries might be added for the following columns, which can result in extra
+                    // filled slots.
+                    let has_partial_slot = (take_amount % max_additions_per_slot) > 1;
+                    slots_filled += has_partial_slot as usize;
+
+                    if slots_filled == 0 {
+                        // All work is done for the current column
+                        ready_index += 1;
+                    } else {
+                        // Inside the first unfinished column - Full slots
+                        for _ in 0..slots_filled - 1 {
+                            let res = input_column.pop().unwrap();
+                            let second_res = input_column.pop().unwrap();
+                            shortint_key.unchecked_add_assign(res, second_res);
+                            for _ in 0..(max_additions_per_slot - 2) {
+                                shortint_key.unchecked_add_assign(res, input_column.pop().unwrap());
+                            }
+                            res.clone_into(second_res);
+                            ciphertext_stack.push((res, current_index, msg_extract));
+                            if current_index != max_index {
+                                ciphertext_stack.push((
+                                    second_res,
+                                    current_index + 1,
+                                    carry_extract,
+                                ));
+                            }
+                            take_amount -= max_additions_per_slot;
+                        }
+
+                        // Partial slots
+                        let res = input_column.pop().unwrap();
+                        let second_res = input_column.pop().unwrap();
+                        shortint_key.unchecked_add_assign(res, second_res);
+                        for _ in 0..(take_amount.min(max_additions_per_slot) - 2) {
+                            shortint_key.unchecked_add_assign(res, input_column.pop().unwrap());
+                        }
+                        res.clone_into(second_res);
+                        ciphertext_stack.push((res, current_index, msg_extract));
+                        if current_index != max_index {
+                            ciphertext_stack.push((second_res, current_index + 1, carry_extract));
+                        }
+                    }
+                } else {
+                    // Only take full slots if previous columns could still carry over carries
+                    for _ in 0..slots_filled {
+                        let res = input_column.pop().unwrap();
+                        let second_res = input_column.pop().unwrap();
+                        shortint_key.unchecked_add_assign(res, second_res);
+                        for _ in 0..(max_additions_per_slot - 2) {
+                            shortint_key.unchecked_add_assign(res, input_column.pop().unwrap());
+                        }
+                        res.clone_into(second_res);
+                        ciphertext_stack.push((res, current_index, msg_extract));
+                        if current_index != max_index {
+                            ciphertext_stack.push((second_res, current_index + 1, carry_extract));
+                        }
+                    }
+                }
+
+                if current_index == max_index {
+                    pbs_slots_open -= slots_filled;
+                } else {
+                    // Every operation counts twice (msg and carry)
+                    pbs_slots_open -= 2 * slots_filled;
+                }
+                current_index += 1;
+            }
+
+            let mut luts: Vec<BelfortLookupTable> = Vec::with_capacity(ciphertext_stack.len());
+            let mut ciphertexts: Vec<Ciphertext> = ciphertext_stack
+                .iter()
+                .map(|(ct, _, lut)| {
+                    luts.push(*lut);
+                    (*ct).clone()
+                })
+                .collect();
+
+            if ciphertext_stack.len() > 0 {
+                self.apply_lookup_table_packed_assign(&mut ciphertexts, &luts);
+            }
+
+            ciphertext_stack
+                .iter_mut()
+                .enumerate()
+                .for_each(|(index, ct)| ciphertexts[index].clone_into(ct.0));
+
+            for _ in 0..ciphertext_stack.len() {
+                let (ct, index, _) = ciphertext_stack.pop().unwrap();
+                input_list[index].push(ct);
+            }
+        }
+    }
+
+    fn calculate_addition_size(&self) -> usize {
+        let integer_key = &self.key.key;
+        let carry_modulus = integer_key.carry_modulus().0;
+        let message_modulus = integer_key.message_modulus().0;
+
+        let total_modulus = message_modulus * carry_modulus;
+        let message_max = message_modulus - 1;
+        (total_modulus - 1) / message_max
+    }
+
+    fn execute_short_int_multiplications<'a>(
+        &'a self,
+        ciphertexts: &'a mut Vec<Ciphertext>,
+        luts: Vec<BelfortLookupTable>,
+        block_indexes: Vec<usize>,
+        max_index: usize,
+    ) -> Vec<Vec<&'a mut Ciphertext>> {
+        let mut to_add: Vec<Vec<&'a mut Ciphertext>> = Vec::with_capacity(max_index + 1);
+        for _ in 0..=max_index {
+            to_add.push(Vec::new());
+        }
+
+        self.apply_lookup_table_packed_assign(ciphertexts, &luts);
+
+        for (ct, block_index) in ciphertexts.iter_mut().zip(block_indexes) {
+            to_add[block_index].push(ct);
+        }
+
+        to_add
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/neg.rs b/tfhe/src/integer/fpga/server_key/radix/neg.rs
new file mode 100644
index 00000000..4549d3d5
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/neg.rs
@@ -0,0 +1,132 @@
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::BelfortServerKey;
+
+impl BelfortServerKey {
+    /// Homomorphically computes the opposite of a ciphertext encrypting an integer message.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 1u64;
+    /// let mut ctxt = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a negation
+    /// let ct_res = sks.smart_neg_parallelized(&mut ctxt);
+    ///
+    /// // Decrypt
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(255, dec);
+    /// ```
+    pub fn smart_neg<T>(&self, ctxt: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+        if integer_key.is_neg_possible(ctxt).is_err() {
+            self.full_propagate(ctxt);
+        }
+        integer_key.is_neg_possible(ctxt).unwrap();
+        integer_key.unchecked_neg(ctxt)
+    }
+
+    /// Homomorphically computes the opposite of a ciphertext encrypting an integer message.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 1u64;
+    ///
+    /// // Encrypt two messages:
+    /// let mut ctxt = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a negation
+    /// let ct_res = sks.neg_parallelized(&mut ctxt);
+    ///
+    /// // Decrypt
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(255, dec);
+    /// ```
+    pub fn neg<T>(&self, ctxt: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+        let mut tmp_ctxt;
+
+        let ct = if ctxt.block_carries_are_empty() {
+            ctxt
+        } else {
+            tmp_ctxt = ctxt.clone();
+            self.full_propagate(&mut tmp_ctxt);
+            &tmp_ctxt
+        };
+
+        if integer_key.is_eligible_for_parallel_single_carry_propagation(ct.blocks().len()) {
+            let mut ct = integer_key.unchecked_neg(ct);
+            self.propagate_single_carry_parallelized_low_latency(ct.blocks_mut());
+            ct
+        } else {
+            let mut ct = integer_key.unchecked_neg(ct);
+            integer_key.full_propagate(&mut ct);
+            ct
+        }
+    }
+    /// This neg_assign two numbers
+    ///
+    /// It is after the Blelloch algorithm to do
+    /// prefix sum / cumulative sum in parallel.
+    ///
+    /// It is not "work efficient" as in, it does not adds
+    /// that much work compared to other parallel algorithm,
+    /// thus requiring less threads.
+    ///
+    /// However it is slower.
+    ///
+    /// At most num_block / 2 threads are used
+    ///
+    /// # Requirements
+    ///
+    /// - The parameters have 4 bits in total
+    /// - Adding rhs to lhs must not consume more than one carry
+    ///
+    /// # Output
+    ///
+    /// - lhs will have its carries empty
+    pub fn neg_work_efficient<T>(&self, ctxt: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ctxt.clone();
+        self.conditional_full_propagate(&mut ct_res);
+        self.key.key.unchecked_neg_assign(&mut ct_res);
+        self.full_propagate_work_efficient(&mut ct_res);
+        ct_res
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/reverse_bits.rs b/tfhe/src/integer/fpga/server_key/radix/reverse_bits.rs
new file mode 100644
index 00000000..72745bec
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/reverse_bits.rs
@@ -0,0 +1,37 @@
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use log::warn;
+
+impl BelfortServerKey {
+    /// Reverse the bits of the integer
+    ///
+    /// # Example
+    ///
+    ///```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// let num_blocks = 4;
+    ///
+    /// // Generate the client key and the server key:
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg = 0b10110100_u8;
+    ///
+    /// let ct = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically an addition:
+    /// let ct_res = sks.reverse_bits(&ct);
+    ///
+    /// // Decrypt:
+    /// let res: u8 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg.reverse_bits(), res);
+    /// ```
+    pub fn reverse_bits<T>(&self, ct: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key.key.reverse_bits_parallelized(ct)
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/rotate.rs b/tfhe/src/integer/fpga/server_key/radix/rotate.rs
new file mode 100644
index 00000000..4290a295
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/rotate.rs
@@ -0,0 +1,275 @@
+use super::shift::BarrelShifterOperation;
+use crate::integer::ciphertext::{IntegerRadixCiphertext, RadixCiphertext};
+use crate::integer::fpga::server_key::BelfortServerKey;
+
+impl BelfortServerKey {
+    //======================================================================
+    //                Rotate Right
+    //======================================================================
+
+    pub fn unchecked_rotate_right<T>(&self, ct: &T, n: &RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result = ct.clone();
+        self.unchecked_rotate_right_assign(&mut result, n);
+        result
+    }
+
+    pub fn unchecked_rotate_right_assign<T>(&self, ct: &mut T, n: &RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.barrel_shifter(ct, n, BarrelShifterOperation::RightRotate);
+    }
+
+    pub fn smart_rotate_right_assign<T>(&self, ct: &mut T, n: &mut RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+
+        rayon::join(
+            || {
+                if !ct.block_carries_are_empty() {
+                    integer_key.full_propagate_parallelized(ct);
+                }
+            },
+            || {
+                if !n.block_carries_are_empty() {
+                    integer_key.full_propagate_parallelized(n);
+                }
+            },
+        );
+        self.unchecked_rotate_right_assign(ct, n);
+    }
+
+    pub fn smart_rotate_right<T>(&self, ct: &mut T, rotate: &mut RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+
+        rayon::join(
+            || {
+                if !ct.block_carries_are_empty() {
+                    integer_key.full_propagate_parallelized(ct);
+                }
+            },
+            || {
+                if !rotate.block_carries_are_empty() {
+                    integer_key.full_propagate_parallelized(rotate);
+                }
+            },
+        );
+        self.unchecked_rotate_right(ct, rotate)
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the right by a specified amount,
+    /// `n`, wrapping the truncated bits to the beginning of the resulting integer.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2;
+    ///
+    /// let ct = cks.encrypt(msg as u64);
+    /// let n_ct = cks.encrypt(n as u64);
+    ///
+    /// let ct_res = sks.rotate_right(&ct, &n_ct);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg.rotate_right(n as u32) as u64, dec);
+    /// ```
+    pub fn rotate_right_assign<T>(&self, ct: &mut T, rotate: &RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (
+            ct.block_carries_are_empty(),
+            rotate.block_carries_are_empty(),
+        ) {
+            (true, true) => (ct, rotate),
+            (true, false) => {
+                tmp_rhs = rotate.clone();
+                integer_key.full_propagate_parallelized(&mut tmp_rhs);
+                (ct, &tmp_rhs)
+            }
+            (false, true) => {
+                integer_key.full_propagate_parallelized(ct);
+                (ct, rotate)
+            }
+            (false, false) => {
+                tmp_rhs = rotate.clone();
+                rayon::join(
+                    || integer_key.full_propagate_parallelized(ct),
+                    || integer_key.full_propagate_parallelized(&mut tmp_rhs),
+                );
+                (ct, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_rotate_right_assign(lhs, rhs);
+    }
+
+    pub fn rotate_right<T>(&self, ct: &T, rotate: &RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct.clone();
+        self.rotate_right_assign(&mut ct_res, rotate);
+        ct_res
+    }
+
+    //======================================================================
+    //                Rotate Left
+    //======================================================================
+
+    pub fn unchecked_rotate_left<T>(&self, ct_left: &T, n: &RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result = ct_left.clone();
+        self.unchecked_rotate_left_assign(&mut result, n);
+        result
+    }
+
+    pub fn unchecked_rotate_left_assign<T>(&self, ct: &mut T, n: &RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.barrel_shifter(ct, n, BarrelShifterOperation::LeftRotate);
+    }
+
+    pub fn smart_rotate_left_assign<T>(&self, ct: &mut T, n: &mut RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+
+        rayon::join(
+            || {
+                if !ct.block_carries_are_empty() {
+                    integer_key.full_propagate_parallelized(ct);
+                }
+            },
+            || {
+                if !n.block_carries_are_empty() {
+                    integer_key.full_propagate_parallelized(n);
+                }
+            },
+        );
+        self.unchecked_rotate_left_assign(ct, n);
+    }
+
+    pub fn smart_rotate_left<T>(&self, ct: &mut T, rotate: &mut RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+
+        rayon::join(
+            || {
+                if !ct.block_carries_are_empty() {
+                    integer_key.full_propagate_parallelized(ct);
+                }
+            },
+            || {
+                if !rotate.block_carries_are_empty() {
+                    integer_key.full_propagate_parallelized(rotate);
+                }
+            },
+        );
+        self.unchecked_rotate_left(ct, rotate)
+    }
+
+    pub fn rotate_left_assign<T>(&self, ct: &mut T, rotate: &RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (
+            ct.block_carries_are_empty(),
+            rotate.block_carries_are_empty(),
+        ) {
+            (true, true) => (ct, rotate),
+            (true, false) => {
+                tmp_rhs = rotate.clone();
+                integer_key.full_propagate_parallelized(&mut tmp_rhs);
+                (ct, &tmp_rhs)
+            }
+            (false, true) => {
+                integer_key.full_propagate_parallelized(ct);
+                (ct, rotate)
+            }
+            (false, false) => {
+                tmp_rhs = rotate.clone();
+                rayon::join(
+                    || integer_key.full_propagate_parallelized(ct),
+                    || integer_key.full_propagate_parallelized(&mut tmp_rhs),
+                );
+                (ct, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_rotate_left_assign(lhs, rhs);
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the left by a specified amount,
+    /// `n`, wrapping the truncated bits to the end of the resulting integer.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2;
+    ///
+    /// let ct = cks.encrypt(msg as u64);
+    /// let n_ct = cks.encrypt(n as u64);
+    ///
+    /// let ct_res = sks.rotate_left(&ct, &n_ct);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg.rotate_left(n as u32) as u64, dec);
+    /// ```
+    pub fn rotate_left<T>(&self, ct: &T, rotate: &RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct.clone();
+        self.rotate_left_assign(&mut ct_res, rotate);
+        ct_res
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/scalar_add.rs b/tfhe/src/integer/fpga/server_key/radix/scalar_add.rs
new file mode 100644
index 00000000..39ddf09b
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/scalar_add.rs
@@ -0,0 +1,183 @@
+use crate::core_crypto::prelude::UnsignedNumeric;
+use crate::integer::block_decomposition::DecomposableInto;
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::integer::{BooleanBlock, RadixCiphertext};
+use log::warn;
+
+impl BelfortServerKey {
+    pub fn overflowing_scalar_add_assign<T, Scalar>(
+        &self,
+        lhs: &mut T,
+        scalar: Scalar,
+    ) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .overflowing_scalar_add_assign_parallelized(lhs, scalar)
+    }
+
+    pub fn overflowing_scalar_add<T, Scalar>(&self, lhs: &T, scalar: Scalar) -> (T, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        let mut result = lhs.clone();
+        let overflowed = self.overflowing_scalar_add_assign(&mut result, scalar);
+        (result, overflowed)
+    }
+
+    pub fn unsigned_overflowing_scalar_add_assign<Scalar>(
+        &self,
+        lhs: &mut RadixCiphertext,
+        scalar: Scalar,
+    ) -> BooleanBlock
+    where
+        Scalar: UnsignedNumeric + DecomposableInto<u8>,
+    {
+        self.overflowing_scalar_add_assign(lhs, scalar)
+    }
+
+    pub fn unsigned_overflowing_scalar_add<Scalar>(
+        &self,
+        lhs: &RadixCiphertext,
+        scalar: Scalar,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        Scalar: UnsignedNumeric + DecomposableInto<u8>,
+    {
+        self.overflowing_scalar_add(lhs, scalar)
+    }
+    /// Computes homomorphically the addition of ciphertext with a scalar.
+    ///
+    /// The result is returned in a new ciphertext.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    pub fn scalar_add<T, Scalar>(&self, ct: &T, scalar: Scalar) -> T
+    where
+        Scalar: DecomposableInto<u8>,
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct.clone();
+        self.scalar_add_assign(&mut ct_res, scalar);
+        ct_res
+    }
+
+    /// Computes homomorphically the addition of ciphertext with a scalar.
+    ///
+    /// The result is assigned to the `ct_left` ciphertext.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    pub fn scalar_add_assign<T, Scalar>(&self, ct: &mut T, scalar: Scalar)
+    where
+        Scalar: DecomposableInto<u8>,
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(ct);
+
+        let integer_key = &self.key.key;
+        if integer_key.is_eligible_for_parallel_single_carry_propagation(ct.blocks().len()) {
+            integer_key.unchecked_scalar_add_assign(ct, scalar);
+            self.propagate_single_carry_parallelized_low_latency(ct.blocks_mut());
+        } else {
+            integer_key.unchecked_scalar_add_assign(ct, scalar);
+            self.full_propagate(ct);
+        }
+    }
+    pub fn unchecked_scalar_add<T, Scalar>(&self, ct: &mut T, scalar: Scalar) -> T
+    where
+        Scalar: DecomposableInto<u8>,
+        T: IntegerRadixCiphertext,
+    {
+        self.key.key.unchecked_scalar_add(ct, scalar)
+    }
+
+    /// Computes homomorphically the addition of ciphertext with a scalar.
+    ///
+    /// The result is returned in a new ciphertext.
+    pub fn smart_scalar_add<T, Scalar>(&self, ct: &mut T, scalar: Scalar) -> T
+    where
+        Scalar: DecomposableInto<u8>,
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+
+        if integer_key.is_scalar_add_possible(ct, scalar).is_err() {
+            self.full_propagate(ct);
+        }
+        integer_key.is_scalar_add_possible(ct, scalar).unwrap();
+        integer_key.unchecked_scalar_add(ct, scalar)
+    }
+
+    /// Computes homomorphically the addition of ciphertext with a scalar.
+    ///
+    /// The result is assigned to the `ct_left` ciphertext.
+    pub fn smart_scalar_add_assign<T, Scalar>(&self, ct: &mut T, scalar: Scalar)
+    where
+        Scalar: DecomposableInto<u8>,
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+        if integer_key.is_scalar_add_possible(ct, scalar).is_err() {
+            self.full_propagate(ct);
+        }
+        integer_key.is_scalar_add_possible(ct, scalar).unwrap();
+        integer_key.unchecked_scalar_add_assign(ct, scalar);
+    }
+
+    /// This scalar_add_assign two numbers
+    ///
+    /// It is after the Blelloch algorithm to do
+    /// prefix sum / cumulative sum in parallel.
+    ///
+    /// It is not "work efficient" as in, it does not adds
+    /// that much work compared to other parallel algorithm,
+    /// thus requiring less threads.
+    ///
+    /// However it is slower.
+    ///
+    /// At most num_block / 2 threads are used
+    ///
+    /// # Requirements
+    ///
+    /// - The parameters have 4 bits in total
+    /// - Adding rhs to lhs must not consume more than one carry
+    ///
+    /// # Output
+    ///
+    /// - lhs will have its carries empty
+    pub fn scalar_add_work_efficient<T, Scalar>(&self, ct: &T, scalar: Scalar) -> T
+    where
+        Scalar: DecomposableInto<u8>,
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+        assert!(integer_key.message_modulus().0 * integer_key.carry_modulus().0 >= (1 << 3));
+
+        let mut ct_res = ct.clone();
+        if !ct.block_carries_are_empty() {
+            self.full_propagate(&mut ct_res);
+        };
+        integer_key.unchecked_scalar_add_assign(&mut ct_res, scalar);
+        self.full_propagate_work_efficient(&mut ct_res);
+        ct_res
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/scalar_bitwise_op.rs b/tfhe/src/integer/fpga/server_key/radix/scalar_bitwise_op.rs
new file mode 100644
index 00000000..5fca9d7d
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/scalar_bitwise_op.rs
@@ -0,0 +1,454 @@
+use crate::core_crypto::fpga::BelfortFpgaLuts;
+use crate::integer::block_decomposition::{BlockDecomposer, DecomposableInto};
+use crate::integer::ciphertext::{IntegerRadixCiphertext, RadixCiphertext};
+use crate::shortint::ciphertext::Degree;
+use crate::BelfortServerKey;
+
+impl BelfortServerKey {
+    pub fn unchecked_scalar_bitand<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        let mut result = lhs.clone();
+        self.unchecked_scalar_bitand_assign(&mut result, rhs);
+        result
+    }
+
+    pub fn unchecked_scalar_bitand_assign<T, Scalar>(&self, lhs: &mut T, rhs: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        let integer_key = &self.key.key;
+        let shortint_key = &integer_key.key;
+
+        let message_modulus = integer_key.message_modulus().0;
+        assert!(message_modulus.is_power_of_two());
+
+        let clear_blocks = BlockDecomposer::with_early_stop_at_zero(rhs, message_modulus.ilog2())
+            .iter_as::<u8>()
+            .collect::<Vec<_>>();
+
+        let mut luts = Vec::new();
+        let mut blocks_vec = Vec::new();
+        let mut new_degrees = Vec::new();
+
+        lhs.blocks_mut()
+            .iter_mut()
+            .zip(clear_blocks.iter().copied())
+            .for_each(|(lhs_block, clear_block)| {
+                let new_degree = lhs_block
+                    .degree
+                    .after_bitand(Degree::new(clear_block as usize));
+
+                new_degrees.push(new_degree);
+
+                let lut = match clear_block {
+                    0 => BelfortFpgaLuts::lut_by_name("scalar_bitand_zero", shortint_key),
+                    1 => BelfortFpgaLuts::lut_by_name("scalar_bitand_one", shortint_key),
+                    2 => BelfortFpgaLuts::lut_by_name("scalar_bitand_two", shortint_key),
+                    3 => BelfortFpgaLuts::lut_by_name("scalar_bitand_three", shortint_key),
+                    _ => panic!("Unexpected clear_block value: {}", clear_block),
+                };
+
+                blocks_vec.push(lhs_block);
+                luts.push(lut)
+            });
+
+        self.apply_lookup_table_mut_packed_assign(&mut blocks_vec, &luts);
+
+        lhs.blocks_mut()
+            .iter_mut()
+            .zip(new_degrees.iter().copied())
+            .for_each(|(lhs_block, new_degree)| {
+                lhs_block.degree = new_degree;
+            });
+
+        let num_clear_blocks = clear_blocks.len();
+        if num_clear_blocks < lhs.blocks().len() {
+            // Blocks beyond clear_blocks.len() should be 'bitanded'
+            // with '0', however, no matter the block value the result will be 0
+            for block in &mut lhs.blocks_mut()[num_clear_blocks..] {
+                shortint_key.create_trivial_assign(block, 0);
+            }
+        }
+    }
+
+    pub fn smart_scalar_bitand<T, Scalar>(&self, lhs: &mut T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        let mut result = lhs.clone();
+        self.unchecked_scalar_bitand_assign(&mut result, rhs);
+        result
+    }
+
+    pub fn smart_scalar_bitand_assign<T, Scalar>(&self, lhs: &mut T, rhs: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        self.unchecked_scalar_bitand_assign(lhs, rhs);
+    }
+
+    /// Computes homomorphically a bitand between a ciphertexts and a clear value
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 14u8;
+    /// let msg2 = 97u8;
+    ///
+    /// let ct1 = cks.encrypt(msg1);
+    ///
+    /// let ct_res = sks.scalar_bitand(&ct1, msg2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u8 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, msg1 & msg2);
+    /// ```
+    pub fn scalar_bitand<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        let mut result = lhs.clone();
+        self.scalar_bitand_assign(&mut result, rhs);
+        result
+    }
+
+    /// Computes homomorphically a bitand between a ciphertexts and a clear value
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 123u8;
+    /// let msg2 = 34u8;
+    ///
+    /// let mut ct1 = cks.encrypt(msg1);
+    ///
+    /// sks.scalar_bitand_assign(&mut ct1, msg2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u8 = cks.decrypt(&ct1);
+    /// assert_eq!(dec_result, msg1 & msg2);
+    /// ```
+    pub fn scalar_bitand_assign<T, Scalar>(&self, lhs: &mut T, rhs: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        self.unchecked_scalar_bitand_assign(lhs, rhs);
+    }
+
+    pub fn unchecked_scalar_bitor<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        let mut result = lhs.clone();
+        self.unchecked_scalar_bitor_assign(&mut result, rhs);
+        result
+    }
+
+    pub fn unchecked_scalar_bitor_assign<T, Scalar>(&self, lhs: &mut T, rhs: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        let shortint_key = &self.key.key.key;
+        let message_modulus = shortint_key.message_modulus.0;
+        assert!(message_modulus.is_power_of_two());
+
+        let clear_blocks = BlockDecomposer::with_early_stop_at_zero(rhs, message_modulus.ilog2())
+            .iter_as::<u8>()
+            .collect::<Vec<_>>();
+
+        let mut luts = Vec::new();
+        let mut blocks_vec = Vec::new();
+        let mut new_degrees = Vec::new();
+
+        lhs.blocks_mut()
+            .iter_mut()
+            .zip(clear_blocks.iter().copied())
+            .for_each(|(lhs_block, clear_block)| {
+                let new_degree = lhs_block
+                    .degree
+                    .after_bitor(Degree::new(clear_block as usize));
+                new_degrees.push(new_degree);
+
+                let lut = match clear_block {
+                    0 => BelfortFpgaLuts::lut_by_name("scalar_bitor_zero", shortint_key),
+                    1 => BelfortFpgaLuts::lut_by_name("scalar_bitor_one", shortint_key),
+                    2 => BelfortFpgaLuts::lut_by_name("scalar_bitor_two", shortint_key),
+                    3 => BelfortFpgaLuts::lut_by_name("scalar_bitor_three", shortint_key),
+                    _ => panic!("Unexpected clear_block value: {}", clear_block),
+                };
+
+                blocks_vec.push(lhs_block);
+                luts.push(lut)
+            });
+
+        self.apply_lookup_table_mut_packed_assign(&mut blocks_vec, &luts);
+
+        lhs.blocks_mut()
+            .iter_mut()
+            .zip(new_degrees.iter().copied())
+            .for_each(|(lhs_block, new_degree)| {
+                lhs_block.degree = new_degree;
+            });
+
+        // Blocks beyond clear_blocks.len() should be 'ored'
+        // with '0', which means they keep their value
+    }
+
+    pub fn smart_scalar_bitor<T, Scalar>(&self, lhs: &mut T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        let mut result = lhs.clone();
+        self.unchecked_scalar_bitor_assign(&mut result, rhs);
+        result
+    }
+
+    pub fn smart_scalar_bitor_assign<T, Scalar>(&self, lhs: &mut T, rhs: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        self.unchecked_scalar_bitor_assign(lhs, rhs);
+    }
+
+    /// Computes homomorphically a bitor between a ciphertexts and a clear value
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 14u8;
+    /// let msg2 = 97u8;
+    ///
+    /// let ct1 = cks.encrypt(msg1);
+    ///
+    /// let ct_res = sks.scalar_bitor(&ct1, msg2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u8 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, msg1 | msg2);
+    /// ```
+    pub fn scalar_bitor<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        let mut result = lhs.clone();
+        self.scalar_bitor_assign(&mut result, rhs);
+        result
+    }
+
+    /// Computes homomorphically a bitor between a ciphertexts and a clear value
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 123u8;
+    /// let msg2 = 34u8;
+    ///
+    /// let mut ct1 = cks.encrypt(msg1);
+    ///
+    /// sks.scalar_bitor_assign(&mut ct1, msg2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u8 = cks.decrypt(&ct1);
+    /// assert_eq!(dec_result, msg1 | msg2);
+    /// ```
+    pub fn scalar_bitor_assign<T, Scalar>(&self, lhs: &mut T, rhs: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        self.unchecked_scalar_bitor_assign(lhs, rhs);
+    }
+
+    pub fn unchecked_scalar_bitxor<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        let mut result = lhs.clone();
+        self.unchecked_scalar_bitxor_assign(&mut result, rhs);
+        result
+    }
+
+    pub fn unchecked_scalar_bitxor_assign<T, Scalar>(&self, lhs: &mut T, rhs: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        let shortint_key = &self.key.key.key;
+        let message_modulus = shortint_key.message_modulus.0;
+        assert!(message_modulus.is_power_of_two());
+
+        let clear_blocks = BlockDecomposer::with_early_stop_at_zero(rhs, message_modulus.ilog2())
+            .iter_as::<u8>()
+            .collect::<Vec<_>>();
+
+        let mut luts = Vec::new();
+        let mut blocks_vec = Vec::new();
+        let mut new_degrees = Vec::new();
+
+        lhs.blocks_mut()
+            .iter_mut()
+            .zip(clear_blocks.iter().copied())
+            .for_each(|(lhs_block, clear_block)| {
+                let new_degree = lhs_block
+                    .degree
+                    .after_bitxor(Degree::new(clear_block as usize));
+                new_degrees.push(new_degree);
+
+                let lut = match clear_block {
+                    0 => BelfortFpgaLuts::lut_by_name("scalar_bitxor_zero", shortint_key),
+                    1 => BelfortFpgaLuts::lut_by_name("scalar_bitxor_one", shortint_key),
+                    2 => BelfortFpgaLuts::lut_by_name("scalar_bitxor_two", shortint_key),
+                    3 => BelfortFpgaLuts::lut_by_name("scalar_bitxor_three", shortint_key),
+                    _ => panic!("Unexpected clear_block value: {}", clear_block),
+                };
+
+                blocks_vec.push(lhs_block);
+                luts.push(lut)
+            });
+
+        self.apply_lookup_table_mut_packed_assign(&mut blocks_vec, &luts);
+
+        lhs.blocks_mut()
+            .iter_mut()
+            .zip(new_degrees.iter().copied())
+            .for_each(|(lhs_block, new_degree)| {
+                lhs_block.degree = new_degree;
+            });
+
+        // Blocks beyond clear_blocks.len() should be 'xored'
+        // with '0', which means they keep their value
+    }
+
+    pub fn smart_scalar_bitxor<T, Scalar>(&self, lhs: &mut T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        let mut result = lhs.clone();
+        self.unchecked_scalar_bitxor_assign(&mut result, rhs);
+        result
+    }
+
+    pub fn smart_scalar_bitxor_assign<T, Scalar>(&self, lhs: &mut RadixCiphertext, rhs: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        self.unchecked_scalar_bitxor_assign(lhs, rhs);
+    }
+
+    /// Computes homomorphically a bitxor between a ciphertexts and a clear value
+    ///
+    /// # Examples
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 14u8;
+    /// let msg2 = 97u8;
+    ///
+    /// let ct1 = cks.encrypt(msg1);
+    ///
+    /// let ct_res = sks.scalar_bitxor(&ct1, msg2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u8 = cks.decrypt(&ct_res);
+    /// assert_eq!(dec_result, msg1 ^ msg2);
+    /// ```
+    pub fn scalar_bitxor<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        let mut result = lhs.clone();
+        self.scalar_bitxor_assign(&mut result, rhs);
+        result
+    }
+
+    /// Computes homomorphically a bitxor between a ciphertexts and a clear value
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // Generate the client key and the server key:
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg1 = 123u8;
+    /// let msg2 = 34u8;
+    ///
+    /// let mut ct1 = cks.encrypt(msg1);
+    ///
+    /// sks.scalar_bitxor_assign(&mut ct1, msg2);
+    ///
+    /// // Decrypt:
+    /// let dec_result: u8 = cks.decrypt(&ct1);
+    /// assert_eq!(dec_result, msg1 ^ msg2);
+    /// ```
+    pub fn scalar_bitxor_assign<T, Scalar>(&self, lhs: &mut T, rhs: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        self.unchecked_scalar_bitxor_assign(lhs, rhs);
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/scalar_comparison.rs b/tfhe/src/integer/fpga/server_key/radix/scalar_comparison.rs
new file mode 100644
index 00000000..9d721630
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/scalar_comparison.rs
@@ -0,0 +1,735 @@
+use crate::core_crypto::fpga::luts::BelfortLookupTable;
+use crate::core_crypto::fpga::BelfortFpgaLuts;
+use crate::integer::block_decomposition::{BlockDecomposer, DecomposableInto};
+use crate::integer::fpga::server_key::comparator::Comparator;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::integer::server_key::comparator::*;
+use crate::integer::{BooleanBlock, IntegerRadixCiphertext};
+use crate::shortint::Ciphertext;
+
+#[derive(Clone, Copy, PartialEq)]
+enum EqualitySelector {
+    Eq,
+    Ne,
+}
+
+impl BelfortServerKey {
+    /// This takes a Vec of shortint blocks, where each block is
+    /// either 0 or 1.
+    ///
+    /// It returns a shortint block encrypting 1 if all input blocks are 1
+    /// otherwise the block encrypts 0
+    ///
+    /// if the vec is empty, a trivial 1 is returned
+    pub(crate) fn are_all_comparisons_block_true(
+        &self,
+        mut block_comparisons: Vec<Ciphertext>,
+    ) -> Ciphertext {
+        let shortint_key = &self.key.key.key;
+
+        if block_comparisons.is_empty() {
+            return shortint_key.create_trivial(1);
+        }
+
+        let message_modulus = shortint_key.message_modulus.0;
+        let carry_modulus = shortint_key.carry_modulus.0;
+        let total_modulus = message_modulus * carry_modulus;
+        let max_value = total_modulus - 1;
+
+        while block_comparisons.len() > 1 {
+            // Since all blocks encrypt either 0 or 1, we can sum max_value of them
+            // as in the worst case we will be adding `max_value` ones
+            let sums: Vec<Ciphertext> = if max_value <= 15 {
+                let sums_and_luts: Vec<(Ciphertext, BelfortLookupTable)> = block_comparisons
+                    .chunks(max_value)
+                    .map(|blocks| {
+                        let mut sum = blocks[0].clone();
+                        for other_block in &blocks[1..] {
+                            shortint_key.unchecked_add_assign(&mut sum, other_block);
+                        }
+
+                        let lut = match blocks.len() {
+                            1 => BelfortFpgaLuts::lut_by_name("is_equal_to_one", shortint_key),
+                            2 => BelfortFpgaLuts::lut_by_name("is_equal_to_two", shortint_key),
+                            3 => BelfortFpgaLuts::lut_by_name("is_equal_to_three", shortint_key),
+                            4 => BelfortFpgaLuts::lut_by_name("is_equal_to_four", shortint_key),
+                            5 => BelfortFpgaLuts::lut_by_name("is_equal_to_five", shortint_key),
+                            6 => BelfortFpgaLuts::lut_by_name("is_equal_to_six", shortint_key),
+                            7 => BelfortFpgaLuts::lut_by_name("is_equal_to_seven", shortint_key),
+                            8 => BelfortFpgaLuts::lut_by_name("is_equal_to_eight", shortint_key),
+                            9 => BelfortFpgaLuts::lut_by_name("is_equal_to_nine", shortint_key),
+                            10 => BelfortFpgaLuts::lut_by_name("is_equal_to_ten", shortint_key),
+                            11 => BelfortFpgaLuts::lut_by_name("is_equal_to_eleven", shortint_key),
+                            12 => BelfortFpgaLuts::lut_by_name("is_equal_to_twelve", shortint_key),
+                            13 => {
+                                BelfortFpgaLuts::lut_by_name("is_equal_to_thirteen", shortint_key)
+                            }
+                            14 => {
+                                BelfortFpgaLuts::lut_by_name("is_equal_to_fourteen", shortint_key)
+                            }
+                            15 => BelfortFpgaLuts::lut_by_name("is_equal_to_max", shortint_key),
+                            _ => panic!("Unexpected blocks.len() value: {}", blocks.len()),
+                        };
+
+                        (sum, lut)
+                    })
+                    .collect::<Vec<_>>();
+
+                let (mut sums, luts): (Vec<Ciphertext>, Vec<BelfortLookupTable>) =
+                    sums_and_luts.into_iter().unzip();
+
+                self.apply_lookup_table_packed_assign(&mut sums, &luts);
+
+                sums
+            } else {
+                let mut blocks_lens: Vec<u8> = Vec::new();
+
+                let mut sums = block_comparisons
+                    .chunks(message_modulus - 1)
+                    .map(|blocks| {
+                        // Sum up the blocks in the chunk
+                        let mut sum = blocks[0].clone();
+                        for other_block in &blocks[1..] {
+                            shortint_key.unchecked_add_assign(&mut sum, other_block);
+                        }
+
+                        blocks_lens.push(blocks.len() as u8);
+                        sum
+                    })
+                    .collect::<Vec<_>>();
+
+                sums.iter_mut()
+                    .zip(blocks_lens.iter())
+                    .for_each(|(lhs_block, rhs_block)| {
+                        shortint_key.unchecked_scalar_left_shift_assign(lhs_block, 2);
+                        shortint_key.unchecked_scalar_add_assign(lhs_block, *rhs_block);
+                    });
+
+                self.apply_same_lookup_table_packed_assign(&mut sums, "equal_to");
+
+                sums
+            };
+
+            block_comparisons.clear();
+            block_comparisons.extend(sums);
+        }
+
+        block_comparisons
+            .into_iter()
+            .next()
+            .expect("one block was expected")
+    }
+
+    /// This takes a Vec of shortint blocks, where each block is
+    /// either 0 or 1.
+    ///
+    /// It returns a shortint block encrypting 1 if at least input blocks is 1
+    /// otherwise the block encrypts 0 (all blocks encrypts 0)
+    ///
+    /// if the vec is empty, a trivial 1 is returned
+    pub(crate) fn is_at_least_one_comparisons_block_true(
+        &self,
+        mut block_comparisons: Vec<Ciphertext>,
+    ) -> Ciphertext {
+        let shortint_key = &self.key.key.key;
+        let message_modulus = shortint_key.message_modulus.0;
+        let carry_modulus = shortint_key.carry_modulus.0;
+        let total_modulus = message_modulus * carry_modulus;
+        let max_value = total_modulus - 1;
+
+        while block_comparisons.len() > 1 {
+            block_comparisons = block_comparisons
+                .chunks(max_value)
+                .map(|blocks| {
+                    let mut sum = blocks[0].clone();
+                    for other_block in &blocks[1..] {
+                        shortint_key.unchecked_add_assign(&mut sum, other_block);
+                    }
+                    sum
+                })
+                .collect();
+
+            self.apply_same_lookup_table_packed_assign(&mut block_comparisons, "is_non_zero");
+        }
+
+        block_comparisons
+            .into_iter()
+            .next()
+            .expect("one block was expected")
+    }
+
+    pub(crate) fn are_all_blocks_zero(&self, ciphertexts: &[Ciphertext]) -> Ciphertext {
+        let block_comparisons =
+            self.compare_blocks_with_zero(ciphertexts, ZeroComparisonType::Equality);
+        self.are_all_comparisons_block_true(block_comparisons)
+    }
+
+    /// This takes an input slice of blocks.
+    ///
+    /// Each block can encrypt any value as long as its < message_modulus.
+    ///
+    /// It will compare blocks with 0, for either equality or difference.
+    ///
+    /// This returns a Vec of block, where each block encrypts 1 or 0
+    /// depending on if all blocks matched with the comparison type with 0.
+    ///
+    /// E.g. For ZeroComparisonType::Equality, if all input blocks are zero
+    /// than all returned block will encrypt 1
+    ///
+    /// The returned Vec will have less block than the number of input blocks.
+    /// The returned blocks potentially needs to be 'reduced' to one block
+    /// with e.g. are_all_comparisons_block_true.
+    ///
+    /// This function exists because sometimes it is faster to concatenate
+    /// multiple vec of 'boolean' shortint block before reducing them with
+    /// are_all_comparisons_block_true
+    pub(crate) fn compare_blocks_with_zero(
+        &self,
+        lhs: &[Ciphertext],
+        comparison_type: ZeroComparisonType,
+    ) -> Vec<Ciphertext> {
+        if lhs.is_empty() {
+            return vec![];
+        }
+
+        debug_assert!(lhs.iter().all(Ciphertext::carry_is_empty));
+        let shortint_key = &self.key.key.key;
+
+        let message_modulus = shortint_key.message_modulus.0;
+        let carry_modulus = shortint_key.carry_modulus.0;
+        let total_modulus = message_modulus * carry_modulus;
+        let message_max = message_modulus - 1;
+
+        // The idea is that we will sum chunks of blocks until carries are full
+        // then we compare the sum with 0.
+        //
+        // If all blocks were 0, the sum will be zero
+        // If at least one bock was not zero, the sum won't be zero
+        let num_elements_to_fill_carry = (total_modulus - 1) / message_max;
+        let is_equal_to_zero_lut = {
+            if matches!(comparison_type, ZeroComparisonType::Equality) {
+                "is_mod_equal_to_zero"
+            } else {
+                "is_mod_not_equal_to_zero"
+            }
+        };
+
+        let mut result = lhs
+            .chunks(num_elements_to_fill_carry)
+            .map(|chunk| {
+                let mut sum = chunk[0].clone();
+                for other_block in &chunk[1..] {
+                    shortint_key.unchecked_add_assign(&mut sum, other_block);
+                }
+                sum
+            })
+            .collect::<Vec<_>>();
+
+        self.apply_same_lookup_table_packed_assign(&mut result, is_equal_to_zero_lut);
+
+        result
+    }
+
+    /// Given a slice of scalar values, and a total_modulus
+    /// where  each scalar value is < total_modulus
+    ///
+    /// This will return a vector of size `total_modulus`,
+    /// where for each index, the vec contains either
+    /// - `None` if fhe scalar was not present in the slice,
+    /// - or `Some` lookuptable that allows to compare a shortint block to the scalar value at this
+    ///  index
+    ///
+    ///
+    ///  E.g.
+    ///  - input slice: [0, 2],
+    ///  - total_modulus: 4,
+    ///  returns -> [Some(LUT(|x| x == 0)), None, Some(LUT(|x| x == 2), None]
+    fn create_scalar_comparison_luts(
+        &self,
+        scalar_blocks: &[u8],
+        comparison_type: EqualitySelector,
+    ) -> Vec<BelfortLookupTable> {
+        let shortint_key = &self.key.key.key;
+
+        // One lut per scalar block
+        // And only generate a lut for scalar block
+        // actually present
+        let mut scalar_comp_luts = Vec::new();
+
+        for scalar_block in scalar_blocks.iter().copied() {
+            match comparison_type {
+                EqualitySelector::Eq => {
+                    let lut: BelfortLookupTable = match scalar_block {
+                        0 => BelfortFpgaLuts::lut_by_name("is_equal_to_zero", shortint_key),
+                        1 => BelfortFpgaLuts::lut_by_name("is_equal_to_one", shortint_key),
+                        2 => BelfortFpgaLuts::lut_by_name("is_equal_to_two", shortint_key),
+                        3 => BelfortFpgaLuts::lut_by_name("is_equal_to_three", shortint_key),
+                        4 => BelfortFpgaLuts::lut_by_name("is_equal_to_four", shortint_key),
+                        5 => BelfortFpgaLuts::lut_by_name("is_equal_to_five", shortint_key),
+                        6 => BelfortFpgaLuts::lut_by_name("is_equal_to_six", shortint_key),
+                        7 => BelfortFpgaLuts::lut_by_name("is_equal_to_seven", shortint_key),
+                        8 => BelfortFpgaLuts::lut_by_name("is_equal_to_eight", shortint_key),
+                        9 => BelfortFpgaLuts::lut_by_name("is_equal_to_nine", shortint_key),
+                        10 => BelfortFpgaLuts::lut_by_name("is_equal_to_ten", shortint_key),
+                        11 => BelfortFpgaLuts::lut_by_name("is_equal_to_eleven", shortint_key),
+                        12 => BelfortFpgaLuts::lut_by_name("is_equal_to_twelve", shortint_key),
+                        13 => BelfortFpgaLuts::lut_by_name("is_equal_to_thirteen", shortint_key),
+                        14 => BelfortFpgaLuts::lut_by_name("is_equal_to_fourteen", shortint_key),
+                        15 => BelfortFpgaLuts::lut_by_name("is_equal_to_max", shortint_key),
+                        _ => panic!("Unexpected scalar_block value: {}", scalar_block),
+                    };
+
+                    scalar_comp_luts.push(lut);
+                }
+                EqualitySelector::Ne => {
+                    let lut = match scalar_block {
+                        0 => BelfortFpgaLuts::lut_by_name("is_not_equal_to_zero", shortint_key),
+                        1 => BelfortFpgaLuts::lut_by_name("is_not_equal_to_one", shortint_key),
+                        2 => BelfortFpgaLuts::lut_by_name("is_not_equal_to_two", shortint_key),
+                        3 => BelfortFpgaLuts::lut_by_name("is_not_equal_to_three", shortint_key),
+                        4 => BelfortFpgaLuts::lut_by_name("is_not_equal_to_four", shortint_key),
+                        5 => BelfortFpgaLuts::lut_by_name("is_not_equal_to_five", shortint_key),
+                        6 => BelfortFpgaLuts::lut_by_name("is_not_equal_to_six", shortint_key),
+                        7 => BelfortFpgaLuts::lut_by_name("is_not_equal_to_seven", shortint_key),
+                        8 => BelfortFpgaLuts::lut_by_name("is_not_equal_to_eight", shortint_key),
+                        9 => BelfortFpgaLuts::lut_by_name("is_not_equal_to_nine", shortint_key),
+                        10 => BelfortFpgaLuts::lut_by_name("is_not_equal_to_ten", shortint_key),
+                        11 => BelfortFpgaLuts::lut_by_name("is_not_equal_to_eleven", shortint_key),
+                        12 => BelfortFpgaLuts::lut_by_name("is_not_equal_to_twelve", shortint_key),
+                        13 => {
+                            BelfortFpgaLuts::lut_by_name("is_not_equal_to_thirteen", shortint_key)
+                        }
+                        14 => {
+                            BelfortFpgaLuts::lut_by_name("is_not_equal_to_fourteen", shortint_key)
+                        }
+                        15 => BelfortFpgaLuts::lut_by_name("is_not_equal_to_max", shortint_key),
+                        _ => panic!("Unexpected scalar_block value: {}", scalar_block),
+                    };
+
+                    scalar_comp_luts.push(lut);
+                }
+            }
+        }
+        scalar_comp_luts
+    }
+
+    /// Compares for equality a ciphertexts and a clear value
+    ///
+    /// Returns a ciphertext containing 1 if lhs == rhs, otherwise 0
+    ///
+    /// Requires carry bits to be empty
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// let size = 4;
+    ///
+    /// // Generate the client key and the server key:
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg1 = 14u64;
+    /// let msg2 = 97u64;
+    ///
+    /// let ct1 = cks.encrypt(msg1);
+    ///
+    /// let ct_res = sks.unchecked_scalar_eq(&ct1, msg2);
+    ///
+    /// // Decrypt:
+    /// let dec_result = cks.decrypt_bool(&ct_res);
+    /// assert_eq!(dec_result, msg1 == msg2);
+    /// ```
+    pub fn unchecked_scalar_eq<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        debug_assert!(lhs.block_carries_are_empty());
+        let integer_key = &self.key.key;
+
+        if T::IS_SIGNED {
+            match integer_key.is_scalar_out_of_bounds(lhs, rhs) {
+                std::cmp::Ordering::Greater | std::cmp::Ordering::Less => {
+                    // Scalar is not within bounds so it cannot be equal
+                    return integer_key.create_trivial_boolean_block(false);
+                }
+                std::cmp::Ordering::Equal => {
+                    let trivial = integer_key.create_trivial_radix(rhs, lhs.blocks().len());
+                    return self.unchecked_eq(lhs, &trivial);
+                }
+            }
+        }
+
+        // Starting From here, we know lhs (T) is an unsigned ciphertext
+        if rhs < Scalar::ZERO {
+            return integer_key.create_trivial_boolean_block(false);
+        }
+
+        let message_modulus = integer_key.message_modulus().0;
+        let carry_modulus = integer_key.carry_modulus().0;
+        let total_modulus = message_modulus * carry_modulus;
+        let max_value = total_modulus - 1;
+
+        assert!(carry_modulus >= message_modulus);
+        u8::try_from(max_value).unwrap();
+
+        let num_blocks = lhs.blocks().len();
+        let num_blocks_halved = (num_blocks / 2) + (num_blocks % 2);
+
+        let mut scalar_blocks =
+            BlockDecomposer::with_early_stop_at_zero(rhs, total_modulus.ilog2())
+                .iter_as::<u64>()
+                .map(|x| x as u8)
+                .collect::<Vec<_>>();
+
+        // If we have more scalar blocks than lhs.blocks
+        // and that any of these additional blocks is != 0
+        // then lhs != rhs
+        let is_scalar_obviously_bigger = scalar_blocks
+            .get(num_blocks_halved..) // We may have less scalar blocks
+            .is_some_and(|sub_slice| sub_slice.iter().any(|&scalar_block| scalar_block != 0));
+        if is_scalar_obviously_bigger {
+            return integer_key.create_trivial_boolean_block(false);
+        }
+
+        // If we are sill here, that means scalar_blocks above
+        // num_blocks_halved are 0s, we can remove them
+        // as we will handle them separately.
+        // (truncate can be called even if scalar_blocks.len() < num_blocks_halved);
+        scalar_blocks.truncate(num_blocks_halved);
+
+        let scalar_comp_luts =
+            self.create_scalar_comparison_luts(&scalar_blocks, EqualitySelector::Eq);
+
+        // scalar_blocks.len() is known to be <= to num_blocks_halved
+        // but num_blocks_halved takes into account the non-even num_blocks case
+        let split_index = num_blocks.min(scalar_blocks.len() * 2);
+        let (least_significant_blocks, most_significant_blocks) =
+            lhs.blocks().split_at(split_index);
+
+        let (mut cmp_1, mut cmp_2) = {
+            let mut packed_blocks: Vec<Ciphertext> = least_significant_blocks
+                .chunks(2)
+                .map(|two_blocks| {
+                    let packed_block = integer_key.pack_block_chunk(two_blocks);
+                    packed_block
+                })
+                .collect();
+
+            self.apply_lookup_table_packed_assign(&mut packed_blocks, &scalar_comp_luts);
+
+            (
+                packed_blocks,
+                self.compare_blocks_with_zero(
+                    most_significant_blocks,
+                    ZeroComparisonType::Equality,
+                ),
+            )
+        };
+        cmp_1.append(&mut cmp_2);
+        let is_equal_result = self.are_all_comparisons_block_true(cmp_1);
+        BooleanBlock::new_unchecked(is_equal_result)
+    }
+
+    pub fn unchecked_scalar_ne<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        debug_assert!(lhs.block_carries_are_empty());
+        let integer_key = &self.key.key;
+
+        if T::IS_SIGNED {
+            match integer_key.is_scalar_out_of_bounds(lhs, rhs) {
+                std::cmp::Ordering::Greater | std::cmp::Ordering::Less => {
+                    // Scalar is not within bounds so its not equal
+                    return integer_key.create_trivial_boolean_block(true);
+                }
+                std::cmp::Ordering::Equal => {
+                    let trivial = integer_key.create_trivial_radix(rhs, lhs.blocks().len());
+                    return self.unchecked_ne(lhs, &trivial);
+                }
+            }
+        }
+
+        if rhs < Scalar::ZERO {
+            return integer_key.create_trivial_boolean_block(true);
+        }
+
+        let message_modulus = integer_key.message_modulus().0;
+        let carry_modulus = integer_key.carry_modulus().0;
+        let total_modulus = message_modulus * carry_modulus;
+        let max_value = total_modulus - 1;
+
+        assert!(carry_modulus >= message_modulus);
+        u8::try_from(max_value).unwrap();
+
+        let num_blocks = lhs.blocks().len();
+        let num_blocks_halved = (num_blocks / 2) + (num_blocks % 2);
+
+        let mut scalar_blocks =
+            BlockDecomposer::with_early_stop_at_zero(rhs, total_modulus.ilog2())
+                .iter_as::<u64>()
+                .map(|x| x as u8)
+                .collect::<Vec<_>>();
+
+        // If we have more scalar blocks than lhs.blocks
+        // and that any of these block additional blocks is != 0
+        // then lhs != rhs
+        let is_scalar_obviously_bigger = scalar_blocks
+            .get(num_blocks_halved..) // We may have less scalar blocks
+            .is_some_and(|sub_slice| sub_slice.iter().any(|&scalar_block| scalar_block != 0));
+        if is_scalar_obviously_bigger {
+            return integer_key.create_trivial_boolean_block(true);
+        }
+        // If we are sill here, that means scalar_blocks above
+        // num_blocks_halved are 0s, we can remove them
+        // as we will handle them separately.
+        // (truncate can be called even if scalar_blocks.len() < num_blocks_halved);
+        scalar_blocks.truncate(num_blocks_halved);
+
+        let scalar_comp_luts =
+            self.create_scalar_comparison_luts(&scalar_blocks, EqualitySelector::Ne);
+
+        // scalar_blocks.len() is known to be <= to num_blocks_halved
+        // but num_blocks_halved takes into account the non-even num_blocks case
+        let split_index = num_blocks.min(scalar_blocks.len() * 2);
+        let (least_significant_blocks, most_significant_blocks) =
+            lhs.blocks().split_at(split_index);
+
+        let (mut cmp_1, mut cmp_2) = {
+            let mut packed_blocks: Vec<Ciphertext> = least_significant_blocks
+                .chunks(2)
+                .map(|two_blocks| {
+                    let packed_block = integer_key.pack_block_chunk(two_blocks);
+                    packed_block
+                })
+                .collect();
+
+            self.apply_lookup_table_packed_assign(&mut packed_blocks, &scalar_comp_luts);
+
+            (
+                packed_blocks,
+                self.compare_blocks_with_zero(
+                    most_significant_blocks,
+                    ZeroComparisonType::Difference,
+                ),
+            )
+        };
+        cmp_1.append(&mut cmp_2);
+        let is_equal_result = self.is_at_least_one_comparisons_block_true(cmp_1);
+        BooleanBlock::new_unchecked(is_equal_result)
+    }
+
+    pub fn smart_scalar_eq<T, Scalar>(&self, lhs: &mut T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.conditional_full_propagate(lhs);
+        self.unchecked_scalar_eq(lhs, rhs)
+    }
+
+    pub fn scalar_eq<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        let mut tmp_lhs;
+        let lhs = if lhs.block_carries_are_empty() {
+            lhs
+        } else {
+            tmp_lhs = lhs.clone();
+            self.full_propagate(&mut tmp_lhs);
+            &tmp_lhs
+        };
+        self.unchecked_scalar_eq(lhs, rhs)
+    }
+
+    pub fn smart_scalar_ne<T, Scalar>(&self, lhs: &mut T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.conditional_full_propagate(lhs);
+        self.unchecked_scalar_ne(lhs, rhs)
+    }
+
+    pub fn scalar_ne<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        let mut tmp_lhs;
+        let lhs = if lhs.block_carries_are_empty() {
+            lhs
+        } else {
+            tmp_lhs = lhs.clone();
+            self.full_propagate(&mut tmp_lhs);
+            &tmp_lhs
+        };
+        self.unchecked_scalar_ne(lhs, rhs)
+    }
+
+    /// Computes homomorphically if lhs > rhs
+    pub fn scalar_gt<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        let mut ct_res = lhs.clone();
+        self.smart_scalar_gt(&mut ct_res, rhs)
+    }
+
+    pub fn smart_scalar_gt<T, Scalar>(&self, lhs: &mut T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.conditional_full_propagate(lhs);
+        Comparator::new(self).scalar_gt(lhs, rhs)
+    }
+
+    pub fn unchecked_scalar_gt<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        Comparator::new(self).unchecked_scalar_gt(lhs, rhs)
+    }
+
+    /// Computes homomorphically if lhs >= rhs
+    pub fn scalar_ge<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        let mut ct_res = lhs.clone();
+        self.smart_scalar_ge(&mut ct_res, rhs)
+    }
+
+    pub fn smart_scalar_ge<T, Scalar>(&self, lhs: &mut T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.conditional_full_propagate(lhs);
+        Comparator::new(self).scalar_ge(lhs, rhs)
+    }
+
+    pub fn unchecked_scalar_ge<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        Comparator::new(self).unchecked_scalar_ge(lhs, rhs)
+    }
+
+    pub fn scalar_lt<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        let mut ct_res = lhs.clone();
+        self.smart_scalar_lt(&mut ct_res, rhs)
+    }
+
+    pub fn smart_scalar_lt<T, Scalar>(&self, lhs: &mut T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.conditional_full_propagate(lhs);
+        Comparator::new(self).scalar_lt(lhs, rhs)
+    }
+
+    pub fn unchecked_scalar_lt<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        Comparator::new(self).unchecked_scalar_lt(lhs, rhs)
+    }
+
+    /// Compute homomorphically lhs <= rhs
+    pub fn scalar_le<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        let mut ct_res = lhs.clone();
+        self.smart_scalar_le(&mut ct_res, rhs)
+    }
+
+    pub fn smart_scalar_le<T, Scalar>(&self, lhs: &mut T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.conditional_full_propagate(lhs);
+        Comparator::new(self).scalar_le(lhs, rhs)
+    }
+
+    pub fn unchecked_scalar_le<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        Comparator::new(self).unchecked_scalar_le(lhs, rhs)
+    }
+
+    /// Computes homomorphically the maximum between a ciphertext and a scalar value
+    pub fn scalar_max<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        let mut ct_res = lhs.clone();
+        self.smart_scalar_max(&mut ct_res, rhs)
+    }
+
+    pub fn smart_scalar_max<T, Scalar>(&self, lhs: &mut T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.conditional_full_propagate(lhs);
+        Comparator::new(self).scalar_max(lhs, rhs)
+    }
+
+    pub fn unchecked_scalar_max<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        Comparator::new(self).unchecked_scalar_min_or_max(lhs, rhs, MinMaxSelector::Max)
+    }
+
+    pub fn scalar_min<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        let mut ct_res = lhs.clone();
+        self.smart_scalar_min(&mut ct_res, rhs)
+    }
+
+    pub fn smart_scalar_min<T, Scalar>(&self, lhs: &mut T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        self.conditional_full_propagate(lhs);
+        Comparator::new(self).scalar_min(lhs, rhs)
+    }
+
+    pub fn unchecked_scalar_min<T, Scalar>(&self, lhs: &T, rhs: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: DecomposableInto<u64>,
+    {
+        Comparator::new(self).unchecked_scalar_min_or_max(lhs, rhs, MinMaxSelector::Min)
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/scalar_div_mod.rs b/tfhe/src/integer/fpga/server_key/radix/scalar_div_mod.rs
new file mode 100644
index 00000000..60103fd5
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/scalar_div_mod.rs
@@ -0,0 +1,392 @@
+use crate::integer::block_decomposition::DecomposableInto;
+use crate::integer::ciphertext::{RadixCiphertext, SignedRadixCiphertext};
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::integer::server_key::radix_parallel::scalar_div_mod::SignedReciprocable;
+use crate::integer::server_key::{MiniUnsignedInteger, Reciprocable, ScalarMultiplier};
+use log::warn;
+
+impl BelfortServerKey {
+    pub fn scalar_div<T>(&self, numerator: &RadixCiphertext, divisor: T) -> RadixCiphertext
+    where
+        T: Reciprocable + DecomposableInto<u8>,
+    {
+        let mut result = numerator.clone();
+        self.scalar_div_assign(&mut result, divisor);
+        result
+    }
+
+    pub fn scalar_div_assign<T>(&self, numerator: &mut RadixCiphertext, divisor: T)
+    where
+        T: Reciprocable + DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(numerator);
+        *numerator = self.unchecked_scalar_div(numerator, divisor);
+    }
+
+    pub fn scalar_rem<T>(&self, numerator: &RadixCiphertext, divisor: T) -> RadixCiphertext
+    where
+        T: Reciprocable + ScalarMultiplier + DecomposableInto<u8>,
+    {
+        let mut result = numerator.clone();
+        self.scalar_rem_assign(&mut result, divisor);
+        result
+    }
+
+    pub fn scalar_rem_assign<T>(&self, numerator: &mut RadixCiphertext, divisor: T)
+    where
+        T: Reciprocable + ScalarMultiplier + DecomposableInto<u8>,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.conditional_full_propagate(numerator);
+        *numerator = self
+            .key
+            .key
+            .unchecked_scalar_rem_parallelized(numerator, divisor);
+    }
+
+    pub fn unchecked_scalar_div<T>(
+        &self,
+        numerator: &RadixCiphertext,
+        divisor: T,
+    ) -> RadixCiphertext
+    where
+        T: Reciprocable,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .unchecked_scalar_div_parallelized(numerator, divisor)
+    }
+
+    /// # Note
+    /// This division rounds (truncates) the quotient towards zero
+    pub fn unchecked_signed_scalar_div<T>(
+        &self,
+        numerator: &SignedRadixCiphertext,
+        divisor: T,
+    ) -> SignedRadixCiphertext
+    where
+        T: SignedReciprocable,
+        <<T as SignedReciprocable>::Unsigned as Reciprocable>::DoublePrecision: Send,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .unchecked_signed_scalar_div_parallelized(numerator, divisor)
+    }
+
+    /// # Note
+    ///
+    /// - This division rounds (truncates) the quotient towards 0
+    pub fn unchecked_signed_scalar_div_rem<T>(
+        &self,
+        numerator: &SignedRadixCiphertext,
+        divisor: T,
+    ) -> (SignedRadixCiphertext, SignedRadixCiphertext)
+    where
+        T: SignedReciprocable + ScalarMultiplier,
+        <<T as SignedReciprocable>::Unsigned as Reciprocable>::DoublePrecision: Send,
+    {
+        let quotient = self.unchecked_signed_scalar_div(numerator, divisor);
+
+        // remainder = numerator - (quotient * divisor)
+        let tmp = self.unchecked_scalar_mul(&quotient, divisor);
+        let remainder = self.sub(numerator, &tmp);
+
+        (quotient, remainder)
+    }
+
+    /// # Note
+    ///
+    /// - This division rounds (truncates) the quotient towards 0
+    /// - If you need both the quotient and remainder use
+    ///   [Self::unchecked_signed_scalar_div_rem_parallelized] instead.
+    pub fn unchecked_signed_scalar_rem<T>(
+        &self,
+        numerator: &SignedRadixCiphertext,
+        divisor: T,
+    ) -> SignedRadixCiphertext
+    where
+        T: SignedReciprocable + ScalarMultiplier,
+        <<T as SignedReciprocable>::Unsigned as Reciprocable>::DoublePrecision: Send,
+    {
+        let (_, remainder) = self.unchecked_signed_scalar_div_rem(numerator, divisor);
+
+        remainder
+    }
+
+    /// Computes and returns the quotient and remainder of the division between
+    /// a signed ciphertext and a signed clear value.
+    ///
+    /// # Note
+    ///
+    /// - This division rounds (truncates) the quotient towards 0
+    pub fn signed_scalar_div_rem<T>(
+        &self,
+        numerator: &SignedRadixCiphertext,
+        divisor: T,
+    ) -> (SignedRadixCiphertext, SignedRadixCiphertext)
+    where
+        T: SignedReciprocable + ScalarMultiplier,
+        <<T as SignedReciprocable>::Unsigned as Reciprocable>::DoublePrecision: Send,
+    {
+        if numerator.block_carries_are_empty() {
+            self.unchecked_signed_scalar_div_rem(numerator, divisor)
+        } else {
+            let mut tmp = numerator.clone();
+            self.full_propagate(&mut tmp);
+            self.unchecked_signed_scalar_div_rem(&tmp, divisor)
+        }
+    }
+
+    /// Computes the quotient of the division between
+    /// a signed ciphertext and a signed clear value and assigns the
+    /// result to the input ciphertext.
+    ///
+    /// # Note
+    ///
+    /// - This division rounds (truncates) the quotient towards 0
+    pub fn signed_scalar_div_assign<T>(&self, numerator: &mut SignedRadixCiphertext, divisor: T)
+    where
+        T: SignedReciprocable,
+        <<T as SignedReciprocable>::Unsigned as Reciprocable>::DoublePrecision: Send,
+    {
+        self.conditional_full_propagate(numerator);
+
+        *numerator = self.unchecked_signed_scalar_div(numerator, divisor);
+    }
+
+    /// Computes and returns the quotient of the division between
+    /// a signed ciphertext and a signed clear value.
+    ///
+    /// # Note
+    ///
+    /// - This division rounds (truncates) the quotient towards 0
+    /// - If you need both the quotient and remainder use [Self::signed_scalar_div_rem] instead.
+    pub fn signed_scalar_div<T>(
+        &self,
+        numerator: &SignedRadixCiphertext,
+        divisor: T,
+    ) -> SignedRadixCiphertext
+    where
+        T: SignedReciprocable,
+        <<T as SignedReciprocable>::Unsigned as Reciprocable>::DoublePrecision: Send,
+    {
+        let mut result = numerator.clone();
+        self.signed_scalar_div_assign(&mut result, divisor);
+        result
+    }
+
+    /// Computes and returns the remainder of the division between
+    /// a signed ciphertext and a signed clear value.
+    ///
+    /// # Note
+    ///
+    /// - If you need both the quotient and remainder use [Self::signed_scalar_div_rem] instead.
+    pub fn signed_scalar_rem<T>(
+        &self,
+        numerator: &SignedRadixCiphertext,
+        divisor: T,
+    ) -> SignedRadixCiphertext
+    where
+        T: SignedReciprocable + ScalarMultiplier,
+        <<T as SignedReciprocable>::Unsigned as Reciprocable>::DoublePrecision: Send,
+    {
+        let mut result = numerator.clone();
+        self.signed_scalar_rem_assign(&mut result, divisor);
+        result
+    }
+
+    /// Computes the remainder of the division between
+    /// a signed ciphertext and a signed clear value and assigns the
+    /// result to the input ciphertext.
+    pub fn signed_scalar_rem_assign<T>(&self, numerator: &mut SignedRadixCiphertext, divisor: T)
+    where
+        T: SignedReciprocable + ScalarMultiplier,
+        <<T as SignedReciprocable>::Unsigned as Reciprocable>::DoublePrecision: Send,
+    {
+        self.conditional_full_propagate(numerator);
+
+        let remainder = self.unchecked_signed_scalar_rem(numerator, divisor);
+        *numerator = remainder;
+    }
+
+    /// # Note
+    /// This division rounds the quotient towards minus infinity
+    pub fn unchecked_signed_scalar_div_floor<T>(
+        &self,
+        numerator: &SignedRadixCiphertext,
+        divisor: T,
+    ) -> SignedRadixCiphertext
+    where
+        T: SignedReciprocable,
+        <<T as SignedReciprocable>::Unsigned as Reciprocable>::DoublePrecision: Send,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+
+        self.key
+            .key
+            .unchecked_signed_scalar_div_floor_parallelized(numerator, divisor)
+    }
+
+    /// # Note
+    /// This division rounds the quotient towards minus infinity
+    pub fn unchecked_signed_scalar_div_rem_floor<T>(
+        &self,
+        numerator: &SignedRadixCiphertext,
+        divisor: T,
+    ) -> (SignedRadixCiphertext, SignedRadixCiphertext)
+    where
+        T: SignedReciprocable + ScalarMultiplier,
+        <<T as SignedReciprocable>::Unsigned as Reciprocable>::DoublePrecision: Send,
+    {
+        let quotient = self.unchecked_signed_scalar_div_floor(numerator, divisor);
+
+        // remainder = numerator - (quotient * divisor)
+        let tmp = self.unchecked_scalar_mul(&quotient, divisor);
+        let remainder = self.sub(numerator, &tmp);
+
+        (quotient, remainder)
+    }
+
+    pub fn unchecked_scalar_div_rem<T>(
+        &self,
+        numerator: &RadixCiphertext,
+        divisor: T,
+    ) -> (RadixCiphertext, RadixCiphertext)
+    where
+        T: Reciprocable + ScalarMultiplier + DecomposableInto<u8>,
+    {
+        let quotient = self.unchecked_scalar_div(numerator, divisor);
+        let remainder = if MiniUnsignedInteger::is_power_of_two(divisor) {
+            // unchecked_scalar_div would have panicked if divisor was zero
+            self.scalar_bitand(numerator, divisor - T::ONE)
+        } else {
+            // remainder = numerator - (quotient * divisor)
+            let tmp = self.unchecked_scalar_mul(&quotient, divisor);
+            self.sub(numerator, &tmp)
+        };
+
+        (quotient, remainder)
+    }
+
+    pub fn unchecked_scalar_rem<T>(
+        &self,
+        numerator: &RadixCiphertext,
+        divisor: T,
+    ) -> RadixCiphertext
+    where
+        T: Reciprocable + ScalarMultiplier + DecomposableInto<u8>,
+    {
+        if MiniUnsignedInteger::is_power_of_two(divisor) {
+            // The remainder is simply the bits that would get 'shifted out'
+            return self.scalar_bitand(numerator, divisor - T::ONE);
+        }
+
+        let (_quotient, remainder) = self.unchecked_scalar_div_rem(numerator, divisor);
+        remainder
+    }
+
+    pub fn smart_scalar_div_assign<T>(&self, numerator: &mut RadixCiphertext, divisor: T)
+    where
+        T: Reciprocable + DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(numerator);
+
+        *numerator = self.unchecked_scalar_div(numerator, divisor);
+    }
+
+    pub fn smart_scalar_rem_assign<T>(&self, numerator: &mut RadixCiphertext, divisor: T)
+    where
+        T: Reciprocable + ScalarMultiplier + DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(numerator);
+
+        *numerator = self.unchecked_scalar_rem(numerator, divisor);
+    }
+
+    pub fn smart_scalar_div<T>(
+        &self,
+        numerator: &mut RadixCiphertext,
+        divisor: T,
+    ) -> RadixCiphertext
+    where
+        T: Reciprocable + DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(numerator);
+
+        self.unchecked_scalar_div(numerator, divisor)
+    }
+
+    pub fn smart_scalar_rem<T>(
+        &self,
+        numerator: &mut RadixCiphertext,
+        divisor: T,
+    ) -> RadixCiphertext
+    where
+        T: Reciprocable + ScalarMultiplier + DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(numerator);
+
+        self.unchecked_scalar_rem(numerator, divisor)
+    }
+
+    pub fn smart_scalar_div_rem<T>(
+        &self,
+        numerator: &mut RadixCiphertext,
+        divisor: T,
+    ) -> (RadixCiphertext, RadixCiphertext)
+    where
+        T: Reciprocable + ScalarMultiplier + DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(numerator);
+
+        self.unchecked_scalar_div_rem(numerator, divisor)
+    }
+
+    /// Computes homomorphically the euclidean the division of a ciphertext by a scalar.
+    ///
+    /// # Panics
+    ///
+    /// Panics if scalar is zero.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2, size);
+    ///
+    /// let msg = 230u8;
+    /// let scalar = 12u8;
+    ///
+    /// let ct = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a scalar division:
+    /// let (q, r) = sks.scalar_div_rem(&ct, scalar);
+    ///
+    /// let decrypted_quotient: u8 = cks.decrypt(&q);
+    /// let decrypted_remainder: u8 = cks.decrypt(&r);
+    /// assert_eq!(msg / scalar, decrypted_quotient);
+    /// assert_eq!(msg % scalar, decrypted_remainder);
+    /// ```
+    pub fn scalar_div_rem<T>(
+        &self,
+        numerator: &RadixCiphertext,
+        divisor: T,
+    ) -> (RadixCiphertext, RadixCiphertext)
+    where
+        T: Reciprocable + ScalarMultiplier + DecomposableInto<u8>,
+    {
+        if numerator.block_carries_are_empty() {
+            self.unchecked_scalar_div_rem(numerator, divisor)
+        } else {
+            let mut cloned_numerator = numerator.clone();
+            self.full_propagate(&mut cloned_numerator);
+            self.unchecked_scalar_div_rem(&cloned_numerator, divisor)
+        }
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/scalar_mul.rs b/tfhe/src/integer/fpga/server_key/radix/scalar_mul.rs
new file mode 100644
index 00000000..86f79f1a
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/scalar_mul.rs
@@ -0,0 +1,214 @@
+use crate::integer::block_decomposition::{BlockDecomposer, DecomposableInto};
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::server_key::ScalarMultiplier;
+use crate::BelfortServerKey;
+
+impl BelfortServerKey {
+    pub fn unchecked_scalar_mul<T, Scalar>(&self, ct: &T, scalar: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: ScalarMultiplier + DecomposableInto<u8>,
+    {
+        let mut ct_res = ct.clone();
+        self.unchecked_scalar_mul_assign(&mut ct_res, scalar);
+        ct_res
+    }
+
+    pub fn unchecked_scalar_mul_assign<T, Scalar>(&self, lhs: &mut T, scalar: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: ScalarMultiplier + DecomposableInto<u8>,
+    {
+        let integer_key = &self.key.key;
+        let shortint_key = &integer_key.key;
+
+        if scalar == Scalar::ZERO || lhs.blocks().is_empty() {
+            for block in lhs.blocks_mut() {
+                shortint_key.create_trivial_assign(block, 0);
+            }
+            return;
+        }
+
+        if scalar == Scalar::ONE {
+            return;
+        }
+
+        if scalar.is_power_of_two() {
+            // Shifting cost one bivariate PBS so its always faster
+            // than multiplying
+            self.unchecked_scalar_left_shift_assign(lhs, scalar.ilog2() as u64);
+            return;
+        }
+
+        let num_blocks = lhs.blocks().len();
+        let msg_bits = shortint_key.message_modulus.0.ilog2() as usize;
+
+        let scalar_bits = BlockDecomposer::with_early_stop_at_zero(scalar, 1)
+            .iter_as::<u8>()
+            .collect::<Vec<_>>();
+
+        // We don't want to compute shifts if we are not going to use the
+        // resulting value
+        let mut has_at_least_one_set = vec![false; msg_bits];
+        for (i, bit) in scalar_bits.iter().copied().enumerate() {
+            if bit == 1 {
+                has_at_least_one_set[i % msg_bits] = true;
+            }
+        }
+
+        // Contains all shifted values of lhs for shift in range (0..msg_bits)
+        // The idea is that with these we can create all other shift that are in
+        // range (0..total_bits) for free (block rotation)
+        let preshifted_lhs = (0..msg_bits)
+            .into_iter()
+            .map(|shift_amount| {
+                if has_at_least_one_set[shift_amount] {
+                    self.unchecked_scalar_left_shift(lhs, shift_amount)
+                } else {
+                    integer_key.create_trivial_zero_radix(num_blocks)
+                }
+            })
+            .collect::<Vec<_>>();
+
+        let num_ciphertext_bits = msg_bits * num_blocks;
+        let all_shifted_lhs = scalar_bits
+            .iter()
+            .enumerate()
+            .take(num_ciphertext_bits) // shift beyond that are technically resulting in 0s
+            .filter(|(_, &rhs_bit)| rhs_bit == 1)
+            .map(|(i, _)| integer_key.blockshift(&preshifted_lhs[i % msg_bits], i / msg_bits))
+            .collect::<Vec<_>>();
+
+        if let Some(result) = self.unchecked_sum_ciphertexts_vec(all_shifted_lhs) {
+            *lhs = result;
+        } else {
+            integer_key.create_trivial_zero_assign_radix(lhs);
+        }
+    }
+
+    /// Computes homomorphically a multiplication between a scalar and a ciphertext.
+    ///
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let modulus = 1 << 8;
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 230;
+    /// let scalar = 376;
+    ///
+    /// let mut ct = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a scalar multiplication:
+    /// let ct_res = sks.smart_scalar_mul(&mut ct, scalar);
+    ///
+    /// // Decrypt:
+    /// let clear: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg * scalar % modulus, clear);
+    /// ```
+    pub fn smart_scalar_mul<T, Scalar>(&self, lhs: &mut T, scalar: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: ScalarMultiplier + DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        self.unchecked_scalar_mul(lhs, scalar)
+    }
+
+    pub fn smart_scalar_mul_assign<T, Scalar>(&self, lhs: &mut T, scalar: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: ScalarMultiplier + DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        self.unchecked_scalar_mul_assign(lhs, scalar);
+    }
+
+    /// Computes homomorphically a multiplication between a scalar and a ciphertext.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let modulus = 1 << 8;
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 230;
+    /// let scalar = 376;
+    ///
+    /// let mut ct = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a scalar multiplication:
+    /// let ct_res = sks.scalar_mul(&mut ct, scalar);
+    ///
+    /// // Decrypt:
+    /// let clear: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg * scalar % modulus, clear);
+    /// ```
+    pub fn scalar_mul<T, Scalar>(&self, ct: &T, scalar: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: ScalarMultiplier + DecomposableInto<u8>,
+    {
+        let mut ct_res = ct.clone();
+        self.scalar_mul_assign(&mut ct_res, scalar);
+        ct_res
+    }
+
+    pub fn scalar_mul_assign<T, Scalar>(&self, lhs: &mut T, scalar: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: ScalarMultiplier + DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(lhs);
+        self.unchecked_scalar_mul_assign(lhs, scalar);
+    }
+
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 1u64;
+    /// let power = 2;
+    ///
+    /// let ct = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a scalar multiplication:
+    /// let ct_res = sks.blockshift(&ct, power);
+    ///
+    /// // Decrypt:
+    /// let clear: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(16, clear);
+    /// ```
+    pub fn blockshift<T>(&self, ctxt: &T, shift: usize) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.key.key.blockshift(ctxt, shift)
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/scalar_rotate.rs b/tfhe/src/integer/fpga/server_key/radix/scalar_rotate.rs
new file mode 100644
index 00000000..626006d9
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/scalar_rotate.rs
@@ -0,0 +1,623 @@
+use crate::core_crypto::prelude::CastFrom;
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::BelfortServerKey;
+
+impl BelfortServerKey {
+    //======================================================================
+    //                Rotate Right
+    //======================================================================
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the right by a specified amount,
+    /// `n`, wrapping the truncated bits to the beginning of the resulting integer.
+    ///
+    /// If necessary the carries of the input will be cleaned beforehand,
+    /// but its value won't change, the result is returned in a new ciphertext
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2;
+    ///
+    /// let mut ct = cks.encrypt(msg as u64);
+    ///
+    /// let ct_res = sks.smart_scalar_rotate_right(&mut ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg.rotate_right(n as u32) as u64, dec);
+    /// ```
+    pub fn smart_scalar_rotate_right<T, Scalar>(&self, ct: &mut T, n: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_scalar_rotate_right(ct, n)
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the right by a specified amount,
+    /// `n`, wrapping the truncated bits to the beginning of the resulting integer.
+    ///
+    /// The result is assigned to the input ciphertext
+    ///
+    /// If necessary carries will be cleaned beforehand
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2;
+    ///
+    /// let mut ct = cks.encrypt(msg as u64);
+    ///
+    /// sks.smart_scalar_rotate_right_assign(&mut ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct);
+    /// assert_eq!(msg.rotate_right(n as u32) as u64, dec);
+    /// ```
+    pub fn smart_scalar_rotate_right_assign<T, Scalar>(&self, ct: &mut T, n: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_scalar_rotate_right_assign(ct, n);
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the right by a specified amount,
+    /// `n`, wrapping the truncated bits to the beginning of the resulting integer.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// # Requirements
+    ///
+    /// - The blocks parameter's carry space have at least one more bit than message space
+    /// - The input ciphertext carry buffer is empty / clean
+    ///
+    /// # Output
+    ///
+    /// - The output's carries will be clean
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2;
+    ///
+    /// let ct = cks.encrypt(msg as u64);
+    ///
+    /// let ct_res = sks.scalar_rotate_right(&ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg.rotate_right(n as u32) as u64, dec);
+    /// ```
+    pub fn scalar_rotate_right<T, Scalar>(&self, ct_right: &T, n: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        let mut result = ct_right.clone();
+        self.scalar_rotate_right_assign(&mut result, n);
+        result
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the right by a specified amount,
+    /// `n`, wrapping the truncated bits to the beginning of the resulting integer.
+    ///
+    /// The result is assigned to the input ciphertext
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2;
+    ///
+    /// let mut ct = cks.encrypt(msg as u64);
+    ///
+    /// sks.scalar_rotate_right_assign(&mut ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct);
+    /// assert_eq!(msg.rotate_right(n as u32) as u64, dec);
+    /// ```
+    pub fn scalar_rotate_right_assign<T, Scalar>(&self, ct: &mut T, n: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_scalar_rotate_right_assign(ct, n);
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the right by a specified amount,
+    /// `n`, wrapping the truncated bits to the beginning of the resulting integer.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// # Requirements
+    ///
+    /// - The blocks parameter's carry space have at least one more bit than message space
+    /// - The input ciphertext carry buffer is empty / clean
+    ///
+    /// # Output
+    ///
+    /// - The output's carries will be clean
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2;
+    ///
+    /// let ct = cks.encrypt(msg as u64);
+    ///
+    /// let ct_res = sks.unchecked_scalar_rotate_right(&ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg.rotate_right(n as u32) as u64, dec);
+    /// ```
+    pub fn unchecked_scalar_rotate_right<T, Scalar>(&self, ct: &T, n: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        let mut result = ct.clone();
+        self.unchecked_scalar_rotate_right_assign(&mut result, n);
+        result
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the right by a specified amount,
+    /// `n`, wrapping the truncated bits to the beginning of the resulting integer.
+    ///
+    /// The result is assigned to the input ciphertext
+    ///
+    /// # Requirements
+    ///
+    /// - The blocks parameter's carry space have at least one more bit than message space
+    /// - The input ciphertext carry buffer is empty / clean
+    ///
+    /// # Output
+    ///
+    /// - The output's carries will be clean
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2;
+    ///
+    /// let mut ct = cks.encrypt(msg as u64);
+    ///
+    /// sks.unchecked_scalar_rotate_right_assign(&mut ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct);
+    /// assert_eq!(msg.rotate_right(n as u32) as u64, dec);
+    /// ```
+    pub fn unchecked_scalar_rotate_right_assign<T, Scalar>(&self, ct: &mut T, n: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        // We know by how much we want to
+        // rotate since `n` is a clear value.
+        //
+        // Implement rotating in two step
+        // 1) rotate blocks
+        // 2) shift within each block and `propagate' the next one
+        let integer_key = &self.key.key;
+        debug_assert!(ct.block_carries_are_empty());
+        debug_assert!(integer_key.carry_modulus().0 >= integer_key.message_modulus().0 / 2);
+
+        let num_bits_in_message = integer_key.message_modulus().0.ilog2() as u64;
+        let num_blocks = ct.blocks().len();
+        let total_num_bits = num_bits_in_message * num_blocks as u64;
+
+        let n = u64::cast_from(n) % total_num_bits;
+        if n == 0 {
+            return;
+        }
+
+        let rotations = (n / num_bits_in_message) as usize;
+
+        // rotate left as the blocks are from LSB to MSB
+        ct.blocks_mut().rotate_left(rotations);
+
+        let shift_within_block = n % num_bits_in_message;
+        if shift_within_block == 0 {
+            return;
+        }
+
+        let lut_name = "shift_and_propagate_swb1";
+        let mut new_blocks = (0..num_blocks)
+            .into_iter()
+            .map(|index| {
+                // rotate_right means moving bits from MSB to LSB
+                // Since our blocks are from LSB to MSB, bits move from
+                // block `index + 1` to `index`
+                let bit_receiver_index = index;
+                let bit_giver_index = (index + 1) % num_blocks;
+
+                let mut bit_receiver_block = ct.blocks()[bit_receiver_index].clone();
+                let bit_giver_block = ct.blocks()[bit_giver_index].clone();
+
+                integer_key.pack_block_assign(&bit_giver_block, &mut bit_receiver_block);
+
+                bit_receiver_block
+            })
+            .collect::<Vec<_>>();
+
+        self.apply_same_lookup_table_packed_assign(&mut new_blocks, lut_name);
+        ct.blocks_mut().swap_with_slice(&mut new_blocks);
+
+        debug_assert!(ct.block_carries_are_empty());
+    }
+
+    //======================================================================
+    //                Rotate Left
+    //======================================================================
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the left by a specified amount,
+    /// `n`, wrapping the truncated bits to the end of the resulting integer.
+    ///
+    /// If necessary the carries of the input will be cleaned beforehand,
+    /// but its value won't change, the result is returned in a new ciphertext
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2u32;
+    ///
+    /// let mut ct = cks.encrypt(msg as u64);
+    ///
+    /// let ct_res = sks.smart_scalar_rotate_left(&mut ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg.rotate_left(n as u32) as u64, dec);
+    /// ```
+    pub fn smart_scalar_rotate_left<T, Scalar>(&self, ct: &mut T, n: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_scalar_rotate_left(ct, n)
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the left by a specified amount,
+    /// `n`, wrapping the truncated bits to the end of the resulting integer.
+    ///
+    /// The result is assigned to the input ciphertext
+    ///
+    /// If necessary carries will be cleaned beforehand
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2u32;
+    ///
+    /// let mut ct = cks.encrypt(msg as u64);
+    ///
+    /// sks.smart_scalar_rotate_left_assign(&mut ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct);
+    /// assert_eq!(msg.rotate_left(n as u32) as u64, dec);
+    /// ```
+    pub fn smart_scalar_rotate_left_assign<T, Scalar>(&self, ct: &mut T, n: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_scalar_rotate_left_assign(ct, n);
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the left by a specified amount,
+    /// `n`, wrapping the truncated bits to the end of the resulting integer.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// # Requirements
+    ///
+    /// - The blocks parameter's carry space have at least one more bit than message space
+    /// - The input ciphertext carry buffer is empty / clean
+    ///
+    /// # Output
+    ///
+    /// - The output's carries will be clean
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2u32;
+    ///
+    /// let ct = cks.encrypt(msg as u64);
+    ///
+    /// let ct_res = sks.scalar_rotate_left(&ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg.rotate_left(n as u32) as u64, dec);
+    /// ```
+    pub fn scalar_rotate_left<T, Scalar>(&self, ct_left: &T, n: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        let mut result = ct_left.clone();
+        self.scalar_rotate_left_assign(&mut result, n);
+        result
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the left by a specified amount,
+    /// `n`, wrapping the truncated bits to the end of the resulting integer.
+    ///
+    /// The result is assigned to the input ciphertext
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2u32;
+    ///
+    /// let mut ct = cks.encrypt(msg as u64);
+    ///
+    /// sks.scalar_rotate_left_assign(&mut ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct);
+    /// assert_eq!(msg.rotate_left(n as u32) as u64, dec);
+    /// ```
+    pub fn scalar_rotate_left_assign<T, Scalar>(&self, ct: &mut T, n: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_scalar_rotate_left_assign(ct, n);
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the left by a specified amount,
+    /// `n`, wrapping the truncated bits to the end of the resulting integer.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// # Requirements
+    ///
+    /// - The blocks parameter's carry space have at least one more bit than message space
+    /// - The input ciphertext carry buffer is empty / clean
+    ///
+    /// # Output
+    ///
+    /// - The output's carries will be clean
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2u32;
+    ///
+    /// let ct = cks.encrypt(msg as u64);
+    ///
+    /// let ct_res = sks.unchecked_scalar_rotate_left(&ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg.rotate_left(n as u32) as u64, dec);
+    /// ```
+    pub fn unchecked_scalar_rotate_left<T, Scalar>(&self, ct: &T, n: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        let mut result = ct.clone();
+        self.unchecked_scalar_rotate_left_assign(&mut result, n);
+        result
+    }
+
+    /// Computes homomorphically a rotation of bits.
+    ///
+    /// Shifts the bits to the left by a specified amount,
+    /// `n`, wrapping the truncated bits to the end of the resulting integer.
+    ///
+    /// The result is assigned to the input ciphertext
+    ///
+    /// # Requirements
+    ///
+    /// - The blocks parameter's carry space have at least one more bit than message space
+    /// - The input ciphertext carry buffer is empty / clean
+    ///
+    /// # Output
+    ///
+    /// - The output's carries will be clean
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128u8;
+    /// let n = 2u32;
+    ///
+    /// let mut ct = cks.encrypt(msg as u64);
+    ///
+    /// sks.unchecked_scalar_rotate_left_assign(&mut ct, n);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct);
+    /// assert_eq!(msg.rotate_left(n as u32) as u64, dec);
+    /// ```
+    pub fn unchecked_scalar_rotate_left_assign<T, Scalar>(&self, ct: &mut T, n: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        // We know by how much we will rotate since `n` is a clear value.
+        //
+        // Implement rotating in two steps
+        // 1) rotate blocks
+        // 2) shift within each block and 'propagate' to the next one
+        let integer_key = &self.key.key;
+        debug_assert!(ct.block_carries_are_empty());
+        debug_assert!(integer_key.carry_modulus().0 >= integer_key.message_modulus().0 / 2);
+
+        let num_bits_in_message = integer_key.message_modulus().0.ilog2() as u64;
+        let num_blocks = ct.blocks().len();
+        let total_num_bits = num_bits_in_message * num_blocks as u64;
+
+        let n = u64::cast_from(n) % total_num_bits;
+        if n == 0 {
+            return;
+        }
+
+        let rotations = (n / num_bits_in_message) as usize;
+        let shift_within_block = n % num_bits_in_message;
+
+        // rotate right as the blocks are from LSB to MSB
+        ct.blocks_mut().rotate_right(rotations);
+
+        if shift_within_block == 0 {
+            return;
+        }
+
+        let lut_name = "create_blocks_swb1";
+        let mut new_blocks = (0..num_blocks)
+            .into_iter()
+            .map(|index| {
+                // Since our blocks are from LSB to MSB, bits move from
+                // block `index - 1` to `index`
+                let bit_receiver_index = index;
+                let bit_giver_index = if index == 0 {
+                    num_blocks - 1
+                } else {
+                    index - 1
+                };
+
+                let bit_receiver_block = ct.blocks()[bit_receiver_index].clone();
+                let mut bit_giver_block = ct.blocks()[bit_giver_index].clone();
+
+                integer_key.pack_block_assign(&bit_receiver_block, &mut bit_giver_block);
+
+                bit_giver_block
+            })
+            .collect::<Vec<_>>();
+
+        self.apply_same_lookup_table_packed_assign(&mut new_blocks, lut_name);
+        ct.blocks_mut().swap_with_slice(&mut new_blocks[0..]);
+
+        debug_assert!(ct.block_carries_are_empty());
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/scalar_shift.rs b/tfhe/src/integer/fpga/server_key/radix/scalar_shift.rs
new file mode 100644
index 00000000..f6f28d07
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/scalar_shift.rs
@@ -0,0 +1,686 @@
+use crate::core_crypto::commons::utils::izip;
+use crate::core_crypto::fpga::BelfortFpgaLuts;
+use crate::core_crypto::prelude::CastFrom;
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::BelfortLookupTable;
+use crate::shortint::ciphertext::Degree;
+use crate::shortint::Ciphertext;
+use crate::BelfortServerKey;
+
+impl BelfortServerKey {
+    //======================================================================
+    //                Shift Right
+    //======================================================================
+
+    /// Computes homomorphically a right shift.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// # Requirements
+    ///
+    /// - The blocks parameter's carry space have at least one more bit than message space
+    /// - The input ciphertext carry buffer is empty / clean
+    ///
+    /// # Output
+    ///
+    /// - The output's carries will be clean
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128;
+    /// let shift = 2;
+    ///
+    /// let ct = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a right shift:
+    /// let ct_res = sks.unchecked_scalar_right_shift(&ct, shift);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg >> shift, dec);
+    /// ```
+    pub fn unchecked_scalar_right_shift<T, Scalar>(&self, ct: &T, shift: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        let mut result = ct.clone();
+        self.unchecked_scalar_right_shift_assign(&mut result, shift);
+        result
+    }
+
+    /// Computes homomorphically a right shift.
+    ///
+    /// # Requirements
+    ///
+    /// - The blocks parameter's carry space have at at least (message_bits - 1)
+    /// - The input ciphertext carry buffer is empty / clean
+    ///
+    /// # Output
+    ///
+    /// - The carry of the output blocks will be empty / clean
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 18;
+    /// let shift = 4;
+    ///
+    /// let mut ct = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a right shift:
+    /// sks.unchecked_scalar_right_shift_assign(&mut ct, shift);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct);
+    /// assert_eq!(msg >> shift, dec);
+    /// ```
+    pub fn unchecked_scalar_right_shift_assign<T, Scalar>(&self, ct: &mut T, shift: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        if T::IS_SIGNED {
+            self.unchecked_scalar_right_shift_arithmetic_assign(ct, shift);
+        } else {
+            self.unchecked_scalar_right_shift_logical_assign(ct, shift);
+        }
+
+        debug_assert!(ct.block_carries_are_empty());
+    }
+
+    pub fn unchecked_scalar_right_shift_arithmetic<T, Scalar>(&self, ct: &T, shift: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        let mut result = ct.clone();
+        self.unchecked_scalar_right_shift_arithmetic_assign(&mut result, shift);
+        result
+    }
+
+    pub fn unchecked_scalar_right_shift_arithmetic_assign<T, Scalar>(
+        &self,
+        ct: &mut T,
+        shift: Scalar,
+    ) where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        // The general idea is that we know by how much we shift
+        // since `shift` is a clear value.
+        //
+        // So we can implement shifting in two steps
+        // 1) shift blocks (implemented by using rotate + replace with trivial ciphertext block
+        //    which 'wrapped around`
+        // 2) shift within each block and 'propagate' block to the next one
+        //
+        debug_assert!(ct.block_carries_are_empty());
+        let server_key = &self.key.key;
+        let carry_modulus = server_key.message_modulus().0;
+        let message_modulus = server_key.carry_modulus().0;
+        debug_assert!(carry_modulus >= message_modulus / 2);
+
+        let num_bits_in_block = message_modulus.ilog2() as u64;
+        let num_blocks = ct.blocks().len();
+        let total_num_bits = num_bits_in_block * num_blocks as u64;
+
+        let shift = u64::cast_from(shift) % total_num_bits;
+        if shift == 0 {
+            return;
+        }
+
+        let rotations = ((shift / num_bits_in_block) as usize).min(num_blocks);
+        let shift_within_block = shift % num_bits_in_block;
+
+        // rotate left as the blocks are from LSB to MSB
+        ct.blocks_mut().rotate_left(rotations);
+
+        if num_bits_in_block == 1 {
+            // if there is only 1 bit in the msg part, it means shift_within block is 0
+            // thus only rotations are required.
+
+            // We still need to pad with the value of the sign bit.
+            // And here since a block only has 1 bit of message
+            // we can optimize things by not doing the pbs to extract this sign bit
+            let sign_bit = ct.blocks()[num_blocks - rotations - 1].clone();
+            for block in &mut ct.blocks_mut()[num_blocks - rotations..] {
+                block.clone_from(&sign_bit);
+            }
+            return;
+        }
+
+        // In the arithmetic shift case we pad with the value of the sign bit.
+        //
+        // This requires a different shifting lut than in the logical shift case
+        // and another PBS to create the padding block.
+        let (last_shifted_block, padding_block) = {
+            let last_block = &ct.blocks()[num_blocks - rotations - 1];
+
+            let last_block_lut = match shift_within_block {
+                0 => "last_block_swb0",
+                1 => "last_block_swb1",
+                _ => panic!("Unexpected shift value: {:?}", shift_within_block),
+            };
+
+            let pad_block_creator_lut = "pad_block_creator";
+
+            let lut_vec: Vec<BelfortLookupTable> = vec![
+                BelfortFpgaLuts::lut_by_name(last_block_lut, &server_key.key),
+                BelfortFpgaLuts::lut_by_name(pad_block_creator_lut, &server_key.key),
+            ];
+            let mut ct_vec: Vec<Ciphertext> = vec![last_block.clone(), last_block.clone()];
+
+            self.apply_lookup_table_packed_assign(&mut ct_vec, &lut_vec);
+
+            (ct_vec[0].clone(), ct_vec[1].clone())
+        };
+
+        let partial_blocks = self.unchecked_scalar_right_shift_inner_blocks(
+            &ct.blocks()[..num_blocks - rotations],
+            shift_within_block,
+        );
+
+        ct.blocks_mut()[num_blocks - rotations - 1] = last_shifted_block;
+
+        // We started with num_blocks, discarded 'rotations' blocks
+        // and did the last one separately
+        let blocks_to_replace = &mut ct.blocks_mut()[..num_blocks - rotations - 1];
+        assert_eq!(partial_blocks.len(), blocks_to_replace.len());
+        for (block, shifted_block) in izip!(blocks_to_replace, partial_blocks) {
+            *block = shifted_block;
+        }
+
+        // Replace blocks 'pulled' from the left with the correct padding block
+        for trivial_block in &mut ct.blocks_mut()[num_blocks - rotations..] {
+            trivial_block.clone_from(&padding_block);
+        }
+
+        debug_assert!(ct.block_carries_are_empty());
+    }
+
+    pub fn unchecked_scalar_right_shift_logical_assign<T, Scalar>(&self, ct: &mut T, shift: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        // The general idea, is that we know by how much to shift
+        // since `shift` is a clear value.
+        //
+        // So we can implement shifting in two steps
+        // 1) shift blocks (implemented by using rotate + replace with trivial ciphertext block
+        //    which 'wrapped around`
+        // 2) shift within each block and 'propagate' block to the next one
+
+        debug_assert!(ct.block_carries_are_empty());
+        let shortint_key = &self.key.key.key;
+        let carry_modulus = shortint_key.carry_modulus.0;
+        let message_modulus = shortint_key.message_modulus.0;
+        debug_assert!(carry_modulus >= message_modulus);
+
+        let num_bits_in_block = message_modulus.ilog2() as u64;
+        let num_blocks = ct.blocks().len();
+        let total_num_bits = num_bits_in_block * num_blocks as u64;
+
+        let shift = u64::cast_from(shift) % total_num_bits;
+        if shift == 0 {
+            return;
+        }
+
+        let rotations = ((shift / num_bits_in_block) as usize).min(num_blocks);
+        let shift_within_block = shift % num_bits_in_block;
+
+        // rotate left as the blocks are from LSB to MSB
+        ct.blocks_mut().rotate_left(rotations);
+        for block in &mut ct.blocks_mut()[num_blocks - rotations..] {
+            shortint_key.create_trivial_assign(block, 0);
+        }
+
+        if shift_within_block == 0 || rotations == num_blocks {
+            // Logical shift means pulling 0s, so we are done now
+            return;
+        }
+
+        let partial_blocks = self.unchecked_scalar_right_shift_inner_blocks(
+            &ct.blocks()[..num_blocks - rotations],
+            shift_within_block,
+        );
+        let last_shifted_block: Ciphertext = {
+            // The right-most block is done separately as it does not
+            // need to recuperate the shifted bits from its right neighbour.
+            let mut block = ct.blocks()[num_blocks - rotations - 1].clone();
+
+            // Apply mutation to the cloned block
+            if shift_within_block == 1 {
+                let degree = block.degree;
+                self.apply_lookup_table_single_assign(&mut block, "right_shift_1");
+                block.degree = Degree::new(degree.get() >> 1);
+            }
+            block
+        };
+
+        ct.blocks_mut()[num_blocks - rotations - 1] = last_shifted_block;
+        // We started with num_blocks, discarded 'rotations' blocks
+        // and did the last one separately
+        let blocks_to_replace = &mut ct.blocks_mut()[..num_blocks - rotations - 1];
+        assert_eq!(partial_blocks.len(), blocks_to_replace.len());
+        for (block, shifted_block) in izip!(blocks_to_replace, partial_blocks) {
+            *block = shifted_block;
+        }
+
+        debug_assert!(ct.block_carries_are_empty());
+    }
+
+    /// This is in internal function to share logic between
+    /// logical right shift and arithmetic right shift.
+    ///
+    /// This functions takes a slice of blocks in little endian order
+    /// and computes right shifting of bits where each blocks pulls bits
+    /// from its right-neighbour.
+    ///
+    /// This means the returned Vec has size `inner_blocks.len() - 1`,
+    /// the block at index `inner_blocks.len() - 1` needs to be handled
+    /// by the caller (arithmetic vs logical right shift).
+    fn unchecked_scalar_right_shift_inner_blocks(
+        &self,
+        inner_blocks: &[Ciphertext],
+        shift_within_block: u64,
+    ) -> Vec<Ciphertext> {
+        let integer_key = &self.key.key;
+        let message_modulus = integer_key.message_modulus().0 as u64;
+        let num_bits_in_block = message_modulus.ilog2() as u64;
+
+        assert!(shift_within_block < num_bits_in_block);
+        assert!(!inner_blocks.is_empty());
+
+        // Since we require that carries are empty,
+        // we can use the bivariate pbs to shift and propagate in parallel at the same time
+        // instead of first shifting then propagating
+        let lut = match shift_within_block {
+            0 => "shift_and_propagate_swb0",
+            1 => "shift_and_propagate_swb1",
+            _ => panic!("Unexpected shift value: {:?}", shift_within_block),
+        };
+
+        let mut inner_blocks_vec = inner_blocks
+            .windows(2)
+            .map(|blocks| {
+                // We are right-shifting,
+                // so we get the bits from the next block in the vec
+                let (mut current_block, next_block) = (blocks[0].clone(), blocks[1].clone());
+                integer_key.pack_block_assign(&next_block, &mut current_block);
+
+                current_block
+            })
+            .collect::<Vec<_>>();
+
+        self.apply_same_lookup_table_packed_assign(&mut inner_blocks_vec, lut);
+
+        inner_blocks_vec
+    }
+
+    /// Computes homomorphically a right shift.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128;
+    /// let shift = 2;
+    ///
+    /// let ct = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a right shift:
+    /// let ct_res = sks.scalar_right_shift(&ct, shift);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg >> shift, dec);
+    /// ```
+    pub fn scalar_right_shift<T, Scalar>(&self, ct: &T, shift: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        let mut result = ct.clone();
+        self.scalar_right_shift_assign(&mut result, shift);
+        result
+    }
+
+    /// Computes homomorphically a right shift.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 18;
+    /// let shift = 4;
+    ///
+    /// let mut ct = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a right shift:
+    /// sks.scalar_right_shift_assign(&mut ct, shift);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct);
+    /// assert_eq!(msg >> shift, dec);
+    /// ```
+    pub fn scalar_right_shift_assign<T, Scalar>(&self, ct: &mut T, shift: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_scalar_right_shift_assign(ct, shift);
+    }
+
+    //======================================================================
+    //                Shift Left
+    //======================================================================
+
+    /// Computes homomorphically a left shift by a scalar.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// # Requirements
+    ///
+    /// - The blocks parameter's carry space have at least one more bit than message space
+    /// - The input ciphertext carry buffer is empty / clean
+    ///
+    /// # Output
+    ///
+    /// - The output ciphertext carry buffers will be clean / empty
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 21;
+    /// let shift = 2;
+    ///
+    /// let ct1 = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a left shift:
+    /// let ct_res = sks.unchecked_scalar_left_shift(&ct1, shift);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg << shift, dec);
+    /// ```
+    pub fn unchecked_scalar_left_shift<T, Scalar>(&self, ct_left: &T, shift: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        let mut result = ct_left.clone();
+        self.unchecked_scalar_left_shift_assign(&mut result, shift);
+        result
+    }
+
+    /// Computes homomorphically a left shift by a scalar.
+    ///
+    /// The result is assigned in the input ciphertext
+    ///
+    /// # Requirements
+    ///
+    /// - The blocks parameter's carry space have at least (message_bits - 1)
+    /// - The input ciphertext carry buffer is empty / clean
+    ///
+    /// # Output
+    ///
+    /// - The ct carry buffers will be clean / empty afterwards
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 13;
+    /// let shift = 2;
+    ///
+    /// let mut ct = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a left shift:
+    /// sks.unchecked_scalar_left_shift_assign(&mut ct, shift);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct);
+    /// assert_eq!(msg << shift, dec);
+    /// ```
+    pub fn unchecked_scalar_left_shift_assign<T, Scalar>(&self, ct: &mut T, shift: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        // The general idea, is that we know by how much we want to shift
+        // since `shift` is a clear value.
+        //
+        // So we can use that to implement shifting in two step
+        // 1) shift blocks (implemented by using rotate + replace with trivial ciphertext block
+        //    which 'wrapped around`
+        // 2) shift within each block in propagate block to the next one
+
+        debug_assert!(ct.block_carries_are_empty());
+        let integer_key = &self.key.key;
+        let shortint_key = &integer_key.key;
+        let carry_modulus = shortint_key.carry_modulus.0;
+        let message_modulus = shortint_key.message_modulus.0;
+        debug_assert!(carry_modulus >= message_modulus / 2);
+
+        let num_bits_in_block = message_modulus.ilog2() as u64;
+        let total_num_bits = num_bits_in_block * ct.blocks().len() as u64;
+
+        let shift = u64::cast_from(shift) % total_num_bits;
+        if shift == 0 {
+            return;
+        }
+
+        let rotations = ((shift / num_bits_in_block) as usize).min(ct.blocks().len());
+        let shift_within_block = shift % num_bits_in_block;
+
+        // rotate right as the blocks are from LSB to MSB
+        ct.blocks_mut().rotate_right(rotations);
+        // Every block below 'rotations' should be discarded
+        for block in &mut ct.blocks_mut()[..rotations] {
+            shortint_key.create_trivial_assign(block, 0);
+        }
+
+        if shift_within_block == 0 || rotations == ct.blocks().len() {
+            return;
+        }
+
+        //
+
+        // Since we require that carries are empty,
+        // we can use the bivariate bps to shift and propagate in parallel at the same time
+        // instead of first shifting then propagating
+        //
+        // The first block is done separately as it does not
+        // need to recuperate the shifted bits from its previous block,
+        // and also that way is does not need a special case for when rotations == 0
+
+        let lut = "create_blocks_swb1";
+
+        let mut partial_blocks = ct.blocks()[rotations..]
+            .windows(2)
+            .map(|blocks| {
+                // We are right-shifting,
+                // so we get the bits from the next block in the vec
+                let (mut previous_block, current_block) = (blocks[0].clone(), blocks[1].clone());
+                integer_key.pack_block_assign(&current_block, &mut previous_block);
+
+                previous_block
+            })
+            .collect::<Vec<_>>();
+
+        let block = ct.blocks()[rotations].clone();
+        partial_blocks.push(block);
+
+        let mut luts =
+            vec![BelfortFpgaLuts::lut_by_name(lut, shortint_key); partial_blocks.len() - 1];
+        luts.push(BelfortFpgaLuts::lut_by_name("shift1_mod", shortint_key));
+
+        self.apply_lookup_table_packed_assign(&mut partial_blocks, &luts);
+
+        let block = partial_blocks.pop().unwrap();
+
+        // We started with num_blocks, discarded 'rotations' blocks
+        // and did the last one separately
+        ct.blocks_mut()[rotations] = block;
+        let blocks_to_replace = &mut ct.blocks_mut()[rotations + 1..];
+        assert_eq!(partial_blocks.len(), blocks_to_replace.len());
+        for (block, shifted_block) in izip!(blocks_to_replace, partial_blocks) {
+            *block = shifted_block;
+        }
+        debug_assert!(ct.block_carries_are_empty());
+    }
+
+    /// Computes homomorphically a left shift by a scalar.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 21;
+    /// let shift = 2;
+    ///
+    /// let ct1 = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a left shift:
+    /// let ct_res = sks.scalar_left_shift(&ct1, shift);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg << shift, dec);
+    /// ```
+    pub fn scalar_left_shift<T, Scalar>(&self, ct_left: &T, shift: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        let mut result = ct_left.clone();
+        self.scalar_left_shift_assign(&mut result, shift);
+        result
+    }
+
+    /// Computes homomorphically a left shift by a scalar.
+    ///
+    /// The result is assigned in the input ciphertext
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 13;
+    /// let shift = 2;
+    ///
+    /// let mut ct = cks.encrypt(msg);
+    ///
+    /// // Compute homomorphically a right shift:
+    /// sks.scalar_left_shift_assign(&mut ct, shift);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct);
+    /// assert_eq!(msg << shift, dec);
+    /// ```
+    pub fn scalar_left_shift_assign<T, Scalar>(&self, ct: &mut T, shift: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        u64: CastFrom<Scalar>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_scalar_left_shift_assign(ct, shift);
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/scalar_sub.rs b/tfhe/src/integer/fpga/server_key/radix/scalar_sub.rs
new file mode 100644
index 00000000..585bb028
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/scalar_sub.rs
@@ -0,0 +1,159 @@
+use crate::core_crypto::prelude::{SignedNumeric, UnsignedNumeric};
+use crate::integer::block_decomposition::DecomposableInto;
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::integer::server_key::TwosComplementNegation;
+use crate::integer::{BooleanBlock, RadixCiphertext, SignedRadixCiphertext};
+use log::warn;
+
+impl BelfortServerKey {
+    /// Computes homomorphically a subtraction of a ciphertext by a scalar.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    pub fn scalar_sub<T, Scalar>(&self, ct: &T, scalar: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: TwosComplementNegation + DecomposableInto<u8>,
+    {
+        let mut ct_res = ct.clone();
+        self.scalar_sub_assign(&mut ct_res, scalar);
+        ct_res
+    }
+
+    pub fn scalar_sub_assign<T, Scalar>(&self, ct: &mut T, scalar: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: TwosComplementNegation + DecomposableInto<u8>,
+    {
+        self.conditional_full_propagate(ct);
+        let integer_key = &self.key.key;
+
+        integer_key.unchecked_scalar_sub_assign(ct, scalar);
+
+        if integer_key.is_eligible_for_parallel_single_carry_propagation(ct.blocks().len()) {
+            self.propagate_single_carry_parallelized_low_latency(ct.blocks_mut());
+        } else {
+            self.full_propagate(ct);
+        }
+    }
+    pub fn unchecked_scalar_sub<T, Scalar>(&self, ct: &mut T, scalar: Scalar) -> T
+    where
+        Scalar: TwosComplementNegation + DecomposableInto<u8>,
+        T: IntegerRadixCiphertext,
+    {
+        self.key.key.unchecked_scalar_sub(ct, scalar)
+    }
+
+    /// Computes homomorphically a subtraction of a ciphertext by a scalar.
+    pub fn smart_scalar_sub<T, Scalar>(&self, ct: &mut T, scalar: Scalar) -> T
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: TwosComplementNegation + DecomposableInto<u8>,
+    {
+        let integer_key = &self.key.key;
+
+        if integer_key.is_scalar_sub_possible(ct, scalar).is_err() {
+            self.full_propagate(ct);
+        }
+        integer_key.is_scalar_sub_possible(ct, scalar).unwrap();
+        integer_key.unchecked_scalar_sub(ct, scalar)
+    }
+
+    pub fn smart_scalar_sub_assign<T, Scalar>(&self, ct: &mut T, scalar: Scalar)
+    where
+        T: IntegerRadixCiphertext,
+        Scalar: TwosComplementNegation + DecomposableInto<u8>,
+    {
+        let integer_key = &self.key.key;
+        if integer_key.is_scalar_sub_possible(ct, scalar).is_err() {
+            self.full_propagate(ct);
+        }
+        integer_key.is_scalar_sub_possible(ct, scalar).unwrap();
+        integer_key.unchecked_scalar_sub_assign(ct, scalar);
+    }
+
+    pub fn unsigned_overflowing_scalar_sub<T>(
+        &self,
+        lhs: &RadixCiphertext,
+        scalar: T,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: UnsignedNumeric + DecomposableInto<u8> + std::ops::Not<Output = T>,
+    {
+        let mut result = lhs.clone();
+        let overflow = self.unsigned_overflowing_scalar_sub_assign(&mut result, scalar);
+        (result, overflow)
+    }
+
+    pub fn unsigned_overflowing_scalar_sub_assign<T>(
+        &self,
+        lhs: &mut RadixCiphertext,
+        scalar: T,
+    ) -> BooleanBlock
+    where
+        T: UnsignedNumeric + DecomposableInto<u8> + std::ops::Not<Output = T>,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+
+        self.key
+            .key
+            .unsigned_overflowing_scalar_sub_assign_parallelized(lhs, scalar)
+    }
+
+    pub fn signed_overflowing_scalar_sub_assig<Scalar>(
+        &self,
+        lhs: &mut SignedRadixCiphertext,
+        scalar: Scalar,
+    ) -> BooleanBlock
+    where
+        Scalar: SignedNumeric + DecomposableInto<u8> + std::ops::Not<Output = Scalar>,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+
+        self.key
+            .key
+            .signed_overflowing_scalar_sub_assign_parallelized(lhs, scalar)
+    }
+
+    /// This scalar_sub_assign two numbers
+    ///
+    /// It is after the Blelloch algorithm to do
+    /// prefix sum / cumulative sum in parallel.
+    ///
+    /// It is not "work efficient" as in, it does not adds
+    /// that much work compared to other parallel algorithm,
+    /// thus requiring less threads.
+    ///
+    /// However it is slower.
+    ///
+    /// At most num_block / 2 threads are used
+    ///
+    /// # Requirements
+    ///
+    /// - The parameters have 4 bits in total
+    /// - Adding rhs to lhs must not consume more than one carry
+    ///
+    /// # Output
+    ///
+    /// - lhs will have its carries empty
+    pub fn scalar_sub_work_efficient<T, Scalar>(&self, ct: &T, scalar: Scalar) -> T
+    where
+        Scalar: TwosComplementNegation + DecomposableInto<u8>,
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+        assert!(integer_key.message_modulus().0 * integer_key.carry_modulus().0 >= (1 << 3));
+        let mut ct_res = ct.clone();
+        self.conditional_full_propagate(&mut ct_res);
+        integer_key.unchecked_scalar_sub_assign(&mut ct_res, scalar);
+        self.full_propagate_work_efficient(&mut ct_res);
+        ct_res
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/shift.rs b/tfhe/src/integer/fpga/server_key/radix/shift.rs
new file mode 100644
index 00000000..f0b10661
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/shift.rs
@@ -0,0 +1,472 @@
+use crate::integer::ciphertext::{IntegerRadixCiphertext, RadixCiphertext};
+use crate::integer::fpga::server_key::radix::bit_extractor::BitExtractor;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::shortint::Ciphertext;
+
+#[derive(Clone, Copy)]
+pub(super) enum BarrelShifterOperation {
+    LeftRotate,
+    LeftShift,
+    RightShift,
+    RightRotate,
+}
+
+impl BelfortServerKey {
+    //======================================================================
+    //                Shift Right
+    //======================================================================
+
+    pub fn unchecked_right_shift<T>(&self, ct_left: &T, shift: &RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result = ct_left.clone();
+        self.unchecked_right_shift_assign(&mut result, shift);
+        result
+    }
+
+    pub fn unchecked_right_shift_assign<T>(&self, ct: &mut T, shift: &RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.barrel_shifter(ct, shift, BarrelShifterOperation::RightShift);
+    }
+
+    pub fn smart_right_shift_assign<T>(&self, ct: &mut T, shift: &mut RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+
+        rayon::join(
+            || {
+                if !ct.block_carries_are_empty() {
+                    integer_key.full_propagate(ct);
+                }
+            },
+            || {
+                if !shift.block_carries_are_empty() {
+                    integer_key.full_propagate(shift);
+                }
+            },
+        );
+        self.unchecked_right_shift_assign(ct, shift);
+    }
+
+    pub fn smart_right_shift<T>(&self, ct: &mut T, shift: &mut RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+
+        rayon::join(
+            || {
+                if !ct.block_carries_are_empty() {
+                    integer_key.full_propagate(ct);
+                }
+            },
+            || {
+                if !shift.block_carries_are_empty() {
+                    integer_key.full_propagate(shift);
+                }
+            },
+        );
+        self.unchecked_right_shift(ct, shift)
+    }
+
+    pub fn right_shift_assign<T>(&self, ct: &mut T, shift: &RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (
+            ct.block_carries_are_empty(),
+            shift.block_carries_are_empty(),
+        ) {
+            (true, true) => (ct, shift),
+            (true, false) => {
+                tmp_rhs = shift.clone();
+                integer_key.full_propagate(&mut tmp_rhs);
+                (ct, &tmp_rhs)
+            }
+            (false, true) => {
+                integer_key.full_propagate(ct);
+                (ct, shift)
+            }
+            (false, false) => {
+                tmp_rhs = shift.clone();
+                rayon::join(
+                    || integer_key.full_propagate(ct),
+                    || integer_key.full_propagate(&mut tmp_rhs),
+                );
+                (ct, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_right_shift_assign(lhs, rhs);
+    }
+
+    /// Computes homomorphically a right shift by an encrypted amount
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 128;
+    /// let shift = 2;
+    ///
+    /// let ct = cks.encrypt(msg);
+    /// let shift_ct = cks.encrypt(shift as u64);
+    ///
+    /// // Compute homomorphically a right shift:
+    /// let ct_res = sks.right_shift(&ct, &shift_ct);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg >> shift, dec);
+    /// ```
+    pub fn right_shift<T>(&self, ct: &T, shift: &RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct.clone();
+        self.right_shift_assign(&mut ct_res, shift);
+        ct_res
+    }
+
+    //======================================================================
+    //                Shift Left
+    //======================================================================
+
+    /// left shift by and encrypted amount
+    ///
+    /// This requires:
+    /// - ct to have clean carries
+    /// - shift to have clean carries
+    /// - the number of bits in the block to be >= 3
+    pub fn unchecked_left_shift<T>(&self, ct_left: &T, shift: &RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result = ct_left.clone();
+        self.unchecked_left_shift_assign(&mut result, shift);
+        result
+    }
+
+    /// left shift by and encrypted amount
+    ///
+    /// This requires:
+    /// - ct to have clean carries
+    /// - shift to have clean carries
+    /// - the number of bits in the block to be >= 3
+    pub fn unchecked_left_shift_assign<T>(&self, ct: &mut T, shift: &RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.barrel_shifter(ct, shift, BarrelShifterOperation::LeftShift);
+    }
+
+    pub fn smart_left_shift_assign<T>(&self, ct: &mut T, shift: &mut RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+
+        rayon::join(
+            || {
+                if !ct.block_carries_are_empty() {
+                    integer_key.full_propagate(ct);
+                }
+            },
+            || {
+                if !shift.block_carries_are_empty() {
+                    integer_key.full_propagate(shift);
+                }
+            },
+        );
+        self.unchecked_left_shift_assign(ct, shift);
+    }
+
+    pub fn smart_left_shift<T>(&self, ct: &mut T, shift: &mut RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+
+        rayon::join(
+            || {
+                if !ct.block_carries_are_empty() {
+                    integer_key.full_propagate(ct);
+                }
+            },
+            || {
+                if !shift.block_carries_are_empty() {
+                    integer_key.full_propagate(shift);
+                }
+            },
+        );
+        self.unchecked_left_shift(ct, shift)
+    }
+
+    pub fn left_shift_assign<T>(&self, ct: &mut T, shift: &RadixCiphertext)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (
+            ct.block_carries_are_empty(),
+            shift.block_carries_are_empty(),
+        ) {
+            (true, true) => (ct, shift),
+            (true, false) => {
+                tmp_rhs = shift.clone();
+                integer_key.full_propagate(&mut tmp_rhs);
+                (ct, &tmp_rhs)
+            }
+            (false, true) => {
+                integer_key.full_propagate(ct);
+                (ct, shift)
+            }
+            (false, false) => {
+                tmp_rhs = shift.clone();
+                rayon::join(
+                    || integer_key.full_propagate(ct),
+                    || integer_key.full_propagate(&mut tmp_rhs),
+                );
+                (ct, &tmp_rhs)
+            }
+        };
+
+        self.unchecked_left_shift_assign(lhs, rhs);
+    }
+
+    /// Computes homomorphically a left shift by an encrypted amount.
+    ///
+    /// The result is returned as a new ciphertext.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let size = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, size);
+    ///
+    /// let msg = 21;
+    /// let shift = 2;
+    ///
+    /// let ct1 = cks.encrypt(msg);
+    /// let ct2 = cks.encrypt(shift as u64);
+    ///
+    /// // Compute homomorphically a left shift:
+    /// let ct_res = sks.left_shift(&ct1, &ct2);
+    ///
+    /// // Decrypt:
+    /// let dec: u64 = cks.decrypt(&ct_res);
+    /// assert_eq!(msg << shift, dec);
+    /// ```
+    pub fn left_shift<T>(&self, ct: &T, shift: &RadixCiphertext) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct.clone();
+        self.left_shift_assign(&mut ct_res, shift);
+        ct_res
+    }
+
+    /// This implements a "barrel shifter".
+    ///
+    /// This construct is what is used in hardware to
+    /// implement left/right shift/rotate
+    ///
+    /// This requires:
+    /// - ct to have clean carries
+    /// - shift to have clean carries
+    /// - the number of bits in the block to be >= 3
+    ///
+    /// Similarly to rust `wrapping_shl/shr` functions
+    /// it removes any high-order bits of `shift`
+    /// that would cause the shift to exceed the bitwidth of the type.
+    ///
+    /// **However**, when the total number of bits represented by the
+    /// radix ciphertext is not a power of two (eg a ciphertext with 12 bits)
+    /// then, it removes bit that are higher than the closest higher power of two.
+    /// So for a 12 bits radix ciphertext, its closest higher power of two is 16,
+    /// thus, any bit that are higher than log2(16) will be removed
+    ///
+    /// `ct` will be assigned the result, and it will be in a fresh state
+    pub(super) fn barrel_shifter<T>(
+        &self,
+        ct: &mut T,
+        shift: &RadixCiphertext,
+        operation: BarrelShifterOperation,
+    ) where
+        T: IntegerRadixCiphertext,
+    {
+        let num_blocks = shift.blocks.len();
+        let shortint_key = &self.key.key.key;
+        let message_bits_per_block: u64 = shortint_key.message_modulus.0.ilog2() as u64;
+        let carry_bits_per_block: u64 = shortint_key.carry_modulus.0.ilog2() as u64;
+        let total_nb_bits = message_bits_per_block * num_blocks as u64; // How many bits are in the shift
+
+        assert!(
+            (message_bits_per_block + carry_bits_per_block) >= 3,
+            "Blocks must have at least 3 bits"
+        );
+
+        let bits = {
+            let bit_extractor =
+                BitExtractor::msg_with_final_offset0(self, message_bits_per_block as usize);
+            bit_extractor.extract_all_bits(ct.blocks())
+        };
+
+        let shift_bits: Vec<Ciphertext> = {
+            let mut max_num_bits_that_tell_shift = total_nb_bits.ilog2() as u64;
+            // This effectively means, that if the block parameters
+            // give a total_nb_bits that is not a power of two,
+            // then the behaviour of shifting won't be the same
+            // if shift >= total_nb_bits compared to when total_nb_bits
+            // is a power of two, as will 'capture' more bits in `shift_bits`
+            if !total_nb_bits.is_power_of_two() {
+                max_num_bits_that_tell_shift += 1;
+            };
+            // Extracts bits and put them in the bit index 2 (=> bit number 3)
+            // so that it is already aligned to the correct position of the cmux input
+            // and we reduce noise growth
+            let bit_extractor =
+                BitExtractor::msg_with_final_offset2(self, message_bits_per_block as usize);
+            bit_extractor.extract_n_bits(&shift.blocks, max_num_bits_that_tell_shift as usize)
+        };
+
+        let offset = match operation {
+            BarrelShifterOperation::LeftShift | BarrelShifterOperation::LeftRotate => 0,
+            BarrelShifterOperation::RightShift | BarrelShifterOperation::RightRotate => {
+                total_nb_bits
+            }
+        };
+
+        let is_right_shift = matches!(operation, BarrelShifterOperation::RightShift);
+        let padding_bit = if T::IS_SIGNED && is_right_shift {
+            // Do an "arithmetic shift" by padding with the sign bit
+            bits.last().unwrap().clone()
+        } else {
+            shortint_key.create_trivial(0)
+        };
+
+        let mut input_bits_a: Vec<Ciphertext> = bits;
+        let mut input_bits_b: Vec<Ciphertext> = input_bits_a.clone();
+        // Buffer used to hold inputs for a bitwise cmux gate, simulated using a PBS
+        let mut mux_inputs: Vec<Ciphertext> = input_bits_a.clone();
+
+        for (d, shift_bit) in shift_bits.iter().enumerate() {
+            for i in 0..total_nb_bits as usize {
+                input_bits_b[i].clone_from(&input_bits_a[i]);
+                shortint_key.create_trivial_assign(&mut mux_inputs[i], 0);
+            }
+
+            match operation {
+                BarrelShifterOperation::LeftShift => {
+                    input_bits_b.rotate_right(1 << d);
+                    for bit_that_wrapped in &mut input_bits_b[..1 << d] {
+                        bit_that_wrapped.clone_from(&padding_bit);
+                    }
+                }
+                BarrelShifterOperation::RightShift => {
+                    input_bits_b.rotate_left(1 << d);
+                    let bits_that_wrapped: &mut [Ciphertext] =
+                        &mut input_bits_b[total_nb_bits as usize - (1 << d)..];
+                    for bit_that_wrapped in bits_that_wrapped {
+                        bit_that_wrapped.clone_from(&padding_bit);
+                    }
+                }
+                BarrelShifterOperation::LeftRotate => {
+                    input_bits_b.rotate_right(1 << d);
+                }
+                BarrelShifterOperation::RightRotate => {
+                    input_bits_b.rotate_left(1 << d);
+                }
+            }
+
+            input_bits_a
+                .iter_mut()
+                .zip(mux_inputs.iter_mut())
+                .enumerate()
+                .for_each(|(i, (a, mux_gate_input))| {
+                    let b = &input_bits_b[((i as u64 + offset) % total_nb_bits) as usize];
+
+                    // pack bits into one block so that we have
+                    // control_bit|b|a
+                    shortint_key.unchecked_add_assign(mux_gate_input, b);
+                    shortint_key.unchecked_scalar_mul_assign(mux_gate_input, 2);
+                    shortint_key.unchecked_add_assign(mux_gate_input, &*a);
+                    // The shift bit is already properly aligned/positioned
+                    shortint_key.unchecked_add_assign(mux_gate_input, shift_bit);
+                });
+
+            // we have
+            //
+            // control_bit|b|a
+            self.apply_same_lookup_table_packed_assign(&mut mux_inputs, "mux");
+
+            input_bits_a
+                .iter_mut()
+                .zip(mux_inputs.iter_mut())
+                .for_each(|(a, mux_gate_input)| {
+                    (*a).clone_from(mux_gate_input);
+                });
+        }
+
+        // rename for clarity
+        let mut output_bits = input_bits_a;
+        assert!(output_bits.len() == message_bits_per_block as usize * num_blocks);
+        // We have to reconstruct blocks from the individual bits
+        output_bits
+            .as_mut_slice()
+            .chunks_exact_mut(message_bits_per_block as usize)
+            .zip(ct.blocks_mut().iter_mut())
+            .for_each(|(grouped_bits, block)| {
+                let (head, last) = grouped_bits.split_at_mut(message_bits_per_block as usize - 1);
+                for bit in head.iter().rev() {
+                    shortint_key.unchecked_scalar_mul_assign(&mut last[0], 2);
+                    shortint_key.unchecked_add_assign(&mut last[0], bit);
+                }
+                // To give back a clean ciphertext
+                std::mem::swap(block, &mut last[0]);
+            });
+        self.apply_same_lookup_table_packed_assign(&mut output_bits, "msg2_extract");
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/slice.rs b/tfhe/src/integer/fpga/server_key/radix/slice.rs
new file mode 100644
index 00000000..ac4adbcb
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/slice.rs
@@ -0,0 +1,280 @@
+use log::warn;
+use std::ops::RangeBounds;
+
+use crate::error::InvalidRangeError;
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::integer::RadixCiphertext;
+use crate::prelude::{CastFrom, CastInto};
+
+impl BelfortServerKey {
+    /// Extract a slice of bits from a ciphertext.
+    ///
+    /// The result is returned as a new ciphertext. This function is more efficient
+    /// if the range starts on a block boundary.
+    ///
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg: u64 = 225;
+    /// let start_bit = 3;
+    /// let end_bit = 6;
+    ///
+    /// // Encrypt the message:
+    /// let ct = cks.encrypt(msg);
+    ///
+    /// let ct_res = sks
+    ///     .unchecked_scalar_bitslice(&ct, start_bit..end_bit)
+    ///     .unwrap();
+    ///
+    /// // Decrypt:
+    /// let clear = cks.decrypt(&ct_res);
+    /// assert_eq!((msg % (1 << end_bit)) >> start_bit, clear);
+    /// ```
+    pub fn unchecked_scalar_bitslice<B, R>(
+        &self,
+        ctxt: &RadixCiphertext,
+        range: R,
+    ) -> Result<RadixCiphertext, InvalidRangeError>
+    where
+        R: RangeBounds<B>,
+        B: CastFrom<usize> + CastInto<usize> + Copy,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .unchecked_scalar_bitslice_parallelized(ctxt, range)
+    }
+
+    /// Extract a slice of bits from a ciphertext.
+    ///
+    /// The result is assigned to the input ciphertext. This function is more efficient
+    /// if the range starts on a block boundary.
+    ///
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg: u64 = 225;
+    /// let start_bit = 3;
+    /// let end_bit = 6;
+    ///
+    /// // Encrypt the message:
+    /// let mut ct = cks.encrypt(msg);
+    ///
+    /// sks.unchecked_scalar_bitslice_assign(&mut ct, start_bit..end_bit)
+    ///     .unwrap();
+    ///
+    /// // Decrypt:
+    /// let clear = cks.decrypt(&ct);
+    /// assert_eq!((msg % (1 << end_bit)) >> start_bit, clear);
+    /// ```
+    pub fn unchecked_scalar_bitslice_assign<B, R>(
+        &self,
+        ctxt: &mut RadixCiphertext,
+        range: R,
+    ) -> Result<(), InvalidRangeError>
+    where
+        R: RangeBounds<B>,
+        B: CastFrom<usize> + CastInto<usize> + Copy,
+    {
+        *ctxt = self.unchecked_scalar_bitslice(ctxt, range)?;
+        Ok(())
+    }
+
+    /// Extract a slice of bits from a ciphertext.
+    ///
+    /// The result is returned as a new ciphertext. This function is more efficient
+    /// if the range starts on a block boundary.
+    ///
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg: u64 = 225;
+    /// let start_bit = 3;
+    /// let end_bit = 6;
+    ///
+    /// // Encrypt the message:
+    /// let ct = cks.encrypt(msg);
+    ///
+    /// let ct_res = sks
+    ///     .scalar_bitslice(&ct, start_bit..end_bit)
+    ///     .unwrap();
+    ///
+    /// // Decrypt:
+    /// let clear = cks.decrypt(&ct_res);
+    /// assert_eq!((msg % (1 << end_bit)) >> start_bit, clear);
+    /// ```
+    pub fn scalar_bitslice<B, R>(
+        &self,
+        ctxt: &RadixCiphertext,
+        range: R,
+    ) -> Result<RadixCiphertext, InvalidRangeError>
+    where
+        R: RangeBounds<B>,
+        B: CastFrom<usize> + CastInto<usize> + Copy,
+    {
+        if ctxt.block_carries_are_empty() {
+            self.unchecked_scalar_bitslice(ctxt, range)
+        } else {
+            let mut ctxt = ctxt.clone();
+            self.full_propagate(&mut ctxt);
+            self.unchecked_scalar_bitslice(&ctxt, range)
+        }
+    }
+
+    /// Extract a slice of bits from a ciphertext.
+    ///
+    /// The result is assigned to the input ciphertext. This function is more efficient
+    /// if the range starts on a block boundary.
+    ///
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg: u64 = 225;
+    /// let start_bit = 3;
+    /// let end_bit = 6;
+    ///
+    /// // Encrypt the message:
+    /// let mut ct = cks.encrypt(msg);
+    ///
+    /// sks.scalar_bitslice_assign(&mut ct, start_bit..end_bit)
+    ///     .unwrap();
+    ///
+    /// // Decrypt:
+    /// let clear = cks.decrypt(&ct);
+    /// assert_eq!((msg % (1 << end_bit)) >> start_bit, clear);
+    /// ```
+    pub fn scalar_bitslice_assign<B, R>(
+        &self,
+        ctxt: &mut RadixCiphertext,
+        range: R,
+    ) -> Result<(), InvalidRangeError>
+    where
+        R: RangeBounds<B>,
+        B: CastFrom<usize> + CastInto<usize> + Copy,
+    {
+        self.conditional_full_propagate(ctxt);
+
+        self.unchecked_scalar_bitslice_assign(ctxt, range)
+    }
+
+    /// Extract a slice of bits from a ciphertext.
+    ///
+    /// The result is returned as a new ciphertext. This function is more efficient
+    /// if the range starts on a block boundary.
+    ///
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg: u64 = 225;
+    /// let start_bit = 3;
+    /// let end_bit = 6;
+    ///
+    /// // Encrypt the message:
+    /// let mut ct = cks.encrypt(msg);
+    ///
+    /// let ct_res = sks
+    ///     .smart_scalar_bitslice(&mut ct, start_bit..end_bit)
+    ///     .unwrap();
+    ///
+    /// // Decrypt:
+    /// let clear = cks.decrypt(&ct_res);
+    /// assert_eq!((msg % (1 << end_bit)) >> start_bit, clear);
+    /// ```
+    pub fn smart_scalar_bitslice<B, R>(
+        &self,
+        ctxt: &mut RadixCiphertext,
+        range: R,
+    ) -> Result<RadixCiphertext, InvalidRangeError>
+    where
+        R: RangeBounds<B>,
+        B: CastFrom<usize> + CastInto<usize> + Copy,
+    {
+        self.conditional_full_propagate(ctxt);
+
+        self.unchecked_scalar_bitslice(ctxt, range)
+    }
+
+    /// Extract a slice of bits from a ciphertext.
+    ///
+    /// The result is assigned to the input ciphertext. This function is more efficient
+    /// if the range starts on a block boundary.
+    ///
+    ///
+    /// # Example
+    ///
+    /// ```rust
+    /// use tfhe::integer::gen_keys_radix;
+    /// use tfhe::shortint::parameters::PARAM_MESSAGE_2_CARRY_2_KS_PBS;
+    ///
+    /// // We have 4 * 2 = 8 bits of message
+    /// let num_blocks = 4;
+    /// let (cks, sks) = gen_keys_radix(PARAM_MESSAGE_2_CARRY_2_KS_PBS, num_blocks);
+    ///
+    /// let msg: u64 = 225;
+    /// let start_bit = 3;
+    /// let end_bit = 6;
+    ///
+    /// // Encrypt the message:
+    /// let mut ct = cks.encrypt(msg);
+    ///
+    /// sks.smart_scalar_bitslice_assign(&mut ct, start_bit..end_bit)
+    ///     .unwrap();
+    ///
+    /// // Decrypt:
+    /// let clear = cks.decrypt(&ct);
+    /// assert_eq!((msg % (1 << end_bit)) >> start_bit, clear);
+    /// ```
+    pub fn smart_scalar_bitslice_assign<B, R>(
+        &self,
+        ctxt: &mut RadixCiphertext,
+        range: R,
+    ) -> Result<(), InvalidRangeError>
+    where
+        R: RangeBounds<B>,
+        B: CastFrom<usize> + CastInto<usize> + Copy,
+    {
+        self.conditional_full_propagate(ctxt);
+
+        self.unchecked_scalar_bitslice_assign(ctxt, range)
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/sub.rs b/tfhe/src/integer/fpga/server_key/radix/sub.rs
new file mode 100644
index 00000000..1c7e70aa
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/sub.rs
@@ -0,0 +1,349 @@
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::{
+    BelfortFpgaLuts, BelfortLookupTable, BelfortServerKey, OutputCarry,
+};
+use crate::integer::server_key::CheckError;
+use crate::integer::{BooleanBlock, RadixCiphertext};
+use crate::shortint::ciphertext::Degree;
+use crate::shortint::Ciphertext;
+use rayon::prelude::*;
+
+impl BelfortServerKey {
+    /// Computes homomorphically the subtraction between ct_left and ct_right.
+    ///
+    /// This function, like all "default" operations (i.e. not smart, checked or unchecked), will
+    /// check that the input ciphertexts block carries are empty and clears them if it's not the
+    /// case and the operation requires it. It outputs a ciphertext whose block carries are always
+    /// empty.
+    ///
+    /// This means that when using only "default" operations, a given operation (like add for
+    /// example) has always the same performance characteristics from one call to another and
+    /// guarantees correctness by pre-emptively clearing carries of output ciphertexts.
+    pub fn sub<T>(&self, ct1: &T, ct2: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ct1.clone();
+        self.sub_assign(&mut ct_res, ct2);
+        ct_res
+    }
+
+    pub fn sub_assign<T>(&self, ct1: &mut T, ct2: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_rhs;
+        let (lhs, rhs) = match (ct1.block_carries_are_empty(), ct2.block_carries_are_empty()) {
+            (true, true) => (ct1, ct2),
+            (true, false) => {
+                tmp_rhs = ct2.clone();
+                self.full_propagate(&mut tmp_rhs);
+                (ct1, &tmp_rhs)
+            }
+            (false, true) => {
+                self.full_propagate(ct1);
+                (ct1, ct2)
+            }
+            (false, false) => {
+                tmp_rhs = ct2.clone();
+                self.full_propagate(ct1);
+                self.full_propagate(&mut tmp_rhs);
+                (ct1, &tmp_rhs)
+            }
+        };
+
+        // if you change params checkout Zama's code for this function
+        let neg = self.key.key.unchecked_neg(rhs);
+        self.unchecked_add_assign_parallelized_low_latency(lhs, &neg);
+    }
+    pub fn unchecked_sub<T>(&self, ct1: &T, ct2: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.key.key.unchecked_sub(ct1, ct2)
+    }
+
+    pub fn unchecked_sub_assign<T>(&self, ct1: &mut T, ct2: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.key.key.unchecked_sub_assign(ct1, ct2);
+    }
+
+    pub fn checked_sub<T>(&self, ct1: &T, ct2: &T) -> Result<T, CheckError>
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.key.key.is_sub_possible(ct1, ct2)?;
+        Ok(self.unchecked_sub(ct1, ct2))
+    }
+
+    pub fn checked_sub_assign<T>(&self, ct_left: &mut T, ct_right: &T) -> Result<(), CheckError>
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.key.key.is_sub_possible(ct_left, ct_right)?;
+        self.unchecked_sub_assign(ct_left, ct_right);
+        Ok(())
+    }
+
+    /// Computes homomorphically the subtraction between ct_left and ct_right.
+    pub fn smart_sub<T>(&self, ct1: &mut T, ct2: &mut T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+
+        if integer_key.is_neg_possible(ct2).is_err() {
+            self.full_propagate(ct2);
+        }
+
+        if integer_key.is_sub_possible(ct1, ct2).is_err() {
+            self.full_propagate(ct1);
+            self.full_propagate(ct2);
+        }
+
+        integer_key.is_sub_possible(ct1, ct2).unwrap();
+
+        let mut result = ct1.clone();
+        self.unchecked_sub_assign(&mut result, ct2);
+
+        result
+    }
+
+    /// Computes homomorphically the subtraction between ct_left and ct_right.
+    pub fn smart_sub_assign<T>(&self, ct1: &mut T, ct2: &mut T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let integer_key = &self.key.key;
+
+        if integer_key.is_neg_possible(ct2).is_err() {
+            self.full_propagate(ct2);
+        }
+
+        if integer_key.is_sub_possible(ct1, ct2).is_err() {
+            self.full_propagate(ct1);
+            self.full_propagate(ct2);
+        }
+
+        integer_key.is_sub_possible(ct1, ct2).unwrap();
+
+        self.unchecked_sub_assign(ct1, ct2);
+    }
+
+    /// Computes the subtraction and returns an indicator of overflow
+    pub fn unsigned_overflowing_sub(
+        &self,
+        ctxt_left: &RadixCiphertext,
+        ctxt_right: &RadixCiphertext,
+    ) -> (RadixCiphertext, BooleanBlock) {
+        let mut tmp_lhs;
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (
+            ctxt_left.block_carries_are_empty(),
+            ctxt_right.block_carries_are_empty(),
+        ) {
+            (true, true) => (ctxt_left, ctxt_right),
+            (true, false) => {
+                tmp_rhs = ctxt_right.clone();
+                self.full_propagate(&mut tmp_rhs);
+                (ctxt_left, &tmp_rhs)
+            }
+            (false, true) => {
+                tmp_lhs = ctxt_left.clone();
+                self.full_propagate(&mut tmp_lhs);
+                (&tmp_lhs, ctxt_right)
+            }
+            (false, false) => {
+                tmp_lhs = ctxt_left.clone();
+                tmp_rhs = ctxt_right.clone();
+                self.full_propagate(&mut tmp_lhs);
+                self.full_propagate(&mut tmp_rhs);
+                (&tmp_lhs, &tmp_rhs)
+            }
+        };
+
+        let (mut res, overflow) = self.unchecked_unsigned_overflowing_sub(lhs, rhs);
+
+        self.full_propagate(&mut res);
+
+        (res, overflow)
+    }
+
+    pub fn unchecked_unsigned_overflowing_sub(
+        &self,
+        lhs: &RadixCiphertext,
+        rhs: &RadixCiphertext,
+    ) -> (RadixCiphertext, BooleanBlock) {
+        // Here we have to use manual unchecked_sub on shortint blocks
+        // rather than calling integer's unchecked_sub as we need each subtraction
+        // to be independent from other blocks. And we don't want to do subtraction by
+        // adding negation
+        assert_eq!(
+            lhs.blocks.len(),
+            rhs.blocks.len(),
+            "Left hand side must must have a number of blocks equal \
+            to the number of blocks of the right hand side: lhs {} blocks, rhs {} blocks",
+            lhs.blocks.len(),
+            rhs.blocks.len()
+        );
+
+        let ct = lhs
+            .blocks
+            .iter()
+            .zip(rhs.blocks.iter())
+            .map(|(lhs_block, rhs_block)| self.key.key.key.unchecked_sub(lhs_block, rhs_block))
+            .collect::<Vec<_>>();
+
+        let mut ct = RadixCiphertext::from(ct);
+        let overflowed = self.unsigned_overflowing_propagate_subtraction_borrow(&mut ct);
+        (ct, overflowed)
+    }
+
+    /// This function takes a ciphertext resulting from a subtraction of 2 clean ciphertexts
+    pub(in crate::integer) fn unsigned_overflowing_propagate_subtraction_borrow(
+        &self,
+        ct: &mut RadixCiphertext,
+    ) -> BooleanBlock {
+        let generates_or_propagates = self.generate_init_borrow_array(ct);
+        let (input_borrows, mut output_borrow) =
+            self.compute_borrow_propagation_parallelized_low_latency(generates_or_propagates);
+
+        ct.blocks
+            .par_iter_mut()
+            .zip(input_borrows.par_iter())
+            .for_each(|(block, input_borrow)| {
+                // Do a true lwe subtraction, as unchecked_sub will adds a correcting term
+                // to avoid overflow (and trashing padding bit). Here we know each
+                // block in the ciphertext is >= 1, and that input borrow is either 0 or 1
+                // so no overflow possible.
+                crate::core_crypto::algorithms::lwe_ciphertext_sub_assign(
+                    &mut block.ct,
+                    &input_borrow.ct,
+                );
+                block.set_noise_level(block.noise_level() + input_borrow.noise_level());
+            });
+
+        let shortint_key = &self.key.key.key;
+        let num_blocks = ct.blocks.len();
+        let msg_lut = BelfortFpgaLuts::lut_by_name("msg2_extract", shortint_key);
+        let msg_lut_indices = vec![msg_lut; num_blocks];
+
+        let mut blocks = ct.blocks.to_vec();
+        self.apply_lookup_table_packed_assign(&mut blocks, &msg_lut_indices);
+
+        ct.blocks
+            .par_iter_mut()
+            .zip(blocks.par_iter())
+            .for_each(|(block, vec_block)| {
+                *block = vec_block.clone();
+            });
+
+        assert!(ct.block_carries_are_empty());
+        // we know here that the result is a boolean value
+        // however the lut used has a degree of 2.
+
+        output_borrow.degree = Degree::new(1);
+
+        BooleanBlock::new_unchecked(output_borrow)
+    }
+    pub(super) fn generate_init_borrow_array(&self, sum_ct: &RadixCiphertext) -> Vec<Ciphertext> {
+        let shortint_key = &self.key.key.key;
+
+        let lut_does_block_generate_borrow =
+            BelfortFpgaLuts::lut_by_name("does_block_generate_borrow", shortint_key);
+        let lut_does_block_generate_or_propagate_borrow =
+            BelfortFpgaLuts::lut_by_name("does_block_generate_or_propagate_borrow", shortint_key);
+
+        let mut lut_indices: Vec<BelfortLookupTable> = Vec::with_capacity(sum_ct.blocks.len());
+
+        sum_ct
+            .blocks
+            .par_iter()
+            .enumerate()
+            .map(|(i, _)| {
+                if i == 0 {
+                    lut_does_block_generate_borrow
+                } else {
+                    lut_does_block_generate_or_propagate_borrow
+                }
+            })
+            .collect_into_vec(&mut lut_indices);
+
+        let mut generates_or_propagates = sum_ct.blocks.to_vec();
+
+        self.apply_lookup_table_packed_assign(&mut generates_or_propagates, &lut_indices);
+
+        generates_or_propagates
+    }
+
+    pub(crate) fn compute_borrow_propagation_parallelized_low_latency(
+        &self,
+        generates_or_propagates: Vec<Ciphertext>,
+    ) -> (Vec<Ciphertext>, Ciphertext) {
+        let num_blocks = generates_or_propagates.len();
+        let mut borrows_out = self.compute_prefix_sum_hillis_steele(
+            generates_or_propagates,
+            |msb, lsb| {
+                if msb == OutputCarry::Propagated as u64 {
+                    lsb
+                } else {
+                    msb
+                }
+            },
+            "carry_propagation_sum".to_owned(),
+        );
+
+        let shortint_key = &self.key.key.key;
+        let mut last_block_out_borrow = shortint_key.create_trivial(0);
+        std::mem::swap(&mut borrows_out[num_blocks - 1], &mut last_block_out_borrow);
+
+        borrows_out.rotate_right(1);
+        shortint_key.create_trivial_assign(&mut borrows_out[0], 0);
+        (borrows_out, last_block_out_borrow)
+    }
+
+    pub fn sub_work_efficient<T>(&self, ctxt_left: &T, ctxt_right: &T) -> T
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut ct_res = ctxt_left.clone();
+        self.sub_assign_work_efficient(&mut ct_res, ctxt_right);
+        ct_res
+    }
+
+    pub fn sub_assign_work_efficient<T>(&self, ctxt_left: &mut T, ctxt_right: &T)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_rhs;
+
+        let (lhs, rhs) = match (
+            ctxt_left.block_carries_are_empty(),
+            ctxt_right.block_carries_are_empty(),
+        ) {
+            (true, true) => (ctxt_left, ctxt_right),
+            (true, false) => {
+                tmp_rhs = ctxt_right.clone();
+                self.full_propagate(&mut tmp_rhs);
+                (ctxt_left, &tmp_rhs)
+            }
+            (false, true) => {
+                self.full_propagate(ctxt_left);
+                (ctxt_left, ctxt_right)
+            }
+            (false, false) => {
+                tmp_rhs = ctxt_right.clone();
+
+                self.full_propagate(ctxt_left);
+                self.full_propagate(&mut tmp_rhs);
+                (ctxt_left, &tmp_rhs)
+            }
+        };
+
+        let neg = self.key.key.unchecked_neg(rhs);
+        self.unchecked_add_assign_work_efficient(lhs, &neg);
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/sum.rs b/tfhe/src/integer/fpga/server_key/radix/sum.rs
new file mode 100644
index 00000000..55946edf
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/sum.rs
@@ -0,0 +1,354 @@
+use crate::integer::ciphertext::IntegerRadixCiphertext;
+use crate::integer::fpga::server_key::{BelfortFpgaLuts, BelfortServerKey};
+
+use crate::integer::{BooleanBlock, RadixCiphertext};
+use crate::shortint::Ciphertext;
+
+use log::warn;
+
+impl BelfortServerKey {
+    /// Computes the sum of the ciphertexts in parallel.
+    ///
+    /// Returns a result that has non propagated carries
+    pub(crate) fn unchecked_partial_sum_ciphertexts_vec<T>(&self, terms: Vec<T>) -> Option<T>
+    where
+        T: IntegerRadixCiphertext,
+    {
+        if terms.is_empty() {
+            return None;
+        }
+
+        if terms.len() == 1 {
+            return Some(terms.into_iter().next().unwrap());
+        }
+
+        let num_blocks = terms[0].blocks().len();
+        assert!(
+            terms[1..].iter().all(|ct| ct.blocks().len() == num_blocks),
+            "Not all ciphertexts have the same number of blocks"
+        );
+
+        if terms.len() == 2 {
+            return Some(self.add(&terms[0], &terms[1]));
+        }
+
+        assert!(
+            terms
+                .iter()
+                .all(IntegerRadixCiphertext::block_carries_are_empty),
+            "All ciphertexts must have empty carries"
+        );
+
+        let integer_key = &self.key.key;
+        let shortint_key = &integer_key.key;
+
+        let message_modulus = integer_key.message_modulus().0;
+        let carry_modulus = integer_key.carry_modulus().0;
+        let total_modulus = message_modulus * carry_modulus;
+        let message_max = message_modulus - 1;
+
+        let num_elements_to_fill_carry = (total_modulus - 1) / message_max;
+
+        // Re-organize radix terms into columns of blocks
+        let mut columns = vec![vec![]; num_blocks];
+        for term in terms {
+            for (i, block) in term.into_blocks().into_iter().enumerate() {
+                if block.degree.get() != 0 {
+                    columns[i].push(block);
+                }
+            }
+        }
+
+        if columns.iter().all(Vec::is_empty) {
+            return Some(integer_key.create_trivial_radix(0, num_blocks));
+        }
+
+        let num_columns = columns.len();
+        // Buffer in which we will store resulting columns after an iteration
+        let mut colum_output_buffer =
+            vec![Vec::<(Ciphertext, Option<Ciphertext>)>::new(); num_blocks];
+
+        let at_least_one_column_has_enough_elements = |columns: &[Vec<Ciphertext>]| {
+            columns.iter().any(|c| c.len() > num_elements_to_fill_carry)
+        };
+
+        while at_least_one_column_has_enough_elements(&columns) {
+            let mut cts_to_extract_msg: Vec<Vec<Ciphertext>> = Vec::new();
+            for column in &columns {
+                let temp = column
+                    .chunks_exact(num_elements_to_fill_carry)
+                    .map(|chunk| {
+                        let mut result = chunk[0].clone();
+                        for c in &chunk[1..] {
+                            shortint_key.unchecked_add_assign(&mut result, c);
+                        }
+                        result
+                    })
+                    .collect();
+                cts_to_extract_msg.push(temp);
+            }
+
+            let cts_to_extract_carry: Vec<Vec<Ciphertext>> = cts_to_extract_msg.clone();
+
+            let mut combined_cts: Vec<Ciphertext> = Vec::new();
+            let mut combined_luts: Vec<crate::core_crypto::fpga::luts::BelfortLookupTable> =
+                Vec::new();
+
+            let sizes = cts_to_extract_msg
+                .iter()
+                .map(|v| v.len())
+                .collect::<Vec<usize>>();
+
+            let mut flattened_msg: Vec<Ciphertext> =
+                cts_to_extract_msg.into_iter().flatten().collect();
+            let mut flattened_carry: Vec<Ciphertext> =
+                cts_to_extract_carry.into_iter().flatten().collect();
+
+            let flattened_len = flattened_msg.len();
+
+            combined_cts.append(&mut flattened_msg);
+            combined_cts.append(&mut flattened_carry);
+
+            let mut luts_msg =
+                vec![BelfortFpgaLuts::lut_by_name("msg2_extract", shortint_key); flattened_len];
+            let mut luts_carry =
+                vec![BelfortFpgaLuts::lut_by_name("carry2_extract", shortint_key); flattened_len];
+
+            combined_luts.append(&mut luts_msg);
+            combined_luts.append(&mut luts_carry);
+
+            self.apply_lookup_table_packed_assign(&mut combined_cts, &combined_luts);
+
+            let (cts_to_extract_msg_slice, cts_to_extract_carry_slice) =
+                combined_cts.split_at(flattened_len);
+            let cts_to_extract_msg = cts_to_extract_msg_slice.to_vec();
+            let cts_to_extract_carry = cts_to_extract_carry_slice.to_vec();
+
+            let mut result_msg = Vec::new();
+            let mut start = 0;
+
+            for size in &sizes {
+                let end = start + size;
+                result_msg.push(cts_to_extract_msg[start..end].to_vec());
+                start = end;
+            }
+
+            let mut result_carry = Vec::new();
+            let mut start = 0;
+
+            for size in &sizes {
+                let end = start + size;
+                result_carry.push(cts_to_extract_carry[start..end].to_vec());
+                start = end;
+            }
+
+            let mut columns_buffer = columns
+                .drain(..)
+                .zip(colum_output_buffer.iter_mut())
+                .enumerate()
+                .map(|(column_index, (mut column, out_buf))| {
+                    if column.len() < num_elements_to_fill_carry {
+                        return column;
+                    }
+
+                    let mut temp: Vec<(Ciphertext, Option<Ciphertext>)> = column
+                        .chunks_exact(num_elements_to_fill_carry)
+                        .enumerate()
+                        .map(|(idx, _)| {
+                            if column_index < num_columns - 1 {
+                                (
+                                    result_msg[column_index][idx].clone(),
+                                    Some(result_carry[column_index][idx].clone()),
+                                )
+                            } else {
+                                (result_msg[column_index][idx].clone(), None)
+                            }
+                        })
+                        .collect();
+
+                    out_buf.clear();
+                    out_buf.append(&mut temp);
+
+                    let num_elem_in_rest = column.len() % num_elements_to_fill_carry;
+                    column.rotate_right(num_elem_in_rest);
+                    column.truncate(num_elem_in_rest);
+                    column
+                })
+                .collect();
+
+            std::mem::swap(&mut columns, &mut columns_buffer);
+
+            // Move resulting message and carry blocks where they belong
+            for (i, column_output) in colum_output_buffer.iter_mut().enumerate() {
+                for (msg, maybe_carry) in column_output.drain(..) {
+                    columns[i].push(msg);
+
+                    if let (Some(carry), true) = (maybe_carry, (i + 1) < columns.len()) {
+                        columns[i + 1].push(carry);
+                    }
+                }
+            }
+        }
+
+        // Reconstruct a radix from the columns
+        let blocks = columns
+            .into_iter()
+            .map(|mut column| {
+                if column.is_empty() {
+                    shortint_key.create_trivial(0)
+                } else {
+                    let (first_block, other_blocks) =
+                        column.as_mut_slice().split_first_mut().unwrap();
+                    for other in other_blocks {
+                        shortint_key.unchecked_add_assign(first_block, other);
+                    }
+                    column.swap_remove(0)
+                }
+            })
+            .collect::<Vec<_>>();
+        assert_eq!(blocks.len(), num_blocks);
+
+        Some(T::from_blocks(blocks))
+    }
+
+    /// Computes the sum of the ciphertexts in parallel.
+    ///
+    /// - Returns None if ciphertexts is empty
+    ///
+    /// - Expects all ciphertexts to have empty carries
+    /// - Expects all ciphertexts to have the same size
+    pub fn unchecked_sum_ciphertexts_vec<T>(&self, ciphertexts: Vec<T>) -> Option<T>
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut result = self.unchecked_partial_sum_ciphertexts_vec(ciphertexts)?;
+
+        self.conditional_full_propagate(&mut result);
+        assert!(result.block_carries_are_empty());
+
+        Some(result)
+    }
+
+    /// See [Self::unchecked_sum_ciphertexts_vec]
+    pub fn unchecked_sum_ciphertexts<'a, T, C>(&self, ciphertexts: C) -> Option<T>
+    where
+        C: IntoIterator<Item = &'a T>,
+        T: IntegerRadixCiphertext + 'a,
+    {
+        let ciphertexts = ciphertexts.into_iter().map(Clone::clone).collect();
+        self.unchecked_sum_ciphertexts_vec(ciphertexts)
+    }
+
+    /// Computes the sum of the ciphertexts.
+    ///
+    /// - Returns None if ciphertexts is empty
+    ///
+    /// See [Self::unchecked_sum_ciphertexts] for constraints
+    pub fn sum_ciphertexts<'a, T, C>(&self, ciphertexts: C) -> Option<T>
+    where
+        C: IntoIterator<Item = &'a T>,
+        T: IntegerRadixCiphertext + 'a,
+    {
+        let mut ciphertexts = ciphertexts
+            .into_iter()
+            .map(Clone::clone)
+            .collect::<Vec<T>>();
+
+        ciphertexts.iter_mut().for_each(|ct| {
+            self.conditional_full_propagate(&mut *ct);
+        });
+
+        self.unchecked_sum_ciphertexts_vec(ciphertexts)
+    }
+
+    // Computes the sum of the ciphertexts.
+    ///
+    /// - Returns None if ciphertexts is empty
+    ///
+    /// See [Self::unchecked_sum_ciphertexts] for constraints
+    pub fn smart_sum_ciphertexts<T, C>(&self, mut ciphertexts: C) -> Option<T>
+    where
+        C: AsMut<[T]> + AsRef<[T]>,
+        T: IntegerRadixCiphertext,
+    {
+        ciphertexts.as_mut().iter_mut().for_each(|ct| {
+            self.conditional_full_propagate(&mut *ct);
+        });
+
+        self.unchecked_sum_ciphertexts(ciphertexts.as_ref())
+    }
+    /// - Expects all ciphertexts to have empty carries
+    /// - Expects all ciphertexts to have the same size
+    pub fn unchecked_unsigned_overflowing_sum_ciphertexts_vec(
+        &self,
+        ciphertexts: Vec<RadixCiphertext>,
+    ) -> Option<(RadixCiphertext, BooleanBlock)> {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .unchecked_unsigned_overflowing_sum_ciphertexts_vec_parallelized(ciphertexts)
+    }
+
+    /// Computes the sum of the unsigned ciphertexts.
+    /// Returns a boolean indicating if the sum overflowed, that is,
+    /// the result did not fit in a ciphertext.
+    ///
+    /// See [Self::unchecked_sum_ciphertexts_vec_parallelized]
+    pub fn unchecked_unsigned_overflowing_sum_ciphertexts<'a, C>(
+        &self,
+        ciphertexts: C,
+    ) -> Option<(RadixCiphertext, BooleanBlock)>
+    where
+        C: IntoIterator<Item = &'a RadixCiphertext>,
+    {
+        let ciphertexts = ciphertexts.into_iter().map(Clone::clone).collect();
+        self.unchecked_unsigned_overflowing_sum_ciphertexts_vec(ciphertexts)
+    }
+
+    /// Computes the sum of the unsigned ciphertexts.
+    /// Returns a boolean indicating if the sum overflowed, that is,
+    /// the result did not fit in a ciphertext.
+    ///
+    /// - Returns None if ciphertexts is empty
+    ///
+    /// See [Self::unchecked_sum_ciphertexts] for constraints
+    pub fn unsigned_overflowing_sum_ciphertexts<'a, C>(
+        &self,
+        ciphertexts: C,
+    ) -> Option<(RadixCiphertext, BooleanBlock)>
+    where
+        C: IntoIterator<Item = &'a RadixCiphertext>,
+    {
+        let mut ciphertexts = ciphertexts
+            .into_iter()
+            .map(Clone::clone)
+            .collect::<Vec<_>>();
+        ciphertexts
+            .iter_mut()
+            .filter(|ct| ct.block_carries_are_empty())
+            .for_each(|ct| self.conditional_full_propagate(ct));
+
+        self.unchecked_unsigned_overflowing_sum_ciphertexts_vec(ciphertexts)
+    }
+
+    /// Computes the sum of the unsigned ciphertexts.
+    /// Returns a boolean indicating if the sum overflowed, that is,
+    /// the result did not fit in a ciphertext.
+    ///
+    /// - Returns None if ciphertexts is empty
+    ///
+    /// See [Self::unchecked_sum_ciphertexts] for constraints
+    pub fn smart_unsigned_overflowing_sum_ciphertexts<C>(
+        &self,
+        mut ciphertexts: C,
+    ) -> Option<(RadixCiphertext, BooleanBlock)>
+    where
+        C: AsMut<[RadixCiphertext]> + AsRef<[RadixCiphertext]>,
+    {
+        ciphertexts.as_mut().iter_mut().for_each(|ct| {
+            self.conditional_full_propagate(ct);
+        });
+
+        self.unchecked_unsigned_overflowing_sum_ciphertexts(ciphertexts.as_ref())
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/mod.rs b/tfhe/src/integer/fpga/server_key/radix/tests/mod.rs
new file mode 100644
index 00000000..6e56647d
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/mod.rs
@@ -0,0 +1,133 @@
+use std::sync::Arc;
+
+use crate::integer::server_key::radix_parallel::tests_cases_unsigned::FunctionExecutor;
+use crate::integer::{RadixCiphertext, RadixClientKey, ServerKey};
+use crate::BelfortServerKey;
+
+pub(crate) mod test_add;
+pub(crate) mod test_bitwise_op;
+pub(crate) mod test_comparison;
+pub(crate) mod test_div_mod;
+pub(crate) mod test_ilog2;
+pub(crate) mod test_mul;
+pub(crate) mod test_neg;
+pub(crate) mod test_propagate;
+pub(crate) mod test_scalar_comparison;
+pub(crate) mod test_scalar_rotate;
+pub(crate) mod test_scalar_shift;
+pub(crate) mod test_sub;
+
+pub(crate) const NB_FPGA: usize = 4;
+
+macro_rules! _timed_execution {
+    ($code:expr) => {{
+        use std::time::Instant;
+        let time_start = Instant::now();
+        let result = $code;
+        let execution_time = time_start.elapsed();
+        println!("     Executed in {:?}", execution_time);
+        result
+    }};
+}
+macro_rules! create_test_default_params {
+    (
+        $name:ident
+    ) => {
+        $crate::integer::tests::create_parametrized_test!($name {
+            coverage => {
+                COVERAGE_PARAM_MESSAGE_2_CARRY_2_KS_PBS,
+            },
+            no_coverage => {
+                PARAM_MESSAGE_2_CARRY_2_KS_PBS,
+            }
+        });
+    };
+}
+pub(crate) use create_test_default_params;
+
+/// The function executor for FPGA server key,
+/// which forwards call to a BelfortServerKey method
+pub(crate) struct FpgaFunctionExecutor<F> {
+    /// The server key is set later, when the test cast calls setup
+    pub(crate) fks: Option<BelfortServerKey>,
+    /// The server key function which will be called
+    pub(crate) func: F,
+}
+
+impl<F> FpgaFunctionExecutor<F> {
+    pub(crate) fn new(func: F) -> Self {
+        Self { fks: None, func }
+    }
+
+    pub(crate) fn setup(&mut self, server_key: Arc<ServerKey>) {
+        self.fks = Some(BelfortServerKey::from(server_key));
+        let fpga_key = self.fks.as_mut().unwrap();
+        fpga_key.connect(NB_FPGA);
+    }
+}
+
+// Ensures fpga key is disconnected when it goes out of memory
+impl<F> Drop for FpgaFunctionExecutor<F> {
+    fn drop(&mut self) {
+        let fpga_key = self.fks.as_mut().unwrap();
+        fpga_key.disconnect()
+    }
+}
+
+/// For binary operations
+impl<F, I1, I2, O> FunctionExecutor<(I1, I2), O> for FpgaFunctionExecutor<F>
+where
+    F: Fn(&BelfortServerKey, I1, I2) -> O,
+{
+    fn setup(&mut self, _cks: &RadixClientKey, server_key: Arc<ServerKey>) {
+        self.setup(server_key);
+    }
+
+    fn execute(&mut self, input: (I1, I2)) -> O {
+        let fks = self.fks.as_ref().expect("setup was not properly called");
+        (self.func)(fks, input.0, input.1)
+    }
+}
+
+/// For unary assign operations
+impl<'a, F> FunctionExecutor<&'a mut RadixCiphertext, ()> for FpgaFunctionExecutor<F>
+where
+    F: Fn(&BelfortServerKey, &'a mut RadixCiphertext),
+{
+    fn setup(&mut self, _cks: &RadixClientKey, server_key: Arc<ServerKey>) {
+        self.setup(server_key);
+    }
+
+    fn execute(&mut self, input: &'a mut RadixCiphertext) {
+        let fks = self.fks.as_ref().expect("setup was not properly called");
+        (self.func)(fks, input);
+    }
+}
+
+impl<'a, F> FunctionExecutor<&'a RadixCiphertext, RadixCiphertext> for FpgaFunctionExecutor<F>
+where
+    F: Fn(&BelfortServerKey, &'a RadixCiphertext) -> RadixCiphertext,
+{
+    fn setup(&mut self, _cks: &RadixClientKey, server_key: Arc<ServerKey>) {
+        self.setup(server_key);
+    }
+
+    fn execute(&mut self, input: &'a RadixCiphertext) -> RadixCiphertext {
+        let fks = self.fks.as_ref().expect("setup was not properly called");
+        (self.func)(fks, input)
+    }
+}
+
+impl<'a, F> FunctionExecutor<&'a mut RadixCiphertext, RadixCiphertext> for FpgaFunctionExecutor<F>
+where
+    F: Fn(&BelfortServerKey, &'a mut RadixCiphertext) -> RadixCiphertext,
+{
+    fn setup(&mut self, _cks: &RadixClientKey, server_key: Arc<ServerKey>) {
+        self.setup(server_key);
+    }
+
+    fn execute(&mut self, input: &'a mut RadixCiphertext) -> RadixCiphertext {
+        let fks = self.fks.as_ref().expect("setup was not properly called");
+        (self.func)(fks, input)
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_add.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_add.rs
new file mode 100644
index 00000000..b6c67c2b
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_add.rs
@@ -0,0 +1,46 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+
+use crate::integer::fpga::BelfortServerKey;
+use crate::integer::server_key::radix_parallel::tests_unsigned::test_add::*;
+use crate::shortint::parameters::*;
+
+////////////////////////////////////////////////////////////////////////////////
+// The tests
+//
+// We do not inlcude all functions in `add.rs`, but exclude;
+//  - `pub(crate)` funcs, as they are helper functions
+//  - `_assign()` funcs, as normal versions already use them
+//  - `_unchecked()` funcs; they are actually the sw version, so tested there
+
+create_test_default_params!(integer_smart_add);
+create_test_default_params!(integer_default_add);
+// TODO: decide if we need the work efficient version
+// create_test_default_params!(integer_default_add_work_efficient);
+
+fn integer_smart_add<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_add);
+    smart_add_test(param, executor);
+}
+
+fn integer_default_add<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::add);
+    default_add_test(param, executor);
+}
+
+// TODO: Decide if we require work efficient version
+#[allow(dead_code)]
+fn integer_default_add_work_efficient<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::add_work_efficient);
+    default_add_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_bitwise_op.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_bitwise_op.rs
new file mode 100644
index 00000000..a7ea33c3
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_bitwise_op.rs
@@ -0,0 +1,104 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+use crate::integer::server_key::radix_parallel::tests_cases_unsigned::{
+    default_bitand_test, default_bitnot_test, default_bitor_test, default_bitxor_test,
+    smart_bitand_test, smart_bitor_test, smart_bitxor_test, unchecked_bitand_test,
+    unchecked_bitor_test, unchecked_bitxor_test,
+};
+
+use crate::integer::fpga::BelfortServerKey;
+#[cfg(tarpaulin)]
+use crate::shortint::parameters::coverage_parameters::*;
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_smart_bitand);
+create_test_default_params!(integer_smart_bitor);
+create_test_default_params!(integer_smart_bitxor);
+create_test_default_params!(integer_default_bitand);
+create_test_default_params!(integer_default_bitxor);
+create_test_default_params!(integer_default_bitor);
+create_test_default_params!(integer_default_bitnot);
+create_test_default_params!(integer_unchecked_bitand);
+create_test_default_params!(integer_unchecked_bitxor);
+create_test_default_params!(integer_unchecked_bitor);
+
+fn integer_smart_bitand<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_bitand);
+    smart_bitand_test(param, executor);
+}
+
+fn integer_smart_bitor<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_bitor);
+    smart_bitor_test(param, executor);
+}
+
+fn integer_smart_bitxor<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_bitxor);
+    smart_bitxor_test(param, executor);
+}
+
+fn integer_default_bitand<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::bitand);
+    default_bitand_test(param, executor);
+}
+
+fn integer_default_bitor<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::bitor);
+    default_bitor_test(param, executor);
+}
+
+fn integer_default_bitxor<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::bitxor);
+    default_bitxor_test(param, executor);
+}
+
+fn integer_default_bitnot<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::bitnot);
+    default_bitnot_test(param, executor);
+}
+
+fn integer_unchecked_bitand<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_bitand);
+    unchecked_bitand_test(param, executor);
+}
+
+fn integer_unchecked_bitor<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_bitor);
+    unchecked_bitor_test(param, executor);
+}
+
+fn integer_unchecked_bitxor<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_bitxor);
+    unchecked_bitxor_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_comparison.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_comparison.rs
new file mode 100644
index 00000000..87a7e7d3
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_comparison.rs
@@ -0,0 +1,114 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+use crate::integer::server_key::radix_parallel::tests_unsigned::test_comparison::{
+    test_default_function, test_default_minmax, test_smart_function, test_smart_minmax,
+    test_unchecked_function, test_unchecked_minmax,
+};
+use crate::integer::U256;
+
+use crate::integer::fpga::BelfortServerKey;
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_unchecked_min_u256);
+create_test_default_params!(integer_unchecked_max_u256);
+create_test_default_params!(integer_smart_min_u256);
+create_test_default_params!(integer_smart_max_u256);
+create_test_default_params!(integer_min_u256);
+create_test_default_params!(integer_max_u256);
+
+fn integer_unchecked_min_u256(params: impl Into<PBSParameters>) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_min);
+    test_unchecked_minmax(params, 2, executor, std::cmp::min::<U256>);
+}
+
+fn integer_unchecked_max_u256(params: impl Into<PBSParameters>) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_max);
+    test_unchecked_minmax(params, 2, executor, std::cmp::max::<U256>);
+}
+
+fn integer_smart_min_u256(params: impl Into<PBSParameters>) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_min);
+    test_smart_minmax(params, 2, executor, std::cmp::min::<U256>);
+}
+
+fn integer_smart_max_u256(params: impl Into<PBSParameters>) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_max);
+    test_smart_minmax(params, 2, executor, std::cmp::max::<U256>);
+}
+
+fn integer_min_u256(params: impl Into<PBSParameters>) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::min);
+    test_default_minmax(params, 2, executor, std::cmp::min::<U256>);
+}
+
+fn integer_max_u256(params: impl Into<PBSParameters>) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::max);
+    test_default_minmax(params, 2, executor, std::cmp::max::<U256>);
+}
+
+/// This macro generates the tests for a given comparison fn
+///
+/// All our comparison function have 3 variants:
+/// - unchecked_$comparison_name
+/// - smart_$comparison_name
+/// - default $comparison_name
+///
+/// So, for example, for the `gt` comparison fn, this macro will generate the tests for
+/// the 3 variants described above
+macro_rules! define_comparison_test_functions {
+    ($comparison_name:ident, $clear_type:ty) => {
+        ::paste::paste!{
+            fn [<integer_unchecked_ $comparison_name _ $clear_type:lower>]<P>(param: P) where P: Into<PBSParameters>{
+                let num_tests = 1;
+                let executor = FpgaFunctionExecutor::new(&BelfortServerKey::[<unchecked_ $comparison_name>]);
+                test_unchecked_function(
+                    param,
+                    num_tests,
+                    executor,
+                    |lhs, rhs| $clear_type::from(<$clear_type>::$comparison_name(&lhs, &rhs)),
+                )
+            }
+
+            fn [<integer_smart_ $comparison_name _ $clear_type:lower>]<P>(param: P) where P: Into<PBSParameters> {
+                let num_tests = 1;
+                let executor = FpgaFunctionExecutor::new(&BelfortServerKey::[<smart_ $comparison_name>]);
+                test_smart_function(
+                    param,
+                    num_tests,
+                    executor,
+                    |lhs, rhs| $clear_type::from(<$clear_type>::$comparison_name(&lhs, &rhs)),
+                )
+            }
+
+            fn [<integer_default_ $comparison_name _ $clear_type:lower>]<P>(param: P) where P: Into<PBSParameters> {
+                let num_tests = 1;
+                let executor = FpgaFunctionExecutor::new(&BelfortServerKey::[<$comparison_name>]);
+                test_default_function(
+                    param,
+                    num_tests,
+                    executor,
+                    |lhs, rhs| $clear_type::from(<$clear_type>::$comparison_name(&lhs, &rhs)),
+                )
+            }
+
+            create_test_default_params!([<integer_unchecked_ $comparison_name _ $clear_type:lower>]);
+            create_test_default_params!([<integer_smart_ $comparison_name _ $clear_type:lower>]);
+            create_test_default_params!([<integer_default_ $comparison_name _ $clear_type:lower>]);
+        }
+    };
+}
+
+define_comparison_test_functions!(eq, U256);
+define_comparison_test_functions!(ne, U256);
+define_comparison_test_functions!(lt, U256);
+define_comparison_test_functions!(le, U256);
+define_comparison_test_functions!(gt, U256);
+define_comparison_test_functions!(ge, U256);
+
+define_comparison_test_functions!(eq, u8);
+define_comparison_test_functions!(ne, u8);
+define_comparison_test_functions!(lt, u8);
+define_comparison_test_functions!(le, u8);
+define_comparison_test_functions!(gt, u8);
+define_comparison_test_functions!(ge, u8);
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_div_mod.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_div_mod.rs
new file mode 100644
index 00000000..628ae53b
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_div_mod.rs
@@ -0,0 +1,62 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+
+use crate::integer::fpga::BelfortServerKey;
+use crate::integer::server_key::radix_parallel::tests_unsigned::test_div_mod::*;
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_smart_div_rem);
+create_test_default_params!(integer_smart_div);
+create_test_default_params!(integer_smart_rem);
+create_test_default_params!(integer_default_div_rem);
+create_test_default_params!(integer_default_div);
+create_test_default_params!(integer_default_rem);
+
+fn integer_smart_div_rem<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_div_rem);
+    smart_div_rem_test(param, executor);
+}
+
+fn integer_smart_div<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_div);
+    smart_div_test(param, executor);
+}
+
+fn integer_smart_rem<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_rem);
+    smart_rem_test(param, executor);
+}
+
+fn integer_default_div_rem<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::div_rem);
+    default_div_rem_test(param, executor);
+}
+
+fn integer_default_div<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::div);
+    default_div_test(param, executor);
+}
+
+fn integer_default_rem<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::rem);
+    default_rem_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_ilog2.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_ilog2.rs
new file mode 100644
index 00000000..fe66f05a
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_ilog2.rs
@@ -0,0 +1,56 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+use crate::integer::server_key::radix_parallel::tests_unsigned::test_ilog2::{
+    default_ilog2_test, default_leading_ones_test, default_leading_zeros_test,
+    default_trailing_ones_test, default_trailing_zeros_test,
+};
+
+use crate::integer::fpga::BelfortServerKey;
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_default_trailing_zeros);
+create_test_default_params!(integer_default_trailing_ones);
+create_test_default_params!(integer_default_leading_zeros);
+create_test_default_params!(integer_default_leading_ones);
+create_test_default_params!(integer_default_ilog2);
+
+fn integer_default_trailing_zeros<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::trailing_zeros);
+    default_trailing_zeros_test(param, executor);
+}
+
+fn integer_default_trailing_ones<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::trailing_ones);
+    default_trailing_ones_test(param, executor);
+}
+
+fn integer_default_leading_zeros<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::leading_zeros);
+    default_leading_zeros_test(param, executor);
+}
+
+fn integer_default_leading_ones<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::leading_ones);
+    default_leading_ones_test(param, executor);
+}
+
+fn integer_default_ilog2<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::ilog2);
+    default_ilog2_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_mul.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_mul.rs
new file mode 100644
index 00000000..05836718
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_mul.rs
@@ -0,0 +1,45 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+use crate::integer::fpga::BelfortServerKey;
+use crate::integer::server_key::radix_parallel::tests_cases_unsigned::{
+    default_mul_test, smart_mul_test, unchecked_mul_corner_cases_test, unchecked_mul_test,
+};
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_default_mul);
+create_test_default_params!(integer_unchecked_mul);
+create_test_default_params!(integer_unchecked_mul_corner_cases);
+create_test_default_params!(integer_smart_mul);
+
+fn integer_default_mul<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::mul);
+    default_mul_test(param, executor);
+}
+
+fn integer_unchecked_mul<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_mul);
+    unchecked_mul_test(param, executor);
+}
+
+fn integer_unchecked_mul_corner_cases<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_mul);
+    unchecked_mul_corner_cases_test(param, executor);
+}
+
+fn integer_smart_mul<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_mul);
+    smart_mul_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_neg.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_neg.rs
new file mode 100644
index 00000000..8025aedc
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_neg.rs
@@ -0,0 +1,37 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+use crate::integer::fpga::BelfortServerKey;
+use crate::integer::server_key::radix_parallel::tests_unsigned::test_neg::*;
+
+#[cfg(tarpaulin)]
+use crate::shortint::parameters::coverage_parameters::*;
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_smart_neg);
+create_test_default_params!(integer_default_neg);
+create_test_default_params!(integer_neg_work_efficient);
+
+fn integer_smart_neg<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_neg);
+    smart_neg_test(param, executor);
+}
+
+fn integer_default_neg<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::neg);
+    default_neg_test(param, executor);
+}
+
+fn integer_neg_work_efficient<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::neg_work_efficient);
+    default_neg_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_propagate.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_propagate.rs
new file mode 100644
index 00000000..3f6a7ce4
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_propagate.rs
@@ -0,0 +1,17 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+use crate::integer::fpga::BelfortServerKey;
+
+use crate::integer::server_key::radix_parallel::tests_cases_unsigned::full_propagate_test;
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_full_propagate);
+
+fn integer_full_propagate<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::full_propagate);
+    full_propagate_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_comparison.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_comparison.rs
new file mode 100644
index 00000000..3ea2af35
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_comparison.rs
@@ -0,0 +1,107 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+use crate::integer::server_key::radix_parallel::tests_unsigned::test_scalar_comparison::{
+    test_default_scalar_function, test_default_scalar_minmax, test_smart_scalar_function,
+    test_smart_scalar_minmax, test_unchecked_scalar_function, test_unchecked_scalar_minmax,
+};
+use crate::integer::U256;
+
+use crate::integer::fpga::BelfortServerKey;
+use crate::shortint::{parameters::*, ClassicPBSParameters};
+
+create_test_default_params!(integer_unchecked_scalar_min_u256);
+create_test_default_params!(integer_unchecked_scalar_max_u256);
+create_test_default_params!(integer_smart_scalar_min_u256);
+create_test_default_params!(integer_smart_scalar_max_u256);
+create_test_default_params!(integer_scalar_min_u256);
+create_test_default_params!(integer_scalar_max_u256);
+
+fn integer_unchecked_scalar_min_u256(params: ClassicPBSParameters) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_scalar_min);
+    test_unchecked_scalar_minmax(params, 2, executor, std::cmp::min::<U256>);
+}
+
+fn integer_unchecked_scalar_max_u256(params: ClassicPBSParameters) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_scalar_max);
+    test_unchecked_scalar_minmax(params, 2, executor, std::cmp::max::<U256>);
+}
+
+fn integer_smart_scalar_min_u256(params: ClassicPBSParameters) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_scalar_min);
+    test_smart_scalar_minmax(params, 2, executor, std::cmp::min::<U256>);
+}
+
+fn integer_smart_scalar_max_u256(params: ClassicPBSParameters) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_scalar_max);
+    test_smart_scalar_minmax(params, 2, executor, std::cmp::max::<U256>);
+}
+
+fn integer_scalar_min_u256(params: ClassicPBSParameters) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::scalar_min);
+    test_default_scalar_minmax(params, 2, executor, std::cmp::min::<U256>);
+}
+
+fn integer_scalar_max_u256(params: ClassicPBSParameters) {
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::scalar_max);
+    test_default_scalar_minmax(params, 2, executor, std::cmp::max::<U256>);
+}
+
+/// This macro generates the tests for a given scalar comparison fn
+///
+/// All our scalar comparison function have 3 variants:
+/// - unchecked_scalar_$comparison_name
+/// - smart_scalar_$comparison_name
+/// - scalar_$comparison_name
+///
+/// So, for example, for the `gt` comparison fn,
+/// this macro will generate the tests for the 3 variants described above
+macro_rules! define_scalar_comparison_test_functions {
+    ($comparison_name:ident, $clear_type:ty) => {
+        ::paste::paste!{
+            fn [<integer_unchecked_scalar_ $comparison_name _ $clear_type:lower>]<P>(param: P) where P: Into<PBSParameters>{
+                let num_tests = 1;
+                let executor = FpgaFunctionExecutor::new(&BelfortServerKey::[<unchecked_scalar_ $comparison_name>]);
+                test_unchecked_scalar_function(
+                    param,
+                    num_tests,
+                    executor,
+                    |lhs, rhs| $clear_type::from(<$clear_type>::$comparison_name(&lhs, &rhs)),
+                )
+            }
+
+            fn [<integer_smart_scalar_ $comparison_name _ $clear_type:lower>]<P>(param: P) where P: Into<PBSParameters>{
+                let num_tests = 1;
+                let executor = FpgaFunctionExecutor::new(&BelfortServerKey::[<smart_scalar_ $comparison_name>]);
+                test_smart_scalar_function(
+                    param,
+                    num_tests,
+                    executor,
+                    |lhs, rhs| $clear_type::from(<$clear_type>::$comparison_name(&lhs, &rhs)),
+                )
+            }
+
+            fn [<integer_default_scalar_ $comparison_name _ $clear_type:lower>]<P>(param: P) where P: Into<PBSParameters>{
+                let num_tests = 1;
+                let executor = FpgaFunctionExecutor::new(&BelfortServerKey::[<scalar_ $comparison_name>]);
+                test_default_scalar_function(
+                    param,
+                    num_tests,
+                    executor,
+                    |lhs, rhs| $clear_type::from(<$clear_type>::$comparison_name(&lhs, &rhs)),
+                )
+            }
+
+            create_test_default_params!([<integer_unchecked_scalar_ $comparison_name _ $clear_type:lower>]);
+            create_test_default_params!([<integer_smart_scalar_ $comparison_name _ $clear_type:lower>]);
+            create_test_default_params!([<integer_default_scalar_ $comparison_name _ $clear_type:lower>]);
+        }
+    };
+}
+
+define_scalar_comparison_test_functions!(eq, U256);
+define_scalar_comparison_test_functions!(ne, U256);
+define_scalar_comparison_test_functions!(lt, U256);
+define_scalar_comparison_test_functions!(le, U256);
+define_scalar_comparison_test_functions!(gt, U256);
+define_scalar_comparison_test_functions!(ge, U256);
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_rotate.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_rotate.rs
new file mode 100644
index 00000000..1536911a
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_rotate.rs
@@ -0,0 +1,47 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+use crate::integer::server_key::radix_parallel::tests_unsigned::test_scalar_rotate::{
+    default_scalar_rotate_left_test, default_scalar_rotate_right_test,
+    unchecked_scalar_rotate_left_test, unchecked_scalar_rotate_right_test,
+};
+
+use crate::integer::fpga::BelfortServerKey;
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_unchecked_scalar_rotate_left);
+create_test_default_params!(integer_default_scalar_rotate_left);
+create_test_default_params!(integer_unchecked_scalar_rotate_right);
+create_test_default_params!(integer_default_scalar_rotate_right);
+
+fn integer_default_scalar_rotate_left<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::scalar_rotate_left);
+    default_scalar_rotate_left_test(param, executor);
+}
+
+fn integer_unchecked_scalar_rotate_left<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_scalar_rotate_left);
+    unchecked_scalar_rotate_left_test(param, executor);
+}
+
+fn integer_default_scalar_rotate_right<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::scalar_rotate_right);
+    default_scalar_rotate_right_test(param, executor);
+}
+
+fn integer_unchecked_scalar_rotate_right<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_scalar_rotate_right);
+    unchecked_scalar_rotate_right_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_shift.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_shift.rs
new file mode 100644
index 00000000..c6bb7dac
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_scalar_shift.rs
@@ -0,0 +1,47 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+
+use crate::integer::fpga::BelfortServerKey;
+use crate::integer::server_key::radix_parallel::tests_cases_unsigned::{
+    default_scalar_left_shift_test, default_scalar_right_shift_test,
+    unchecked_scalar_left_shift_test, unchecked_scalar_right_shift_test,
+};
+use crate::shortint::parameters::*;
+
+create_test_default_params!(integer_unchecked_scalar_right_shift);
+create_test_default_params!(integer_unchecked_scalar_left_shift);
+create_test_default_params!(integer_scalar_right_shift);
+create_test_default_params!(integer_scalar_left_shift);
+
+fn integer_unchecked_scalar_right_shift<P>(param: P)
+where
+    P: Into<PBSParameters> + Copy,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_scalar_right_shift);
+    unchecked_scalar_right_shift_test(param, executor);
+}
+
+fn integer_scalar_right_shift<P>(param: P)
+where
+    P: Into<PBSParameters> + Copy,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::scalar_right_shift);
+    default_scalar_right_shift_test(param, executor);
+}
+
+fn integer_unchecked_scalar_left_shift<P>(param: P)
+where
+    P: Into<PBSParameters> + Copy,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unchecked_scalar_left_shift);
+    unchecked_scalar_left_shift_test(param, executor);
+}
+
+fn integer_scalar_left_shift<P>(param: P)
+where
+    P: Into<PBSParameters> + Copy,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::scalar_left_shift);
+    default_scalar_left_shift_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/tests/test_sub.rs b/tfhe/src/integer/fpga/server_key/radix/tests/test_sub.rs
new file mode 100644
index 00000000..7a7d091b
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/tests/test_sub.rs
@@ -0,0 +1,55 @@
+use crate::integer::fpga::server_key::radix::tests::{
+    create_test_default_params, FpgaFunctionExecutor,
+};
+
+use crate::integer::fpga::BelfortServerKey;
+use crate::integer::server_key::radix_parallel::tests_unsigned::test_sub::*;
+use crate::shortint::parameters::*;
+
+////////////////////////////////////////////////////////////////////////////////
+// The tests
+//
+// We do not inlcude all functions in `sub.rs`, but exclude;
+//  - `pub(crate)` funcs, as they are helper functions
+//  - `_assign()` funcs, as normal versions already use them
+//  - `_unchecked()` funcs; they are actually the sw version, so tested there
+
+create_test_default_params!(integer_smart_sub);
+create_test_default_params!(integer_default_sub);
+create_test_default_params!(integer_default_sub_work_efficient);
+create_test_default_params!(integer_default_overflowing_sub);
+
+////////////////////////////////////////////////////////////////////////////////
+// Helper functions associating tests with executors
+
+fn integer_smart_sub<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::smart_sub);
+    smart_sub_test(param, executor);
+}
+
+fn integer_default_sub<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::sub);
+    default_sub_test(param, executor);
+}
+
+fn integer_default_sub_work_efficient<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::sub_work_efficient);
+    default_sub_test(param, executor);
+}
+
+fn integer_default_overflowing_sub<P>(param: P)
+where
+    P: Into<PBSParameters>,
+{
+    let executor = FpgaFunctionExecutor::new(&BelfortServerKey::unsigned_overflowing_sub);
+    default_overflowing_sub_test(param, executor);
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/vector_comparisons.rs b/tfhe/src/integer/fpga/server_key/radix/vector_comparisons.rs
new file mode 100644
index 00000000..081a1af4
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/vector_comparisons.rs
@@ -0,0 +1,103 @@
+use crate::integer::fpga::server_key::BelfortServerKey;
+use crate::integer::{BooleanBlock, IntegerRadixCiphertext};
+use log::warn;
+impl BelfortServerKey {
+    /// Compares two slices containing ciphertexts and returns an encryption of `true` if all
+    /// pairs are equal, otherwise, returns an encryption of `false`.
+    ///
+    /// - If slices do not have the same length, false is returned
+    /// - If at least one  pair (`lhs[i]`, `rhs[i]`) do not have the same number of blocks, false is
+    ///   returned
+    pub fn unchecked_all_eq_slices<T>(&self, lhs: &[T], rhs: &[T]) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key.key.unchecked_all_eq_slices_parallelized(lhs, rhs)
+    }
+
+    /// Compares two slices containing ciphertexts and returns an encryption of `true` if all
+    /// pairs are equal, otherwise, returns an encryption of `false`.
+    ///
+    /// - If slices do not have the same length, false is returned
+    /// - If at least one  pair (`lhs[i]`, `rhs[i]`) do not have the same number of blocks, false is
+    ///   returned
+    pub fn smart_all_eq_slices<T>(&self, lhs: &mut [T], rhs: &mut [T]) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        lhs.iter_mut()
+            .chain(rhs.iter_mut())
+            .for_each(|ct| self.conditional_full_propagate(ct));
+        self.unchecked_all_eq_slices(lhs, rhs)
+    }
+
+    /// Compares two slices containing ciphertexts and returns an encryption of `true` if all
+    /// pairs are equal, otherwise, returns an encryption of `false`.
+    ///
+    /// - If slices do not have the same length, false is returned
+    /// - If at least one  pair (`lhs[i]`, `rhs[i]`) do not have the same number of blocks, false is
+    ///   returned
+    pub fn all_eq_slices<T>(&self, lhs: &[T], rhs: &[T]) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut lhs_clone;
+        let mut rhs_clone;
+        let lhs = if lhs.iter().any(|ct| !ct.block_carries_are_empty()) {
+            lhs_clone = lhs.to_vec();
+            lhs_clone
+                .iter_mut()
+                .for_each(|ct| self.conditional_full_propagate(ct));
+            &lhs_clone
+        } else {
+            lhs
+        };
+
+        let rhs = if rhs.iter().any(|ct| !ct.block_carries_are_empty()) {
+            rhs_clone = rhs.to_vec();
+            rhs_clone
+                .iter_mut()
+                .for_each(|ct| self.conditional_full_propagate(ct));
+            &rhs_clone
+        } else {
+            rhs
+        };
+
+        self.unchecked_all_eq_slices(lhs, rhs)
+    }
+
+    /// Returns a boolean ciphertext encrypting `true` if `lhs` contains `rhs`, `false` otherwise
+    pub fn unchecked_contains_sub_slice<T>(&self, lhs: &[T], rhs: &[T]) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .unchecked_contains_sub_slice_parallelized(lhs, rhs)
+    }
+
+    /// Returns a boolean ciphertext encrypting `true` if `lhs` contains `rhs`, `false` otherwise
+    pub fn smart_contains_sub_slice<T>(&self, lhs: &mut [T], rhs: &mut [T]) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        lhs.iter_mut().chain(rhs.iter_mut()).for_each(|radix| {
+            self.conditional_full_propagate(radix);
+        });
+
+        self.unchecked_contains_sub_slice(lhs, rhs)
+    }
+
+    /// Returns a boolean ciphertext encrypting `true` if `lhs` contains `rhs`, `false` otherwise
+    pub fn contains_sub_slice<T>(&self, lhs: &[T], rhs: &[T]) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key
+            .key
+            .unchecked_contains_sub_slice_parallelized(lhs, rhs)
+    }
+}
diff --git a/tfhe/src/integer/fpga/server_key/radix/vector_find.rs b/tfhe/src/integer/fpga/server_key/radix/vector_find.rs
new file mode 100644
index 00000000..e822b6cd
--- /dev/null
+++ b/tfhe/src/integer/fpga/server_key/radix/vector_find.rs
@@ -0,0 +1,724 @@
+use crate::core_crypto::prelude::UnsignedInteger;
+use crate::integer::fpga::server_key::BelfortServerKey;
+
+use crate::integer::block_decomposition::DecomposableInto;
+use crate::integer::server_key::radix_parallel::MatchValues;
+use crate::integer::{BooleanBlock, IntegerRadixCiphertext, RadixCiphertext};
+use crate::prelude::CastInto;
+use log::warn;
+use std::hash::Hash;
+
+impl BelfortServerKey {
+    /// `match` an input value to an output value
+    ///
+    /// - Input values are not required to span all possible values that `ct` could hold.
+    ///
+    /// - The output radix has a number of blocks that depends on the maximum possible output value
+    ///   from the `MatchValues`
+    ///
+    /// Returns a boolean block that encrypts `true` if the input `ct`
+    /// matched one of the possible inputs
+    pub fn unchecked_match_value<Clear>(
+        &self,
+        ct: &RadixCiphertext,
+        matches: &MatchValues<Clear>,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        Clear: UnsignedInteger + DecomposableInto<u64> + CastInto<usize>,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key.key.unchecked_match_value_parallelized(ct, matches)
+    }
+
+    /// `match` an input value to an output value
+    ///
+    /// - Input values are not required to span all possible values that `ct` could hold.
+    ///
+    /// - The output radix has a number of blocks that depends on the maximum possible output value
+    ///   from the `MatchValues`
+    ///
+    /// Returns a boolean block that encrypts `true` if the input `ct`
+    /// matched one of the possible inputs
+    pub fn smart_match_value<Clear>(
+        &self,
+        ct: &mut RadixCiphertext,
+        matches: &MatchValues<Clear>,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        Clear: UnsignedInteger + DecomposableInto<u64> + CastInto<usize>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_match_value(ct, matches)
+    }
+
+    /// `match` an input value to an output value
+    ///
+    /// - Input values are not required to span all possible values that `ct` could hold.
+    ///
+    /// - The output radix has a number of blocks that depends on the maximum possible output value
+    ///   from the `MatchValues`
+    ///
+    /// Returns a boolean block that encrypts `true` if the input `ct`
+    /// matched one of the possible inputs
+    pub fn match_value<Clear>(
+        &self,
+        ct: &RadixCiphertext,
+        matches: &MatchValues<Clear>,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        Clear: UnsignedInteger + DecomposableInto<u64> + CastInto<usize>,
+    {
+        if ct.block_carries_are_empty() {
+            self.unchecked_match_value(ct, matches)
+        } else {
+            let mut clone = ct.clone();
+            self.full_propagate(&mut clone);
+            self.unchecked_match_value(&clone, matches)
+        }
+    }
+
+    /// `match` an input value to an output value
+    ///
+    /// - Input values are not required to span all possible values that `ct` could hold.
+    ///
+    /// - The output radix has a number of blocks that depends on the maximum possible output value
+    ///   from the `MatchValues`
+    ///
+    ///
+    /// If none of the input matched the `ct` then, `ct` will encrypt the
+    /// value given to `or_value`
+    pub fn unchecked_match_value_or<Clear>(
+        &self,
+        ct: &RadixCiphertext,
+        matches: &MatchValues<Clear>,
+        or_value: Clear,
+    ) -> RadixCiphertext
+    where
+        Clear: UnsignedInteger + DecomposableInto<u64> + CastInto<usize>,
+    {
+        self.key
+            .key
+            .unchecked_match_value_or_parallelized(ct, matches, or_value)
+    }
+
+    /// `map` an input value to an output value
+    ///
+    /// - Input values are not required to span all possible values that `ct` could hold.
+    ///
+    /// - The output radix has a number of blocks that depends on the maximum possible output value
+    ///   from the `MatchValues`
+    ///
+    /// If none of the input matched the `ct` then, `ct` will encrypt the
+    /// value given to `or_value`
+    pub fn smart_match_value_or<Clear>(
+        &self,
+        ct: &mut RadixCiphertext,
+        matches: &MatchValues<Clear>,
+        or_value: Clear,
+    ) -> RadixCiphertext
+    where
+        Clear: UnsignedInteger + DecomposableInto<u64> + CastInto<usize>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_match_value_or(ct, matches, or_value)
+    }
+
+    /// `match` an input value to an output value
+    ///
+    /// - Input values are not required to span all possible values that `ct` could hold.
+    ///
+    /// - The output radix has a number of blocks that depends on the maximum possible output value
+    ///   from the `MatchValues`
+    ///
+    /// If none of the input matched the `ct` then, `ct` will encrypt the
+    /// value given to `or_value`
+    pub fn match_value_or<Clear>(
+        &self,
+        ct: &RadixCiphertext,
+        matches: &MatchValues<Clear>,
+        or_value: Clear,
+    ) -> RadixCiphertext
+    where
+        Clear: UnsignedInteger + DecomposableInto<u64> + CastInto<usize>,
+    {
+        if ct.block_carries_are_empty() {
+            self.unchecked_match_value_or(ct, matches, or_value)
+        } else {
+            let mut clone = ct.clone();
+            self.full_propagate(&mut clone);
+            self.unchecked_match_value_or(&clone, matches, or_value)
+        }
+    }
+
+    /// Returns an encrypted `true` if the encrypted `value` is found in the encrypted slice
+    pub fn unchecked_contains<T>(&self, cts: &[T], value: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key.key.unchecked_contains_parallelized(cts, value)
+    }
+
+    /// Returns an encrypted `true` if the encrypted `value` is found in the encrypted slice
+    pub fn smart_contains<T>(&self, cts: &mut [T], value: &mut T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key.key.smart_contains_parallelized(cts, value)
+    }
+
+    /// Returns an encrypted `true` if the encrypted `value` is found in the encrypted slice
+    pub fn contains<T>(&self, cts: &[T], value: &T) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_cts;
+        let mut tmp_value;
+
+        let cts = if cts.iter().any(|ct| !ct.block_carries_are_empty()) {
+            tmp_cts = cts.to_vec();
+            tmp_cts
+                .iter_mut()
+                .for_each(|ct| self.conditional_full_propagate(ct));
+            &tmp_cts
+        } else {
+            cts
+        };
+
+        let value = if value.block_carries_are_empty() {
+            value
+        } else {
+            tmp_value = value.clone();
+            self.full_propagate(&mut tmp_value);
+            &tmp_value
+        };
+
+        self.unchecked_contains(cts, value)
+    }
+
+    /// Returns an encrypted `true` if the clear `value` is found in the encrypted slice
+    pub fn unchecked_contains_clear<T, Clear>(&self, cts: &[T], clear: Clear) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64>,
+    {
+        self.key
+            .key
+            .unchecked_contains_clear_parallelized(cts, clear)
+    }
+
+    /// Returns an encrypted `true` if the clear `value` is found in the encrypted slice
+    pub fn smart_contains_clear<T, Clear>(&self, cts: &mut [T], clear: Clear) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64>,
+    {
+        let mut tmp_cts;
+
+        let cts = if cts.iter().any(|ct| !ct.block_carries_are_empty()) {
+            tmp_cts = cts.to_vec();
+            tmp_cts
+                .iter_mut()
+                .filter(|ct| !ct.block_carries_are_empty())
+                .for_each(|ct| self.full_propagate(ct));
+            tmp_cts.as_slice()
+        } else {
+            cts
+        };
+
+        self.unchecked_contains_clear(cts, clear)
+    }
+
+    /// Returns an encrypted `true` if the clear `value` is found in the encrypted slice
+    pub fn contains_clear<T, Clear>(&self, cts: &[T], clear: Clear) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64>,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key.key.contains_clear_parallelized(cts, clear)
+    }
+
+    /// Returns an encrypted `true` if the encrypted `value` is found in the clear slice
+    pub fn unchecked_is_in_clears<T, Clear>(&self, ct: &T, clears: &[Clear]) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key.key.unchecked_is_in_clears_parallelized(ct, clears)
+    }
+
+    /// Returns an encrypted `true` if the encrypted `value` is found in the clear slice
+    pub fn smart_is_in_clears<T, Clear>(&self, ct: &mut T, clears: &[Clear]) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_is_in_clears(ct, clears)
+    }
+
+    /// Returns an encrypted `true` if the encrypted `value` is found in the clear slice
+    pub fn is_in_clears<T, Clear>(&self, ct: &T, clears: &[Clear]) -> BooleanBlock
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        let mut tmp_ct;
+        let ct = if ct.block_carries_are_empty() {
+            ct
+        } else {
+            tmp_ct = ct.clone();
+            self.full_propagate(&mut tmp_ct);
+            &tmp_ct
+        };
+        self.unchecked_is_in_clears(ct, clears)
+    }
+
+    /// Returns the encrypted index of the encrypted `value` in the clear slice
+    /// also returns an encrypted boolean that is `true` if the encrypted value was found.
+    ///
+    /// # Notes
+    ///
+    /// - clear values in the slice must be unique (otherwise use
+    ///   [Self::unchecked_first_index_in_clears])
+    /// - If the encrypted value is not in the clear slice, the returned index is 0
+    pub fn unchecked_index_in_clears<T, Clear>(
+        &self,
+        ct: &T,
+        clears: &[Clear],
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        self.key
+            .key
+            .unchecked_index_in_clears_parallelized(ct, clears)
+    }
+
+    /// Returns the encrypted index of the encrypted `value` in the clear slice
+    /// also returns an encrypted boolean that is `true` if the encrypted value was found.
+    ///
+    /// # Notes
+    ///
+    /// - clear values in the slice must be unique (otherwise use
+    ///   [Self::smart_first_index_in_clears])
+    /// - If the encrypted value is not in the clear slice, the returned index is 0
+    pub fn smart_index_in_clears<T, Clear>(
+        &self,
+        ct: &mut T,
+        clears: &[Clear],
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        self.conditional_full_propagate(ct);
+        self.unchecked_index_in_clears(ct, clears)
+    }
+
+    /// Returns the encrypted index of the encrypted `value` in the clear slice
+    /// also returns an encrypted boolean that is `true` if the encrypted value was found.
+    ///
+    /// # Notes
+    ///
+    /// - clear values in the slice must be unique (otherwise use
+    ///   [Self::index_in_clears])
+    /// - If the encrypted value is not in the clear slice, the returned index is 0
+    pub fn index_in_clears<T, Clear>(
+        &self,
+        ct: &T,
+        clears: &[Clear],
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        let mut tmp_ct;
+        let ct = if ct.block_carries_are_empty() {
+            ct
+        } else {
+            tmp_ct = ct.clone();
+            self.full_propagate(&mut tmp_ct);
+            &tmp_ct
+        };
+
+        self.unchecked_index_in_clears(ct, clears)
+    }
+
+    /// Returns the encrypted index of the _first_ occurrence of encrypted `value` in the clear
+    /// slice also, it returns an encrypted boolean that is `true` if the encrypted value was
+    /// found.
+    ///
+    /// # Notes
+    ///
+    /// - If the encrypted value is not in the clear slice, the returned index is 0
+    pub fn unchecked_first_index_in_clears<T, Clear>(
+        &self,
+        ct: &T,
+        clears: &[Clear],
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize> + Hash,
+    {
+        self.key
+            .key
+            .unchecked_first_index_in_clears_parallelized(ct, clears)
+    }
+
+    /// Returns the encrypted index of the _first_ occurrence of encrypted `value` in the clear
+    /// slice also, it returns an encrypted boolean that is `true` if the encrypted value was
+    /// found.
+    ///
+    /// # Notes
+    ///
+    /// - If the encrypted value is not in the clear slice, the returned index is 0
+    pub fn smart_first_index_in_clears_parallelized<T, Clear>(
+        &self,
+        ct: &mut T,
+        clears: &[Clear],
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize> + Hash,
+    {
+        self.conditional_full_propagate(ct);
+
+        self.unchecked_first_index_in_clears(ct, clears)
+    }
+
+    /// Returns the encrypted index of the _first_ occurrence of encrypted `value` in the clear
+    /// slice also, it returns an encrypted boolean that is `true` if the encrypted value was
+    /// found.
+    ///
+    /// # Notes
+    ///
+    /// - If the encrypted value is not in the clear slice, the returned index is 0
+    pub fn first_index_in_clears<T, Clear>(
+        &self,
+        ct: &T,
+        clears: &[Clear],
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize> + Hash,
+    {
+        let mut tmp_ct;
+        let ct = if ct.block_carries_are_empty() {
+            ct
+        } else {
+            tmp_ct = ct.clone();
+            self.full_propagate(&mut tmp_ct);
+            &tmp_ct
+        };
+
+        self.unchecked_first_index_in_clears(ct, clears)
+    }
+
+    /// Returns the encrypted index of the of encrypted `value` in the ciphertext slice
+    /// also, it returns an encrypted boolean that is `true` if the encrypted value was found.
+    ///
+    /// # Notes
+    ///
+    /// - clear values in the slice must be unique (otherwise use
+    ///   [Self::unchecked_first_index_of])
+    /// - If the encrypted value is not in the encrypted slice, the returned index is 0
+    pub fn unchecked_index_of<T>(&self, cts: &[T], value: &T) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        warn!("Non-optimized function call. Contact Belfort if you experience a slow run.");
+        self.key.key.unchecked_index_of_parallelized(cts, value)
+    }
+
+    /// Returns the encrypted index of the of encrypted `value` in the ciphertext slice
+    /// also, it returns an encrypted boolean that is `true` if the encrypted value was found.
+    ///
+    /// # Notes
+    ///
+    /// - clear values in the slice must be unique (otherwise use
+    ///   [Self::smart_first_index_of])
+    /// - If the encrypted value is not in the encrypted slice, the returned index is 0
+    pub fn smart_index_of<T>(&self, cts: &mut [T], value: &mut T) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(value);
+
+        cts.iter_mut()
+            .for_each(|ct| self.conditional_full_propagate(ct));
+
+        self.unchecked_index_of(cts, value)
+    }
+
+    /// Returns the encrypted index of the of encrypted `value` in the ciphertext slice
+    /// also, it returns an encrypted boolean that is `true` if the encrypted value was found.
+    ///
+    /// # Notes
+    ///
+    /// - clear values in the slice must be unique (otherwise use
+    ///   [Self::first_index_of])
+    /// - If the encrypted value is not in the encrypted slice, the returned index is 0
+    pub fn index_of<T>(&self, cts: &[T], value: &T) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_cts;
+        let mut tmp_value;
+
+        let cts = if cts.iter().any(|ct| !ct.block_carries_are_empty()) {
+            tmp_cts = cts.to_vec();
+            tmp_cts
+                .iter_mut()
+                .filter(|ct| !ct.block_carries_are_empty())
+                .for_each(|ct| self.full_propagate(ct));
+            &tmp_cts
+        } else {
+            cts
+        };
+
+        let value = if value.block_carries_are_empty() {
+            value
+        } else {
+            tmp_value = value.clone();
+            self.full_propagate(&mut tmp_value);
+            &tmp_value
+        };
+
+        self.unchecked_index_of(cts, value)
+    }
+
+    /// Returns the encrypted index of the of clear `value` in the ciphertext slice
+    /// also, it returns an encrypted boolean that is `true` if the encrypted value was found.
+    ///
+    /// # Notes
+    ///
+    /// - clear values in the slice must be unique (otherwise use
+    ///   [Self::unchecked_first_index_of_clear])
+    /// - If the clear value is not in the encrypted slice, the returned index is 0
+    pub fn unchecked_index_of_clear<T, Clear>(
+        &self,
+        cts: &[T],
+        clear: Clear,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        self.key
+            .key
+            .unchecked_index_of_clear_parallelized(cts, clear)
+    }
+
+    /// Returns the encrypted index of the of clear `value` in the ciphertext slice
+    /// also, it returns an encrypted boolean that is `true` if the encrypted value was found.
+    ///
+    /// # Notes
+    ///
+    /// - clear values in the slice must be unique (otherwise use
+    ///   [Self::smart_first_index_of_clear_parallelized])
+    /// - If the clear value is not in the encrypted slice, the returned index is 0
+    pub fn smart_index_of_clear<T, Clear>(
+        &self,
+        cts: &mut [T],
+        clear: Clear,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        cts.iter_mut()
+            .for_each(|ct| self.conditional_full_propagate(ct));
+
+        self.unchecked_index_of_clear(cts, clear)
+    }
+
+    /// Returns the encrypted index of the of clear `value` in the ciphertext slice
+    /// also, it returns an encrypted boolean that is `true` if the encrypted value was found.
+    ///
+    /// # Notes
+    ///
+    /// - clear values in the slice must be unique (otherwise use
+    ///   [Self::first_index_of_clear_parallelized])
+    /// - If the clear value is not in the encrypted slice, the returned index is 0
+    pub fn index_of_clear_parallelized<T, Clear>(
+        &self,
+        cts: &[T],
+        clear: Clear,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        let mut tmp_cts;
+
+        let cts = if cts.iter().any(|ct| !ct.block_carries_are_empty()) {
+            tmp_cts = cts.to_vec();
+            tmp_cts
+                .iter_mut()
+                .for_each(|ct| self.conditional_full_propagate(ct));
+            tmp_cts.as_slice()
+        } else {
+            cts
+        };
+
+        self.unchecked_index_of_clear(cts, clear)
+    }
+
+    /// Returns the encrypted index of the _first_ occurrence of clear `value` in the ciphertext
+    /// slice also, it returns an encrypted boolean that is `true` if the encrypted value was
+    /// found.
+    ///
+    /// # Notes
+    ///
+    /// - If the clear value is not in the clear slice, the returned index is 0
+    pub fn unchecked_first_index_of_clear<T, Clear>(
+        &self,
+        cts: &[T],
+        clear: Clear,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        self.key
+            .key
+            .unchecked_first_index_of_clear_parallelized(cts, clear)
+    }
+
+    /// Returns the encrypted index of the _first_ occurrence of clear `value` in the ciphertext
+    /// slice also, it returns an encrypted boolean that is `true` if the encrypted value was
+    /// found.
+    ///
+    /// # Notes
+    ///
+    /// - If the clear value is not in the clear slice, the returned index is 0
+    pub fn smart_first_index_of_clear<T, Clear>(
+        &self,
+        cts: &mut [T],
+        clear: Clear,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        cts.iter_mut()
+            .filter(|ct| !ct.block_carries_are_empty())
+            .for_each(|ct| self.conditional_full_propagate(ct));
+
+        self.unchecked_first_index_of_clear(cts, clear)
+    }
+
+    /// Returns the encrypted index of the _first_ occurrence of clear `value` in the ciphertext
+    /// slice also, it returns an encrypted boolean that is `true` if the encrypted value was
+    /// found.
+    ///
+    /// # Notes
+    ///
+    /// - If the clear value is not in the clear slice, the returned index is 0
+    pub fn first_index_of_clear<T, Clear>(
+        &self,
+        cts: &[T],
+        clear: Clear,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+        Clear: DecomposableInto<u64> + CastInto<usize>,
+    {
+        let mut tmp_cts;
+
+        let cts = if cts.iter().any(|ct| !ct.block_carries_are_empty()) {
+            tmp_cts = cts.to_vec();
+            tmp_cts
+                .iter_mut()
+                .for_each(|ct| self.conditional_full_propagate(ct));
+            tmp_cts.as_slice()
+        } else {
+            cts
+        };
+
+        self.unchecked_first_index_of_clear(cts, clear)
+    }
+
+    /// Returns the encrypted index of the _first_ occurrence of encrypted `value` in the ciphertext
+    /// slice also, it returns an encrypted boolean that is `true` if the encrypted value was
+    /// found.
+    ///
+    /// # Notes
+    ///
+    /// - If the encrypted value is not in the clear slice, the returned index is 0
+    pub fn unchecked_first_index_of<T>(
+        &self,
+        cts: &[T],
+        value: &T,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.key
+            .key
+            .unchecked_first_index_of_parallelized(cts, value)
+    }
+
+    /// Returns the encrypted index of the _first_ occurrence of encrypted `value` in the ciphertext
+    /// slice also, it returns an encrypted boolean that is `true` if the encrypted value was
+    /// found.
+    ///
+    /// # Notes
+    ///
+    /// - If the encrypted value is not in the clear slice, the returned index is 0
+    pub fn smart_first_index_of_parallelized<T>(
+        &self,
+        cts: &mut [T],
+        value: &mut T,
+    ) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        self.conditional_full_propagate(value);
+
+        cts.iter_mut()
+            .for_each(|ct| self.conditional_full_propagate(ct));
+
+        self.unchecked_first_index_of(cts, value)
+    }
+
+    /// Returns the encrypted index of the _first_ occurrence of encrypted `value` in the ciphertext
+    /// slice also, it returns an encrypted boolean that is `true` if the encrypted value was
+    /// found.
+    ///
+    /// # Notes
+    ///
+    /// - If the encrypted value is not in the clear slice, the returned index is 0
+    pub fn first_index_of<T>(&self, cts: &[T], value: &T) -> (RadixCiphertext, BooleanBlock)
+    where
+        T: IntegerRadixCiphertext,
+    {
+        let mut tmp_cts;
+        let mut tmp_value;
+
+        let cts = if cts.iter().any(|ct| !ct.block_carries_are_empty()) {
+            tmp_cts = cts.to_vec();
+            tmp_cts
+                .iter_mut()
+                .for_each(|ct| self.conditional_full_propagate(ct));
+            &tmp_cts
+        } else {
+            cts
+        };
+
+        let value = if value.block_carries_are_empty() {
+            value
+        } else {
+            tmp_value = value.clone();
+            self.conditional_full_propagate(&mut tmp_value);
+            &tmp_value
+        };
+
+        self.unchecked_first_index_of(cts, value)
+    }
+}
diff --git a/tfhe/src/integer/mod.rs b/tfhe/src/integer/mod.rs
index 03ae281b..5bf4ca42 100755
--- a/tfhe/src/integer/mod.rs
+++ b/tfhe/src/integer/mod.rs
@@ -74,6 +74,9 @@ pub mod gpu;
 #[cfg(feature = "zk-pok")]
 pub use ciphertext::ProvenCompactCiphertextList;
 
+// #[cfg(feature = "fpga")]
+pub mod fpga;
+
 pub use bigint::i256::I256;
 pub use bigint::i512::I512;
 pub use bigint::u256::U256;
diff --git a/tfhe/src/integer/server_key/comparator.rs b/tfhe/src/integer/server_key/comparator.rs
index 2f39ccd7..5023f65f 100644
--- a/tfhe/src/integer/server_key/comparator.rs
+++ b/tfhe/src/integer/server_key/comparator.rs
@@ -15,7 +15,7 @@ pub(crate) enum ZeroComparisonType {
 
 /// Simple enum to select whether we are looking for the min or the max
 #[derive(Clone, Copy)]
-enum MinMaxSelector {
+pub(crate) enum MinMaxSelector {
     Max,
     Min,
 }
diff --git a/tfhe/src/integer/server_key/radix_parallel/count_zeros_ones.rs b/tfhe/src/integer/server_key/radix_parallel/count_zeros_ones.rs
index 7479c27e..59dd439b 100644
--- a/tfhe/src/integer/server_key/radix_parallel/count_zeros_ones.rs
+++ b/tfhe/src/integer/server_key/radix_parallel/count_zeros_ones.rs
@@ -5,7 +5,7 @@ use crate::shortint::ciphertext::Degree;
 use rayon::prelude::*;
 
 #[derive(Copy, Clone, PartialEq, Eq)]
-enum BitCountKind {
+pub(crate) enum BitCountKind {
     Zero,
     One,
 }
@@ -44,7 +44,11 @@ impl ServerKey {
         self.unchecked_count_bits_parallelized(ct, BitCountKind::Zero)
     }
 
-    fn unchecked_count_bits_parallelized<T>(&self, ct: &T, kind: BitCountKind) -> RadixCiphertext
+    pub(crate) fn unchecked_count_bits_parallelized<T>(
+        &self,
+        ct: &T,
+        kind: BitCountKind,
+    ) -> RadixCiphertext
     where
         T: IntegerRadixCiphertext,
     {
@@ -77,7 +81,11 @@ impl ServerKey {
         self.smart_count_bits_parallelized(ct, BitCountKind::Zero)
     }
 
-    fn smart_count_bits_parallelized<T>(&self, ct: &mut T, kind: BitCountKind) -> RadixCiphertext
+    pub(crate) fn smart_count_bits_parallelized<T>(
+        &self,
+        ct: &mut T,
+        kind: BitCountKind,
+    ) -> RadixCiphertext
     where
         T: IntegerRadixCiphertext,
     {
@@ -110,7 +118,7 @@ impl ServerKey {
         self.count_bits_parallelized(ct, BitCountKind::Zero)
     }
 
-    fn count_bits_parallelized<T>(&self, ct: &T, kind: BitCountKind) -> RadixCiphertext
+    pub(crate) fn count_bits_parallelized<T>(&self, ct: &T, kind: BitCountKind) -> RadixCiphertext
     where
         T: IntegerRadixCiphertext,
     {
diff --git a/tfhe/src/integer/server_key/radix_parallel/mod.rs b/tfhe/src/integer/server_key/radix_parallel/mod.rs
index eaee8dc4..920cec1a 100644
--- a/tfhe/src/integer/server_key/radix_parallel/mod.rs
+++ b/tfhe/src/integer/server_key/radix_parallel/mod.rs
@@ -3,7 +3,7 @@ mod add;
 mod bit_extractor;
 mod bitwise_op;
 pub(crate) mod cmux;
-mod comparison;
+pub(crate) mod comparison;
 mod div_mod;
 mod modulus_switch_compression;
 mod mul;
@@ -21,7 +21,7 @@ mod shift;
 pub(crate) mod sub;
 mod sum;
 
-mod count_zeros_ones;
+pub(crate) mod count_zeros_ones;
 pub(crate) mod ilog2;
 mod reverse_bits;
 mod slice;
diff --git a/tfhe/src/integer/server_key/radix_parallel/modulus_switch_compression.rs b/tfhe/src/integer/server_key/radix_parallel/modulus_switch_compression.rs
index 7539efc7..0c9b4c9b 100644
--- a/tfhe/src/integer/server_key/radix_parallel/modulus_switch_compression.rs
+++ b/tfhe/src/integer/server_key/radix_parallel/modulus_switch_compression.rs
@@ -57,7 +57,7 @@ impl ServerKey {
     }
 
     #[allow(clippy::int_plus_one)]
-    fn switch_modulus_and_compress_generic_parallelized(
+    pub(crate) fn switch_modulus_and_compress_generic_parallelized(
         &self,
         blocks: &[Ciphertext],
     ) -> CompressedModulusSwitchedRadixCiphertextGeneric {
@@ -107,7 +107,7 @@ impl ServerKey {
         }
     }
 
-    fn decompress_generic_parallelized(
+    pub(crate) fn decompress_generic_parallelized(
         &self,
         compressed_ct: &CompressedModulusSwitchedRadixCiphertextGeneric,
     ) -> Vec<Ciphertext> {
diff --git a/tfhe/src/integer/server_key/radix_parallel/mul.rs b/tfhe/src/integer/server_key/radix_parallel/mul.rs
index e37ff165..e04f79d1 100644
--- a/tfhe/src/integer/server_key/radix_parallel/mul.rs
+++ b/tfhe/src/integer/server_key/radix_parallel/mul.rs
@@ -253,7 +253,7 @@ impl ServerKey {
         self.full_propagate_parallelized(lhs);
     }
 
-    fn unchecked_block_mul_lsb_msb_parallelized<T>(
+    pub(crate) fn unchecked_block_mul_lsb_msb_parallelized<T>(
         &self,
         result_lsb: &mut T,
         result_msb: &mut T,
diff --git a/tfhe/src/integer/server_key/radix_parallel/tests_unsigned/mod.rs b/tfhe/src/integer/server_key/radix_parallel/tests_unsigned/mod.rs
index 36f85846..06066eeb 100644
--- a/tfhe/src/integer/server_key/radix_parallel/tests_unsigned/mod.rs
+++ b/tfhe/src/integer/server_key/radix_parallel/tests_unsigned/mod.rs
@@ -53,7 +53,7 @@ pub(crate) const fn nb_unchecked_tests_for_params(params: PBSParameters) -> usiz
     nb_tests_for_params(params)
 }
 
-/// Returns th number of loop iteration within randomized tests
+/// Returns the number of loop iteration within randomized tests
 ///
 /// The bigger the number of bits bootstrapped by the input parameters, the smaller the
 /// number of iteration is
@@ -207,7 +207,7 @@ pub(crate) fn unsigned_modulus_u128(block_modulus: MessageModulus, num_blocks: u
 /// Given a radix ciphertext, checks that all the block's decrypted message and carry
 /// do not exceed the block's degree.
 #[track_caller]
-fn panic_if_any_block_values_exceeds_its_degree<C>(ct: &RadixCiphertext, cks: &C)
+pub(crate) fn panic_if_any_block_values_exceeds_its_degree<C>(ct: &RadixCiphertext, cks: &C)
 where
     C: AsRef<crate::integer::ClientKey>,
 {
@@ -223,7 +223,7 @@ where
 }
 
 #[track_caller]
-fn panic_if_any_block_info_exceeds_max_degree_or_noise(
+pub(crate) fn panic_if_any_block_info_exceeds_max_degree_or_noise(
     ct: &RadixCiphertext,
     max_degree: MaxDegree,
     max_noise_level: MaxNoiseLevel,
@@ -270,7 +270,7 @@ fn panic_if_any_block_info_exceeds_max_degree_or_noise(
 /// - Its decrypted_value is <= its degree
 /// - Its noise level is nominal
 #[track_caller]
-fn panic_if_any_block_is_not_clean<C>(ct: &RadixCiphertext, cks: &C)
+pub(crate) fn panic_if_any_block_is_not_clean<C>(ct: &RadixCiphertext, cks: &C)
 where
     C: AsRef<crate::integer::ClientKey>,
 {
@@ -306,7 +306,7 @@ where
 /// Panics if a block is not either a clean block (see [panic_if_any_block_is_not_clean])
 /// or if it not trivial
 #[track_caller]
-fn panic_if_any_block_is_not_clean_or_trivial<C>(ct: &RadixCiphertext, cks: &C)
+pub(crate) fn panic_if_any_block_is_not_clean_or_trivial<C>(ct: &RadixCiphertext, cks: &C)
 where
     C: AsRef<crate::integer::ClientKey>,
 {
@@ -342,15 +342,15 @@ where
 }
 
 /// Little struct meant to reduce test boilerplate and increase readability
-struct ExpectedValues<T> {
+pub(crate) struct ExpectedValues<T> {
     values: Vec<T>,
 }
 
-type ExpectedNoiseLevels = ExpectedValues<NoiseLevel>;
-type ExpectedDegrees = ExpectedValues<Degree>;
+pub(crate) type ExpectedNoiseLevels = ExpectedValues<NoiseLevel>;
+pub(crate) type ExpectedDegrees = ExpectedValues<Degree>;
 
 impl<T> ExpectedValues<T> {
-    fn new(init: T, len: usize) -> Self
+    pub(crate) fn new(init: T, len: usize) -> Self
     where
         T: Clone,
     {
@@ -359,7 +359,7 @@ impl<T> ExpectedValues<T> {
         }
     }
 
-    fn set_with(&mut self, iter: impl Iterator<Item = T>) {
+    pub(crate) fn set_with(&mut self, iter: impl Iterator<Item = T>) {
         let mut self_iter = self.values.iter_mut();
         self_iter
             .by_ref()
@@ -376,7 +376,7 @@ impl<T> ExpectedValues<T> {
 
 impl ExpectedNoiseLevels {
     #[track_caller]
-    fn panic_if_any_is_not_equal(&self, ct: &RadixCiphertext) {
+    pub(crate) fn panic_if_any_is_not_equal(&self, ct: &RadixCiphertext) {
         assert_eq!(self.values.len(), ct.blocks.len());
         for (i, (block, expected_noise)) in ct
             .blocks
@@ -395,7 +395,7 @@ impl ExpectedNoiseLevels {
 
 impl ExpectedDegrees {
     #[track_caller]
-    fn panic_if_any_is_not_equal(&self, ct: &RadixCiphertext) {
+    pub(crate) fn panic_if_any_is_not_equal(&self, ct: &RadixCiphertext) {
         assert_eq!(self.values.len(), ct.blocks.len());
         for (i, (block, expected_degree)) in ct
             .blocks
@@ -412,7 +412,7 @@ impl ExpectedDegrees {
     }
 
     #[track_caller]
-    fn panic_if_any_is_greater(&self, ct: &RadixCiphertext) {
+    pub(crate) fn panic_if_any_is_greater(&self, ct: &RadixCiphertext) {
         assert_eq!(self.values.len(), ct.blocks.len());
         for (i, (block, expected_degree)) in ct
             .blocks
diff --git a/tfhe/src/shortint/client_key/mod.rs b/tfhe/src/shortint/client_key/mod.rs
index 6c307c88..30c6af6d 100644
--- a/tfhe/src/shortint/client_key/mod.rs
+++ b/tfhe/src/shortint/client_key/mod.rs
@@ -519,7 +519,7 @@ impl ClientKey {
         self.decrypt_message_and_carry(ct) % ct.message_modulus.0 as u64
     }
 
-    pub(crate) fn decrypt_no_decode(&self, ct: &Ciphertext) -> u64 {
+    pub fn decrypt_no_decode(&self, ct: &Ciphertext) -> u64 {
         let lwe_decryption_key = match ct.pbs_order {
             PBSOrder::KeyswitchBootstrap => self.large_lwe_secret_key(),
             PBSOrder::BootstrapKeyswitch => self.small_lwe_secret_key(),
diff --git a/tfhe/src/shortint/engine/mod.rs b/tfhe/src/shortint/engine/mod.rs
index b58bd950..51cdf52a 100644
--- a/tfhe/src/shortint/engine/mod.rs
+++ b/tfhe/src/shortint/engine/mod.rs
@@ -131,6 +131,64 @@ where
     max_value
 }
 
+pub(crate) fn fill_accumulator_vector<C>(
+    accumulator: &mut GlweCiphertext<C>,
+    server_key: &ServerKey,
+    vector: &Vec<u64>,
+) -> u64
+where
+    C: ContainerMut<Element = u64>,
+{
+    assert_eq!(
+        accumulator.polynomial_size(),
+        server_key.bootstrapping_key.polynomial_size()
+    );
+    assert_eq!(
+        accumulator.glwe_size(),
+        server_key.bootstrapping_key.glwe_size()
+    );
+
+    let mut accumulator_view = accumulator.as_mut_view();
+
+    accumulator_view.get_mut_mask().as_mut().fill(0);
+
+    // Modulus of the msg contained in the msg bits and operations buffer
+    let modulus_sup = server_key.message_modulus.0 * server_key.carry_modulus.0;
+
+    assert_eq!(vector.len(), modulus_sup);
+
+    // N/(p/2) = size of each block
+    let box_size = server_key.bootstrapping_key.polynomial_size().0 / modulus_sup;
+
+    // Value of the shift we multiply our messages by
+    let delta = (1_u64 << 63) / (server_key.message_modulus.0 * server_key.carry_modulus.0) as u64;
+
+    let mut body = accumulator_view.get_mut_body();
+    let accumulator_u64 = body.as_mut();
+
+    // Tracking the max value of the function to define the degree later
+    let mut max_value = 0;
+
+    for i in 0..modulus_sup {
+        let index = i * box_size;
+        let f_eval = vector[i as usize];
+        max_value = max_value.max(f_eval);
+        accumulator_u64[index..index + box_size].fill(f_eval * delta);
+    }
+
+    let half_box_size = box_size / 2;
+
+    // Negate the first half_box_size coefficients
+    for a_i in accumulator_u64[0..half_box_size].iter_mut() {
+        *a_i = (*a_i).wrapping_neg();
+    }
+
+    // Rotate the accumulator
+    accumulator_u64.rotate_left(half_box_size);
+
+    max_value
+}
+
 pub(crate) fn fill_accumulator_no_encoding<F, C>(
     accumulator: &mut GlweCiphertext<C>,
     server_key: &ServerKey,
@@ -290,6 +348,17 @@ pub struct ShortintEngine {
 }
 
 impl ShortintEngine {
+    /// Replace the thread_local ShortIntEngine
+    ///
+    /// `new_engine` will replace the already_existing
+    /// `thread_local` engine.
+    /// ```
+    pub fn replace_thread_local(new_engine: Self) {
+        Self::with_thread_local_mut(|local_engine| {
+            let _ = std::mem::replace(local_engine, new_engine);
+        });
+    }
+
     /// Safely gives access to the `thead_local` shortint engine
     /// to call one (or many) of its method.
     #[inline]
diff --git a/tfhe/src/shortint/server_key/bivariate_pbs.rs b/tfhe/src/shortint/server_key/bivariate_pbs.rs
index 419b6115..e91ca01b 100644
--- a/tfhe/src/shortint/server_key/bivariate_pbs.rs
+++ b/tfhe/src/shortint/server_key/bivariate_pbs.rs
@@ -164,6 +164,22 @@ impl ServerKey {
         self.apply_lookup_table_assign(ct_left, &acc.acc);
     }
 
+    //version without actual PBS to allow for parallelized version
+    pub fn unchecked_apply_lookup_table_bivariate_assign_prep(
+        &self,
+        ct_left: &mut Ciphertext,
+        ct_right: &Ciphertext,
+        acc: &BivariateLookupTableOwned,
+    ) {
+        let modulus = (ct_right.degree.get() + 1) as u64;
+        assert!(modulus <= acc.ct_right_modulus.0 as u64);
+
+        self.unchecked_scalar_mul_assign(ct_left, acc.ct_right_modulus.0 as u8);
+
+        unchecked_add_assign(ct_left, ct_right);
+    }
+
+
     /// Compute a keyswitch and programmable bootstrap.
     ///
     /// # Example
diff --git a/tfhe/src/shortint/server_key/mod.rs b/tfhe/src/shortint/server_key/mod.rs
index d33f7bb3..7c4dea7a 100644
--- a/tfhe/src/shortint/server_key/mod.rs
+++ b/tfhe/src/shortint/server_key/mod.rs
@@ -49,8 +49,10 @@ use crate::core_crypto::prelude::ComputationBuffers;
 use crate::shortint::ciphertext::{Ciphertext, Degree, MaxDegree, MaxNoiseLevel, NoiseLevel};
 use crate::shortint::client_key::ClientKey;
 use crate::shortint::engine::{
-    fill_accumulator, fill_accumulator_no_encoding, fill_many_lut_accumulator, ShortintEngine,
+    fill_accumulator, fill_accumulator_no_encoding, fill_accumulator_vector,
+    fill_many_lut_accumulator, ShortintEngine,
 };
+
 use crate::shortint::parameters::{
     CarryModulus, CiphertextConformanceParams, CiphertextModulus, MessageModulus,
 };
@@ -784,6 +786,21 @@ impl ServerKey {
         }
     }
 
+    pub fn generate_lookup_table_vector(&self, vector: &Vec<u64>) -> LookupTableOwned {
+        let mut acc = GlweCiphertext::new(
+            0,
+            self.bootstrapping_key.glwe_size(),
+            self.bootstrapping_key.polynomial_size(),
+            self.ciphertext_modulus,
+        );
+        let max_value = fill_accumulator_vector(&mut acc, self, vector);
+
+        LookupTableOwned {
+            acc,
+            degree: Degree::new(max_value as usize),
+        }
+    }
+
     /// Given a function as input, constructs the lookup table working on the message bits
     /// Carry bits are ignored
     ///
@@ -1055,6 +1072,40 @@ impl ServerKey {
         }
     }
 
+    pub fn apply_lookup_table_packed(
+        &self,
+        cts: Vec<&Ciphertext>,
+        accs: &Vec<LookupTableOwned>,
+    ) -> Vec<Ciphertext> {
+        let mut ct_ress: Vec<Ciphertext> = cts.iter().map(|&ct| ct.clone()).collect();
+
+        match self.pbs_order {
+            PBSOrder::KeyswitchBootstrap => {
+                self.keyswitch_programmable_bootstrap_assign_packed(&mut ct_ress, &accs);
+            }
+            PBSOrder::BootstrapKeyswitch => {
+                panic!("Packed BootstrapKeyswitch is not supported")
+            }
+        };
+
+        ct_ress
+    }
+
+    pub fn apply_lookup_table_packed_assign(
+        &self,
+        cts: &mut Vec<Ciphertext>,
+        accs: &Vec<LookupTableOwned>,
+    ) {
+        match self.pbs_order {
+            PBSOrder::KeyswitchBootstrap => {
+                self.keyswitch_programmable_bootstrap_assign_packed(cts, accs);
+            }
+            PBSOrder::BootstrapKeyswitch => {
+                panic!("Packed BootstrapKeyswitch is not supported")
+            }
+        };
+    }
+
     /// Applies the given function to the message of a ciphertext
     /// The input is reduced to the message space before the function application
     /// Thee output of the function is also rduced to the message space such that the carry bits are
@@ -1349,7 +1400,7 @@ impl ServerKey {
             .set_deterministic_pbs_execution(new_deterministic_execution);
     }
 
-    fn trivial_pbs_assign(&self, ct: &mut Ciphertext, acc: &LookupTableOwned) {
+    pub fn trivial_pbs_assign(&self, ct: &mut Ciphertext, acc: &LookupTableOwned) {
         #[cfg(feature = "pbs-stats")]
         // We want to count trivial PBS in simulator mode
         // In the non trivial case, this increment is done in the `apply_blind_rotate` function
@@ -1482,6 +1533,87 @@ impl ServerKey {
         outputs
     }
 
+    pub(crate) fn keyswitch_programmable_bootstrap_assign(
+        &self,
+        ct: &mut Ciphertext,
+        acc: &LookupTableOwned,
+    ) {
+        if ct.is_trivial() {
+            self.trivial_pbs_assign(ct, acc);
+            return;
+        }
+
+        ShortintEngine::with_thread_local_mut(|engine| {
+            // Compute the programmable bootstrapping with fixed test polynomial
+            let (mut ciphertext_buffers, buffers) = engine.get_buffers(self);
+
+            // Compute a key switch
+            keyswitch_lwe_ciphertext(
+                &self.key_switching_key,
+                &ct.ct,
+                &mut ciphertext_buffers.buffer_lwe_after_ks,
+            );
+
+            match &self.bootstrapping_key {
+                ShortintBootstrappingKey::Classic(fourier_bsk) => {
+                    let fft = Fft::new(fourier_bsk.polynomial_size());
+                    let fft = fft.as_view();
+                    buffers.resize(
+                        programmable_bootstrap_lwe_ciphertext_mem_optimized_requirement::<u64>(
+                            fourier_bsk.glwe_size(),
+                            fourier_bsk.polynomial_size(),
+                            fft,
+                        )
+                        .unwrap()
+                        .unaligned_bytes_required(),
+                    );
+                    let stack = buffers.stack();
+
+                    // Compute a bootstrap
+                    programmable_bootstrap_lwe_ciphertext_mem_optimized(
+                        &ciphertext_buffers.buffer_lwe_after_ks,
+                        &mut ct.ct,
+                        &acc.acc,
+                        fourier_bsk,
+                        fft,
+                        stack,
+                    );
+                }
+                ShortintBootstrappingKey::MultiBit {
+                    fourier_bsk,
+                    thread_count,
+                    deterministic_execution,
+                } => {
+                    multi_bit_programmable_bootstrap_lwe_ciphertext(
+                        &ciphertext_buffers.buffer_lwe_after_ks,
+                        &mut ct.ct,
+                        &acc.acc,
+                        fourier_bsk,
+                        *thread_count,
+                        *deterministic_execution,
+                    );
+                }
+            }
+        });
+
+        ct.degree = acc.degree;
+        ct.set_noise_level(NoiseLevel::NOMINAL);
+    }
+
+    pub(crate) fn keyswitch_programmable_bootstrap_assign_packed(
+        &self,
+        cts: &mut Vec<Ciphertext>,
+        accs: &Vec<LookupTableOwned>,
+    ) {
+        use rayon::prelude::*;
+
+        cts.par_iter_mut()
+            .zip(accs.par_iter())
+            .for_each(|(ct, acc)| {
+                self.keyswitch_programmable_bootstrap_assign(ct, acc);
+            });
+    }
+
     pub(crate) fn programmable_bootstrap_keyswitch_many_lut(
         &self,
         ct: &Ciphertext,
diff --git a/tfhe/wrapper.h b/tfhe/wrapper.h
new file mode 100644
index 00000000..a0874875
--- /dev/null
+++ b/tfhe/wrapper.h
@@ -0,0 +1,4 @@
+#include "xrt.h"
+#include "xrt/xrt_bo.h"
+#include "xrt/xrt_device.h"
+#include "xrt/xrt_kernel.h"
\ No newline at end of file
